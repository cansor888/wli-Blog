/*
 Navicat Premium Data Transfer

 Source Server         : localhost
 Source Server Type    : MySQL
 Source Server Version : 50716
 Source Host           : localhost:3306
 Source Schema         : cms

 Target Server Type    : MySQL
 Target Server Version : 50716
 File Encoding         : 65001

 Date: 21/01/2021 13:17:24
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for tb_article
-- ----------------------------
DROP TABLE IF EXISTS `tb_article`;
CREATE TABLE `tb_article`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `channel_id` int(11) NOT NULL,
  `title` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `title_img` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `summary` varchar(500) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `author` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `url` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `status` int(1) NULL DEFAULT NULL COMMENT '0待发布|1已发布',
  `comment_status` int(1) NULL DEFAULT NULL COMMENT '0/NULL允许评论|1不允许评论',
  `rotation` int(1) NULL DEFAULT NULL COMMENT '0/NULL非轮播|1轮播',
  `top` int(1) NULL DEFAULT NULL COMMENT '0/NULL不置顶 | 1 置顶',
  `orderby` int(11) NULL DEFAULT NULL,
  `create_date` date NULL DEFAULT NULL,
  `create_user` int(11) NULL DEFAULT NULL,
  `update_date` date NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 49 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of tb_article
-- ----------------------------
INSERT INTO `tb_article` VALUES (6, 17, '前后端分离登录解决方案-JavaWeb—基于Token的身份验证', 'http://localhost:8888/cms/upload/e1365261-e7b7-4856-95ff-5da038a374ef.png', 'HTTP Basic Auth简单点说明就是每次请求API时都提供用户的username和password，简言之，Basic Auth是配合RESTful API 使用的最简单的认证方式，只需提供用户名密码即可，但由于有把用户名密码暴露给第三方客户端的风险，在生产环境下被使用的越来越少。因此，在开发对外开放的RESTful API时，尽量避免采用HTTP Basic Auth。', 'cc老师', '', '参考网页\n\n​ https://www.cnblogs.com/Jason-Xiang/p/9808596.html\n\n​ http://tool.chinaz.com/Tools/Base64.aspx\n\nHTTP Basic Auth\nHTTP Basic Auth简单点说明就是每次请求API时都提供用户的username和password，简言之，Basic Auth是配合RESTful API 使用的最简单的认证方式，只需提供用户名密码即可，但由于有把用户名密码暴露给第三方客户端的风险，在生产环境下被使用的越来越少。因此，在开发对外开放的RESTful API时，尽量避免采用HTTP Basic Auth。\n\nCookie Auth\nCookie认证机制就是为一次请求认证在服务端创建一个Session对象，同时在客户端的浏览器端创建了一个Cookie对象（jsessionId）；通过客户端带上的Cookie对象来与服务器端的session对象匹配来实现状态管理的。默认的，当我们关闭浏览器的时候，cookie会被删除。但可以通过修改cookie 的expire time使cookie在一定时间内有效。\n\n基于 Token 的身份验证方法\n使用基于 Token 的身份验证方法，大概的流程是这样的：\n\n客户端使用用户名跟密码请求登录\n服务端收到请求，去验证用户名与密码\n验证成功后，服务端会签发一个 Token然后保存（缓存或者数据库），再把这个 Token 发送给客户端\n客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里\n客户端每次向服务端请求资源的时候需要带着服务端签发的 Token\n服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据\nToken机制相对于Cookie机制又有什么好处呢？\n支持跨域访问: Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提是传输的用户认证信息通过HTTP头传输.\n无状态(也称：服务端可扩展行):Token机制在服务端不需要存储session信息，因为Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息.\n更适用CDN: 可以通过内容分发网络请求你服务端的所有资料（如：javascript，HTML,图片等），而你的服务端只要提供API即可.\n去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在你的API被调用的时候，你可以进行Token生成调用即可.\n更适用于移动应用: 当你的客户端是一个原生平台（iOS, Android，Windows 8等）时，Cookie是不被支持的（你需要通过Cookie容器进行处理），这时采用Token认证机制就会简单得多。\nCSRF:因为不再依赖于Cookie，所以你就不需要考虑对CSRF（跨站请求伪造）的防范。\n性能: 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算 的Token验证和解析要费时得多.\n基于标准化:你的API可以采用标准化的 JSON Web Token (JWT). 这个标准已经存在多个后端库（.NET, Ruby, Java,Python, PHP）和多家公司的支持（如：Firebase,Google, Microsoft）.\n基于JWT的Token认证机制实现\n实施 Token 验证的方法挺多的，还有一些标准规范，其中JSON Web Token（JWT）是一个非常轻巧的规范 。JWT 标准的 Token 有三个部分：\n\nheader（头部）\npayload（数据）\nsignature（签名）\n中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样：\n\neyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\nHeader\n每个 JWT token 里面都有一个 header，也就是头部数据。里面包含了使用的算法，这个 JWT 是不是带签名的或者加密的。主要就是说明一下怎么处理这个 JWT token 。\n\n头部里包含的东西可能会根据 JWT 的类型有所变化，比如一个加密的 JWT 里面要包含使用的加密的算法。唯一在头部里面要包含的是 alg 这个属性，如果是加密的 JWT，这个属性的值就是使用的签名或者解密用的算法。如果是未加密的 JWT，这个属性的值要设置成 none。\n\n示例：', 1, 0, 0, 0, NULL, '2020-11-05', 1, '2020-11-05');
INSERT INTO `tb_article` VALUES (7, 22, '我刚开始就把它当做一个我吐槽心情的地方', '', '个人博客，用来做什么？我刚开始就把它当做一个我吐槽心情的地方，也就相当于一个网络记事本，写上一些关于自己生活工作中的小情小事，也会放上一些照片，音乐。每天工作回家后就能访问自己的网站，一边听着音乐，一边写写文章。', '', '', '本文很长，记录了我博客建站初到现在的过程，还有我从毕业到现在的一个状态，感谢您的阅读，如果你还是学生，也许你能从此文中，找到我们曾经相似的地方。如果你已经工作，有自己的博客，我想，你并没有忘记当初建立个人博客的初衷吧！\n\n我的个人博客已经建站有8年的时间了，对它的热爱，一直都是只增未减。回想大学读书的那几年，那会儿非常流行QQ空间，我们寝室的室友还经常邀约去学校的网吧做自己的空间。系里有个男生，空间做得非常漂亮，什么悬浮，开场动画，音乐播放器，我们女生羡慕得不得了。还邀约他跟我们一起去通宵弄空间，网上可以找到很多免费的flash资源，还有音乐，那也是第一次接触js，知道在浏览器输入一个地址，修改一下数据，就能调用一些背景出来。然后把自己QQ空间弄得漂漂亮亮的，经常邀约室友来互踩。我记得08年地震，第二天晚上，我们寝室的几个人还淡定的在寝室装扮空间呢！', 1, 0, 0, 0, NULL, '2020-11-05', 1, '2020-11-05');
INSERT INTO `tb_article` VALUES (8, 22, '个人网站做好了，百度不收录怎么办？来，看看他们怎么做的。', '', '不管你是学前端的还是后端的，作为一个程序员，做一个自己的博客，那是必然的。咱们的圈子就这么大，想让更多的人了解你，看看你的技术多牛逼，扔一个博客地址就行了。', '', '', '不管你是学前端的还是后端的，作为一个程序员，做一个自己的博客，那是必然的。咱们的圈子就这么大，想让更多的人了解你，看看你的技术多牛逼，扔一个博客地址就行了。\n\n大多数人在没有搭建好博客之前，看到别人的博客做得那么绚丽，内容那么丰富，心里啊就想着自己也要弄个博客玩儿，不求排名，自娱自乐。可是越往后，你越会发现，自己一个人观赏那不够，于是就想让更多的人搜到你自己的博客。又开始琢磨怎么优化，天天在百度site看收录没有，七天，绝对熬不过七天，九成的人就会崩溃，而且对博客的热度开始慢慢减少，有些甚至破罐子破摔了，本来坚持原创的，后来伪原创，再后来直接转别人的，再再后来就干脆懒得打理网站了。\n\n还有些站长啊，刚开始连续一星期发布了上千条记录，这些内容都不是他自己的，全是照搬别的网站，或者采集的。也是盼着能收录，怎么还不收录啊，明明发了那么多文章，收一篇也行啊，又开始琢磨，是不是网站程序不好啊，听说**好，换一个试试，于是开始了新一轮的战斗....\n\n今天我要给大家介绍的这两位站长，有SEO大咖，也有刚加入博客圈的站长，咱们来看看他们怎么做SEO的吧\n\n01\n\n白杨，真名杨红林，在杭州的四川人。他专注SEO研究八年，SEO实战派，前杰恩西运营总监。他做过很多网站平台优化，如电子市场网、捷多邦、王氏阳澄湖大闸蟹、日贸通（杰恩西国内品牌）等，涉及艺术、金融类企业网站、化工、电信等行业。', 1, 0, 0, 0, NULL, '2020-11-05', 1, '2020-11-05');
INSERT INTO `tb_article` VALUES (9, 28, '再见 Spring Boot 1.X ，Spring Boot 2.X 走向舞台中心', 'http://localhost:8888/cms/upload/ea2a3fcc-0efc-43d6-be4d-5cfb0dbe71ce.png', '如果项目中使用了微服务架构，建议可以一个一个子服务进行升级，不要一次全部升级完成，保障整个服务在升级过程的稳定性。我之前写过 Spring Boot 1.x 升级 2.x 的文章，大家可以参考：Spring Boot 2.0 版的开源项目云收藏来了！', '', '', '2019年8月6日，Spring 官方在其博客宣布，Spring Boot 1.x 停止维护，Spring Boot 1.x 生命周期正式结束。\n\n\n\n其实早在2018年7月30号，Spring 官方就已经在博客进行过预告，Spring Boot 1.X 将维护到2019年8月1日。 1.5.x 将会是 Spring Boot 1.0 系列的最后一个大版本。\n\n\n\n如今 Spring Boot 1.X 版本最后将永久的定格在 v1.5.22.RELEASE，其实回想起来自从 Spring Boot 1.0 发布已经过去了 5 年多，相当于 Spring Boot 一年发布一个大的子版本，然后到了现在的 1.5.x。\n\n而 Spring Boot 2.0.0 也于2018年3月1号正式发布，如今已经过了整整一年多，同时 Spring Boot 2.2 已经到了第五个里程碑。\n\nSpring Boot 2.X 也是时候走向舞台中心接力 Spring Boot 1.x 的历史使命。\n\n我们来回顾一下 Spring Boot 重大版本的历史节点：\n\n2014年04月01号，Spring Boot 发布 v1.0.0.RELEASE，Spring Boot 正式商用\n2014年06月11号，Spring Boot 发布 v1.1.0.RELEASE，主要修复了若干 Bug\n2014年12月11号，Spring Boot 发布 v1.2.0.RELEASE，此版本更新的特性比较多，主要集成了 Servlet 3.1，支持 JTA、J2EE 等。\n2015年11月16号，Spring Boot 发布 v1.3.0.RELEASE，增加了新 spring-boot-devtools 模块，缓存自动配置、颜色 banners 等新特性。\n2016年07月29号，Spring Boot 发布 v1.4.0.RELEASE，以 Spring 4.3 为基础进行的构建，更新了很多第三方库的支持，重点增加了 Neo4J, Couchbase、 Redis 等 Nosql 的支持。\n2017年01月30号，Spring Boot 发布 v1.5.0.RELEASE，更新了动态日志修改，增加 Apache Kafka、LDAP、事物管理等特性的支持。\n2018年03月01号，Spring Boot 发布 v2.0.0.RELEASE，2.0更新的内容就太多了，详情请参考：Spring Boot 2.0权威发布\n2018年10月30号，Spring Boot 发布 v2.1.0.RELEASE，主要更新了相关特性，详见：Spring Boot 2.1.0 权威发布\n当时 Spring Boot 2.0 刚刚发布的时候，我说过一段话：\n\nSpring Boot 2.0 是历时 4 年开发出来的巨作，在 Spring Boot 1.0 的基础上进行了大量的优化，淘汰了很多过期的 API，同时引入了一大批最新的技术，这些新技术在未来的一段时间内都具有引导性。\n\n如果不是特别需要使用 Spring Boot 2.0 上面提到的新特性，就尽量不要着急进行升级，等 Spring Boot 2.0 彻底稳定下来后再使用。如果想要升级也请先从早期的版本升级到 Spring Boot 1.5.X 系列之后，再升级到 Spring Boot 2.0 版本，Spring Boot 2.0 的很多配置内容和 Spring Boot 1.0 不一致需要注意。\n\n当时因为 Spring Boot 2.0 刚刚发布有一些特性可能不是特别稳定，并不推荐大家立刻在生产环境使用，但到了今天 Spring Boot 2.X 系列最新稳定版本已经到了 2.1.7，大家可以放心的在生产环境使用了。\n\n生产中正在使用 Spring Boot 1.x 需要立刻升级吗？\n\nSpring Boot 1.x 只是停止维护，并不是不能用了，如果你不是特别着急想用 Spring Boot 2.x 的新特性，再用个几年也是没有任何问题的。\n\n另外，Spring Boot 1.x 到 2.x 中间更新了很多 API 以及依赖组件。升级时需要先将 Spring Boot 1.X 系列升级到 1.5.x，再从 1.5.x 升级到 2.x 最新稳定版本。\n\nSpring Boot 2.x 对 Java 环境的要求最低为 JDK 8，可能还有很多的公司服务器还在 1.6 或者 1.7 的环境中跑着，升级的时候也需要先升级服务器的基础环境。\n\n如果项目中使用了微服务架构，建议可以一个一个子服务进行升级，不要一次全部升级完成，保障整个服务在升级过程的稳定性。我之前写过 Spring Boot 1.x 升级 2.x 的文章，大家可以参考：Spring Boot 2.0 版的开源项目云收藏来了！。\n\n最后祝愿 Spirng Boot 发展越来越好。', 1, 0, 0, 0, NULL, '2020-11-06', 1, '2020-11-06');
INSERT INTO `tb_article` VALUES (10, 28, 'Spring Boot 面试，一个问题就干趴下了', 'http://localhost:8888/cms/upload/f609f686-14cf-4ae0-af2d-cefa44e7be7c.jpg', '随着 Spring Boot 使用越来越广泛，Spring Boot 已经成为 Java 程序员面试的知识点，很多同学对 Spring Boot 理解不是那么深刻，经常就会被几个连环跑给干趴下了！Spring Boot 的最大的优势是“约定优于配置“。“约定优于配置“是一种软件设计范式，开发人员按照约定的方式来进行编程，可以减少软件开发人员需做决定的数量，获得简单的好处，而又不失灵活性', '', '', '随着 Spring Boot 使用越来越广泛，Spring Boot 已经成为 Java 程序员面试的知识点，很多同学对 Spring Boot 理解不是那么深刻，经常就会被几个连环跑给干趴下了！\n\n比如下面这一段的 Spring Boot 问答：\n\n问：你觉得 Spring Boot 最大的优势是什么呢？\n\n答：Spring Boot 的最大的优势是“约定优于配置“。“约定优于配置“是一种软件设计范式，开发人员按照约定的方式来进行编程，可以减少软件开发人员需做决定的数量，获得简单的好处，而又不失灵活性。\n\n问：Spring Boot 中 “约定优于配置“的具体产品体现在哪里。\n\n答：Spring Boot Starter、Spring Boot Jpa 都是“约定优于配置“的一种体现。都是通过“约定优于配置“的设计思路来设计的，Spring Boot Starter 在启动的过程中会根据约定的信息对资源进行初始化；Spring Boot Jpa 通过约定的方式来自动生成 Sql ，避免大量无效代码编写。具体详细可以参考：Spring Boot 为什么这么火？\n\n问：Spring Boot Starter 的工作原理是什么？\n\n答：Spring Boot 在启动的时候会干这几件事情：\n\n① Spring Boot 在启动时会去依赖的 Starter 包中寻找 resources/META-INF/spring.factories 文件，然后根据文件中配置的 Jar 包去扫描项目所依赖的 Jar 包。\n\n② 根据 spring.factories 配置加载 AutoConfigure 类\n\n③ 根据 @Conditional 注解的条件，进行自动配置并将 Bean 注入 Spring Context\n\n总结一下，其实就是 Spring Boot 在启动的时候，按照约定去读取 Spring Boot Starter 的配置信息，再根据配置信息对资源进行初始化，并注入到 Spring 容器中。这样 Spring Boot 启动完毕后，就已经准备好了一切资源，使用过程中直接注入对应 Bean 资源即可。\n\n这只是简单的三连环问答，不知道有多少同学能够完整的回答出来。\n\n其实 Spring Boot 中有很多的技术点可以挖掘，今天给大家整理了十个高频 Spring Boot 面试题，希望可以在后期的面试中帮助到大家。\n\n1、Spring Boot 的自动配置是如何实现的？\nSpring Boot 项目的启动注解是：@SpringBootApplication，其实它就是由下面三个注解组成的：\n\n@Configuration\n\n@ComponentScan\n\n@EnableAutoConfiguration\n\n其中 @EnableAutoConfiguration 是实现自动配置的入口，该注解又通过 @Import 注解导入了AutoConfigurationImportSelector，在该类中加载 META-INF/spring.factories 的配置信息。然后筛选出以 EnableAutoConfiguration 为 key 的数据，加载到 IOC 容器中，实现自动配置功能！\n\n2、什么是嵌入式服务器？我们为什么要使用嵌入式服务器呢?\n思考一下在你的虚拟机上部署应用程序需要些什么。\n\n第一步：安装 Java\n\n第二部：安装 Web 或者是应用程序的服务器（Tomat/Wbesphere/Weblogic 等等）\n\n第三部：部署应用程序 war 包\n\n如果我们想简化这些步骤，应该如何做呢？\n\n让我们来思考如何使服务器成为应用程序的一部分？\n\n你只需要一个安装了 Java 的虚拟机，就可以直接在上面部署应用程序了，\n\n是不是很爽？\n\n这个想法是嵌入式服务器的起源。\n\n当我们创建一个可以部署的应用程序的时候，我们将会把服务器（例如，tomcat）嵌入到可部署的服务器中。\n\n例如，对于一个 Spring Boot 应用程序来说，你可以生成一个包含 Embedded Tomcat 的应用程序 jar。你就可以像运行正常 Java 应用程序一样来运行 web 应用程序了。\n\n嵌入式服务器就是我们的可执行单元包含服务器的二进制文件（例如，tomcat.jar）。\n\n3、微服务同时调用多个接口，怎么支持事务的啊？\n支持分布式事务，可以使用Spring Boot集成 Aatomikos来解决，但是我一般不建议这样使用，因为使用分布式事务会增加请求的响应时间，影响系统的TPS。一般在实际工作中，会利用消息的补偿机制来处理分布式的事务。\n\n4、shiro和oauth还有cas他们之间的关系是什么？问下您公司权限是如何设计，还有就是这几个概念的区别。\ncas和oauth是一个解决单点登录的组件，shiro主要是负责权限安全方面的工作，所以功能点不一致。但往往需要单点登陆和权限控制一起来使用，所以就有 cas+shiro或者oauth+shiro这样的组合。\n\ntoken一般是客户端登录后服务端生成的令牌，每次访问服务端会进行校验，一般保存到内存即可，也可以放到其他介质；redis可以做Session共享，如果前端web服务器有几台负载，但是需要保持用户登录的状态，这场景使用比较常见。\n\n我们公司使用oauth+shiro这样的方式来做后台权限的管理，oauth负责多后台统一登录认证，shiro负责给登录用户赋予不同的访问权限。\n\n5、各服务之间通信，对Restful和Rpc这2种方式如何做选择？\n在传统的SOA治理中，使用rpc的居多；Spring Cloud默认使用restful进行服务之间的通讯。rpc通讯效率会比restful要高一些，但是对于大多数公司来讲，这点效率影响甚微。我建议使用restful这种方式，易于在不同语言实现的服务之间通讯。\n\n6、怎么设计无状态服务？\n对于无状态服务，首先说一下什么是状态：如果一个数据需要被多个服务共享，才能完成一笔交易，那么这个数据被称为状态。进而依赖这个“状态”数据的服务被称为有状态服务，反之称为无状态服务。\n\n那么这个无状态服务原则并不是说在微服务架构里就不允许存在状态，表达的真实意思是要把有状态的业务服务改变为无状态的计算类服务，那么状态数据也就相应的迁移到对应的“有状态数据服务”中。\n\n场景说明：例如我们以前在本地内存中建立的数据缓存、Session缓存，到现在的微服务架构中就应该把这些数据迁移到分布式缓存中存储，让业务服务变成一个无状态的计算节点。迁移后，就可以做到按需动态伸缩，微服务应用在运行时动态增删节点，就不再需要考虑缓存数据如何同步的问题。\n\n7、Spring Cache 三种常用的缓存注解和意义？\n@Cacheable ，用来声明方法是可缓存，将结果存储到缓存中以便后续使用相同参数调用时不需执行实际的方法，直接从缓存中取值。\n\n@CachePut，使用 @CachePut 标注的方法在执行前，不会去检查缓存中是否存在之前执行过的结果，而是每次都会执行该方法，并将执行结果以键值对的形式存入指定的缓存中。\n\n@CacheEvict，是用来标注在需要清除缓存元素的方法或类上的，当标记在一个类上时表示其中所有的方法的执行都会触发缓存的清除操作。\n\n8、Spring Boot 如何设置支持跨域请求？\n现代浏览器出于安全的考虑， HTTP 请求时必须遵守同源策略，否则就是跨域的 HTTP 请求，默认情况下是被禁止的，IP（域名）不同、或者端口不同、协议不同（比如 HTTP、HTTPS）都会造成跨域问题。\n\n一般前端的解决方案有：\n\n① 使用 JSONP 来支持跨域的请求，JSONP 实现跨域请求的原理简单的说，就是动态创建<script>标签，然后利用<script>的 SRC 不受同源策略约束来跨域获取数据。缺点是需要后端配合输出特定的返回信息。\n\n② 利用反应代理的机制来解决跨域的问题，前端请求的时候先将请求发送到同源地址的后端，通过后端请求转发来避免跨域的访问。\n\n后来 HTML5 支持了 CORS 协议。CORS 是一个 W3C 标准，全称是”跨域资源共享”（Cross-origin resource sharing），允许浏览器向跨源服务器，发出 XMLHttpRequest 请求，从而克服了 AJAX 只能同源使用的限制。它通过服务器增加一个特殊的 Header[Access-Control-Allow-Origin]来告诉客户端跨域的限制，如果浏览器支持 CORS、并且判断 Origin 通过的话，就会允许 XMLHttpRequest 发起跨域请求。\n\n前端使用了 CORS 协议，就需要后端设置支持非同源的请求，Spring Boot 设置支持非同源的请求有两种方式。\n\n第一，配置 CorsFilter。\n\n\n@Configuration\npublic class GlobalCorsConfig {\n    @Bean\n    public CorsFilter corsFilter() {\n        CorsConfiguration config = new CorsConfiguration();\n          config.addAllowedOrigin(\"*\");\n          config.setAllowCredentials(true);\n          config.addAllowedMethod(\"*\");\n          config.addAllowedHeader(\"*\");\n          config.addExposedHeader(\"*\");\n\n        UrlBasedCorsConfigurationSource configSource = new UrlBasedCorsConfigurationSource();\n        configSource.registerCorsConfiguration(\"/**\", config);\n\n        return new CorsFilter(configSource);\n    }\n}\n\n需要配置上述的一段代码。第二种方式稍微简单一些。\n\n第二，在启动类上添加：\n\n\npublic class Application extends WebMvcConfigurerAdapter {  \n\n    @Override  \n    public void addCorsMappings(CorsRegistry registry) {  \n\n        registry.addMapping(\"/**\")  \n                .allowCredentials(true)  \n                .allowedHeaders(\"*\")  \n                .allowedOrigins(\"*\")  \n                .allowedMethods(\"*\");  \n\n    }  \n}  \n\n9、JPA 和 Hibernate 有哪些区别？JPA 可以支持动态 SQL 吗？\nJPA本身是一种规范，它的本质是一种ORM规范（不是ORM框架，因为JPA并未提供ORM实现，只是制定了规范）因为JPA是一种规范，所以，只是提供了一些相关的接口，但是接口并不能直接使用，JPA底层需要某种JPA实现，Hibernate 是 JPA 的一个实现集。\n\nJPA 是根据实体类的注解来创建对应的表和字段，如果需要动态创建表或者字段，需要动态构建对应的实体类，再重新调用Jpa刷新整个Entity。动态SQL，mybatis支持的最好，jpa也可以支持，但是没有Mybatis那么灵活。\n\n10、Spring 、Spring Boot 和 Spring Cloud 的关系?\nSpring 最初最核心的两大核心功能 Spring Ioc 和 Spring Aop 成就了 Spring，Spring 在这两大核心的功能上不断的发展，才有了 Spring 事务、Spring Mvc 等一系列伟大的产品，最终成就了 Spring 帝国，到了后期 Spring 几乎可以解决企业开发中的所有问题。\n\nSpring Boot 是在强大的 Spring 帝国生态基础上面发展而来，发明 Spring Boot 不是为了取代 Spring ,是为了让人们更容易的使用 Spring 。\n\nSpring Cloud 是一系列框架的有序集合。它利用 Spring Boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot 的开发风格做到一键启动和部署。\n\nSpring Cloud 是为了解决微服务架构中服务治理而提供的一系列功能的开发框架，并且 Spring Cloud 是完全基于 Spring Boot 而开发，Spring Cloud 利用 Spring Boot 特性整合了开源行业中优秀的组件，整体对外提供了一套在微服务架构中服务治理的解决方案。\n\n用一组不太合理的包含关系来表达它们之间的关系。\n\nSpring ioc/aop > Spring > Spring Boot > Spring Cloud', 1, 0, 0, 0, NULL, '2020-11-06', 1, '2020-11-06');
INSERT INTO `tb_article` VALUES (11, 17, 'Spring项目实战', 'http://localhost:8888/cms/upload/8496a1a0-abd6-4605-85f3-c8c0c220706f.png', '配置前端控制器DispatcherServlet 加载Spring-mvc.xml配置文件,还有启动很多东西，加载spring容器，配置前端控制器DispatcherServlet 加载Spring-mvc.xml配置文件,还有启动很多东西，加载spring容器，配置前端控制器DispatcherServlet 加载Spring-mvc.xml配置文件,还有启动很多东西，加载spring容器', '', '', '# 学生学籍管理系统\n\n主讲人：研真教育-cc（QQ：596183363）\n\n视频及源码地址：http://yanzhen.ke.qq.com/\n\n## 1.技术路线\n\n- 开发工具：IDEA\n- 技术框架：SSM（Spring+SpringMVC+Mybatis）\n- Web容器：Apache Tomcat 8.5\n- 数据库：MySQL8.0（建议使用5.5及其以上版本）\n- 前端UI框架：Layui\n\n## 2.需求分析\n\n详见思维导图\n\n## 3.数据库设计\n\n![pdm图初稿](images\\pdm图初稿.png)\n\n## 4.项目框架搭建\n\n### 4.1引入jar\n\n```xml\n引入Spring相关jar\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-context</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-core</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-beans</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-aop</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-web</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-webmvc</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-jdbc</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-tx</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-test</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n\n<dependency>\n    <groupId>org.mybatis</groupId>\n    <artifactId>mybatis</artifactId>\n    <version>3.5.5</version>\n</dependency>\n\n<dependency>\n    <groupId>org.mybatis</groupId>\n    <artifactId>mybatis-spring</artifactId>\n    <version>2.0.5</version>\n</dependency>\n```\n\n### 4.2配置spring核心配置文件\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n</beans>\n```\n\n### 4.3配置spring-MVC核心配置文件\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n</beans>\n```\n\n### 4.4 配置web.xml\n\n```xml\n<!--整合spring的几个步骤\n    1、配置前端控制器DispatcherServlet 加载Spring-mvc.xml配置文件,还有启动很多东西，加载spring容器\n    2、配置Spring上下文监听器：加载applicationContext.xml文件\n    3、配置编码过滤器：解决编码问题 -->\n\n<servlet>\n    <servlet-name>student_system</servlet-name>\n    <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n    <init-param>\n        <param-name>contextConfigLocation</param-name>\n        <param-value>classpath:spring-mvc.xml</param-value>\n    </init-param>\n    <load-on-startup>1</load-on-startup>\n</servlet>\n\n<servlet-mapping>\n    <servlet-name>student_system</servlet-name>\n    <url-pattern>/</url-pattern>\n</servlet-mapping>\n\n<!--上下文参数-->\n<context-param>\n    <param-name>contextConfigLocation</param-name>\n    <param-value>classpath:applicationContext.xml</param-value>\n</context-param>\n<!--配置spring上下文监听-->\n<listener>\n    <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>\n</listener>\n\n<filter>\n    <filter-name>encodingFilter</filter-name>\n    <filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>\n    <init-param>\n        <param-name>encoding</param-name>\n        <param-value>utf-8</param-value>\n    </init-param>\n</filter>\n<filter-mapping>\n    <filter-name>encodingFilter</filter-name>\n    <url-pattern>/*</url-pattern>\n</filter-mapping>\n```\n\n### 4.5 整合Mybatis\n\n**准备工作：**\n\n```xml\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>8.0.12</version>\n</dependency>\n\n<dependency>\n    <groupId>org.apache.commons</groupId>\n    <artifactId>commons-dbcp2</artifactId>\n    <version>2.7.0</version>\n</dependency>\n```\n\n```properties\njdbc.driver=com.mysql.cj.jdbc.Driver\njdbc.url=jdbc:mysql://127.0.0.1:3306/student_system?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai&useSSL=false\njdbc.username=root\njdbc.password=123456\n```\n\n```xml\n操作步骤\n1、加载db.properties\n<context:property-placeholder location=\"classpath:db.properties\" />\n2、配置数据源\n<bean id=\"dataSource\" class=\"org.apache.commons.dbcp2.BasicDataSource\">\n    <property name=\"driverClassName\" value=\"${jdbc.driver}\"></property>\n    <property name=\"url\" value=\"${jdbc.url}\"></property>\n    <property name=\"username\" value=\"${jdbc.username}\"></property>\n    <property name=\"password\" value=\"${jdbc.password}\"></property>\n</bean>\n3、获取SqlSessionFactory工厂\n<bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <property name=\"dataSource\" ref=\"dataSource\"/>\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"></property>\n        <property name=\"mapperLocations\">\n            <list>\n                <value>classpath:com/yanzhen/dao/*.xml</value>\n            </list>\n        </property>\n        <!--配置分页插件-->\n        <property name=\"plugins\">\n            <array>\n                <bean class=\"com.github.pagehelper.PageInterceptor\">\n                    <property name=\"properties\">\n                        <value>\n                            helperDialect=mysql\n                        </value>\n                    </property>\n                </bean>\n            </array>\n        </property>\n</bean>\n4、配置扫描Mapper文件\n<bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\">\n    <property name=\"basePackage\" value=\"com.yanzhen.dao\"></property>\n    <property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"></property>\n</bean>\n```\n\n### 4.6测试SSM框架\n\n```xml\n<context:component-scan base-package=\"com.yanzhen.controller\" />\n<context:component-scan base-package=\"com.yanzhen.service\" />\n```\n\n![](images\\test.png)\n\n\n\n### 4.7Dao层编写\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.yanzhen.mapper.ClazzDao\">\n    <resultMap type=\"com.yanzhen.entity.Clazz\" id=\"Clazz\">\n        <id column=\"id\" property=\"id\"/>\n        <result column=\"clazz_name\" property=\"clazzName\"/>\n        <result column=\"id\" property=\"id\"/>\n        <result column=\"remark\" property=\"remark\"/>\n        <result column=\"subject_id\" property=\"subjectId\"/>\n    </resultMap>\n\n    <insert id=\"create\" keyProperty=\"id\" useGeneratedKeys=\"true\" parameterType=\"com.yanzhen.entity.Clazz\">\n		insert into tb_clazz(\n			clazz_name,\n			remark,\n			subject_id\n		)values(\n			#{clazzName},\n			#{remark},\n			#{subjectId}\n		)\n	</insert>\n\n    <select id=\"query\" resultMap=\"Clazz\">\n        select * from tb_clazz\n        <include refid=\"ClazzFindCriteria\"/>\n        <if test=\"offset!=null and rows!=null\">limit ${offset} , ${rows}</if>\n    </select>\n\n    <select id=\"count\" resultType=\"int\">\n        select count(1) from tb_clazz\n        <include refid=\"ClazzFindCriteria\"/>\n    </select>\n\n    <select id=\"detail\" resultMap=\"Clazz\">\n        select * from tb_clazz\n        <include refid=\"ClazzFindCriteria\"/>\n        limit 1\n    </select>\n\n    <delete id=\"delete\">\n        delete from tb_clazz\n        <include refid=\"ClazzFindCriteria\"/>\n    </delete>\n    <update id=\"update\">\n        update tb_clazz\n        <include refid=\"ClazzUpdateCriteria\"/>\n        <include refid=\"ClazzFindCriteria\"/>\n    </update>\n    <sql id=\"ClazzFindCriteria\">\n        <where>\n            <if test=\"clazzName != null and clazzName != \'\'\">and clazz_name = #{clazzName}</if>\n            <if test=\"id != null\">and id = #{id}</if>\n            <if test=\"remark != null and remark != \'\'\">and remark = #{remark}</if>\n            <if test=\"subjectId != null\">and subject_id = #{subjectId}</if>\n        </where>\n    </sql>\n    <sql id=\"ClazzUpdateCriteria\">\n        <set>\n            <if test=\"updateClazzName != null and updateClazzName != \'\'\">clazz_name = #{updateClazzName},</if>\n            <if test=\"updateId != null\">id = #{updateId},</if>\n            <if test=\"updateRemark != null and updateRemark != \'\'\">remark = #{updateRemark},</if>\n            <if test=\"updateSubjectId != null\">subject_id = #{updateSubjectId},</if>\n        </set>\n    </sql>\n</mapper>\n```\n\n### 4.8Service层编写\n\n```java\n@Service\npublic class UserService {\n\n    @Autowired\n    private UserDao userDao;\n\n    public int create(User pi) {\n        return userDao.create(pi);\n    }\n\n    public int delete(Integer id) {\n        return userDao.delete(MapParameter.getInstance().addId(id).getMap());\n    }\n\n    public int update(User user) {\n        return userDao.update(BeanMapUtils.beanToMapForUpdate(user));\n    }\n\n    public List<User> query(User user) {\n        return userDao.query(BeanMapUtils.beanToMapForUpdate(user));\n    }\n\n    public User detail(Integer id) {\n        return userDao.detail(MapParameter.getInstance().addId(id).getMap());\n    }\n\n    public int count(User user) {\n        return userDao.count(BeanMapUtils.beanToMapForUpdate(user));\n    }\n\n}\n```\n\n### 4.9 Controller层编写\n\n```xml\n<!--spring将Map转为json对象的时依赖的两个包-->\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-core</artifactId>\n    <version>${jackson.version}</version>\n</dependency>\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-databind</artifactId>\n    <version>${jackson.version}</version>\n</dependency>\n```\n\n', 1, 0, 0, 0, NULL, '2020-11-06', 1, '2020-11-06');
INSERT INTO `tb_article` VALUES (12, 31, '构造函数和原型', '', '静态成员 在构造函数本身上添加的成员  如下列代码中 sex 就是静态成员,静态成员只能通过构造函数来访问，JavaScript 规定，每一个构造函数都有一个prototype 属性，指向另一个对象。注意这个prototype就是一个对象，这个对象的所有属性和方法，都会被构造函数所拥有。', '', '', '### 1.1对象的三种创建方式--复习\n\n1. 字面量方式\n\n   ```js\n   var obj = {};\n   ```\n\n2. new关键字\n\n   ```js\n   var obj = new Object();\n   ```\n\n3. 构造函数方式\n\n   ```js\n   function Person(name,age){\n     this.name = name;\n     this.age = age;\n   }\n   var obj = new Person(\'zs\',12);\n   ```\n\n### 1.2静态成员和实例成员\n\n#### 1.2.1实例成员\n\n实例成员就是构造函数内部通过this添加的成员 如下列代码中uname age sing 就是实例成员,实例成员只能通过实例化的对象来访问\n\n```js\n function Star(uname, age) {\n     this.uname = uname;\n     this.age = age;\n     this.sing = function() {\n     console.log(\'我会唱歌\');\n    }\n}\nvar ldh = new Star(\'刘德华\', 18);\nconsole.log(ldh.uname);//实例成员只能通过实例化的对象来访问\n```\n\n#### 1.2.2静态成员\n\n静态成员 在构造函数本身上添加的成员  如下列代码中 sex 就是静态成员,静态成员只能通过构造函数来访问\n\n```js\n function Star(uname, age) {\n     this.uname = uname;\n     this.age = age;\n     this.sing = function() {\n     console.log(\'我会唱歌\');\n    }\n}\nStar.sex = \'男\';\nvar ldh = new Star(\'刘德华\', 18);\nconsole.log(Star.sex);//静态成员只能通过构造函数来访问\n```\n\n### 1.3构造函数的问题\n\n构造函数方法很好用，但是存在浪费内存的问题。\n\n![](images/img1.png)\n\n### 1.4构造函数原型prototype\n\n构造函数通过原型分配的函数是所有对象所共享的。\n\nJavaScript 规定，每一个构造函数都有一个prototype 属性，指向另一个对象。注意这个prototype就是一个对象，这个对象的所有属性和方法，都会被构造函数所拥有。\n\n我们可以把那些不变的方法，直接定义在 prototype 对象上，这样所有对象的实例就可以共享这些方法。\n\n```js\nfunction Star(uname, age) {\n    this.uname = uname;\n    this.age = age;\n}\nStar.prototype.sing = function() {\n	console.log(\'我会唱歌\');\n}\nvar ldh = new Star(\'刘德华\', 18);\nvar zxy = new Star(\'张学友\', 19);\nldh.sing();//我会唱歌\nzxy.sing();//我会唱歌\n```\n\n![](images/img7.png)\n\n### 1.5对象原型\n\n```html\n对象都会有一个属性 __proto__ 指向构造函数的 prototype 原型对象，之所以我们对象可以使用构造函数 prototype 原型对象的属性和方法，就是因为对象有 __proto__ 原型的存在。\n__proto__对象原型和原型对象 prototype 是等价的\n__proto__对象原型的意义就在于为对象的查找机制提供一个方向，或者说一条路线，但是它是一个非标准属性，因此实际开发中，不可以使用这个属性，它只是内部指向原型对象 prototype\n```\n\n![](images/img2.png)\n\n\n\n![](images/img3.png)\n\n\n\n### 1.6constructor构造函数\n\n```html\n对象原型（ __proto__）和构造函数（prototype）原型对象里面都有一个属性 constructor 属性 ，constructor 我们称为构造函数，因为它指回构造函数本身。\nconstructor 主要用于记录该对象引用于哪个构造函数，它可以让原型对象重新指向原来的构造函数。\n一般情况下，对象的方法都在构造函数的原型对象中设置。如果有多个对象的方法，我们可以给原型对象采取对象形式赋值，但是这样就会覆盖构造函数原型对象原来的内容，这样修改后的原型对象 constructor  就不再指向当前构造函数了。此时，我们可以在修改后的原型对象中，添加一个 constructor 指向原来的构造函数。\n```\n\n如果我们修改了原来的原型对象,给原型对象赋值的是一个对象,则必须手动的利用constructor指回原来的构造函数如:\n\n```js\n function Star(uname, age) {\n     this.uname = uname;\n     this.age = age;\n }\n // 很多情况下,我们需要手动的利用constructor 这个属性指回 原来的构造函数\n Star.prototype = {\n // 如果我们修改了原来的原型对象,给原型对象赋值的是一个对象,则必须手动的利用constructor指回原来的构造函数\n   constructor: Star, // 手动设置指回原来的构造函数\n   sing: function() {\n     console.log(\'我会唱歌\');\n   },\n   movie: function() {\n     console.log(\'我会演电影\');\n   }\n}\nvar zxy = new Star(\'张学友\', 19);\nconsole.log(zxy)\n```\n\n以上代码运行结果,设置constructor属性如图:\n\n![](images/img8.png)如果未设置constructor属性,如图:\n\n![](images/img9.png)\n\n### 1.7原型链\n\n​	每一个实例对象又有一个__proto__属性，指向的构造函数的原型对象，构造函数的原型对象也是一个对象，也有__proto__属性，这样一层一层往上找就形成了原型链。\n\n![](images/img5.png)\n\n### 1.8构造函数实例和原型对象三角关系\n\n```js\n1.构造函数的prototype属性指向了构造函数原型对象\n2.实例对象是由构造函数创建的,实例对象的__proto__属性指向了构造函数的原型对象\n3.构造函数的原型对象的constructor属性指向了构造函数,实例对象的原型的constructor属性也指向了构造函数\n```\n\n![](images/img4.png)\n\n\n\n### 1.9原型链和成员的查找机制\n\n任何对象都有原型对象,也就是prototype属性,任何原型对象也是一个对象,该对象就有__proto__属性,这样一层一层往上找,就形成了一条链,我们称此为原型链;\n\n```html\n当访问一个对象的属性（包括方法）时，首先查找这个对象自身有没有该属性。\n如果没有就查找它的原型（也就是 __proto__指向的 prototype 原型对象）。\n如果还没有就查找原型对象的原型（Object的原型对象）。\n依此类推一直找到 Object 为止（null）。\n__proto__对象原型的意义就在于为对象成员查找机制提供一个方向，或者说一条路线。\n```\n\n### 1.10原型对象中this指向\n\n构造函数中的this和原型对象的this,都指向我们new出来的实例对象\n\n```js\nfunction Star(uname, age) {\n    this.uname = uname;\n    this.age = age;\n}\nvar that;\nStar.prototype.sing = function() {\n    console.log(\'我会唱歌\');\n    that = this;\n}\nvar ldh = new Star(\'刘德华\', 18);\n// 1. 在构造函数中,里面this指向的是对象实例 ldh\nconsole.log(that === ldh);//true\n// 2.原型对象函数里面的this 指向的是 实例对象 ldh\n```\n\n![](images/img6.png)\n\n### 1.11通过原型为数组扩展内置方法\n\n```js\n Array.prototype.sum = function() {\n   var sum = 0;\n   for (var i = 0; i < this.length; i++) {\n   sum += this[i];\n   }\n   return sum;\n };\n //此时数组对象中已经存在sum()方法了  可以始终 数组.sum()进行数据的求\n```\n\n## 2.继承\n\n### 2.1call()\n\n- call()可以调用函数\n- call()可以修改this的指向,使用call()的时候 参数一是修改后的this指向,参数2,参数3..使用逗号隔开连接\n\n```js\n function fn(x, y) {\n     console.log(this);\n     console.log(x + y);\n}\n  var o = {\n  	name: \'andy\'\n  };\n  fn.call(o, 1, 2);//调用了函数此时的this指向了对象o,\n```\n\n![](images/img10.png)\n\n### 2.2子构造函数继承父构造函数中的属性\n\n1. 先定义一个父构造函数\n2. 再定义一个子构造函数\n3. 子构造函数继承父构造函数的属性(使用call方法)\n\n```js\n // 1. 父构造函数\n function Father(uname, age) {\n   // this 指向父构造函数的对象实例\n   this.uname = uname;\n   this.age = age;\n }\n  // 2 .子构造函数 \nfunction Son(uname, age, score) {\n  // this 指向子构造函数的对象实例\n  3.使用call方式实现子继承父的属性\n  Father.call(this, uname, age);\n  this.score = score;\n}\nvar son = new Son(\'刘德华\', 18, 100);\nconsole.log(son);\n```\n\n![](images/img11.png)\n\n### 2.3借用原型对象继承方法\n\n1. 先定义一个父构造函数\n2. 再定义一个子构造函数\n3. 子构造函数继承父构造函数的属性(使用call方法)\n\n```js\n// 1. 父构造函数\nfunction Father(uname, age) {\n  // this 指向父构造函数的对象实例\n  this.uname = uname;\n  this.age = age;\n}\nFather.prototype.money = function() {\n  console.log(100000);\n };\n // 2 .子构造函数 \n  function Son(uname, age, score) {\n      // this 指向子构造函数的对象实例\n      Father.call(this, uname, age);\n      this.score = score;\n  }\n// Son.prototype = Father.prototype;  这样直接赋值会有问题,如果修改了子原型对象,父原型对象也会跟着一起变化\n  Son.prototype = new Father();\n  // 如果利用对象的形式修改了原型对象,别忘了利用constructor 指回原来的构造函数\n  Son.prototype.constructor = Son;\n  // 这个是子构造函数专门的方法\n  Son.prototype.exam = function() {\n    console.log(\'孩子要考试\');\n\n  }\n  var son = new Son(\'刘德华\', 18, 100);\n  console.log(son);\n```\n\n如上代码结果如图:\n\n![](images/img12.png)\n\n## 3.ES5新增方法\n\n### 3.1数组方法forEach遍历数组\n\n```js\n arr.forEach(function(value, index, array) {\n       //参数一是:数组元素\n       //参数二是:数组元素的索引\n       //参数三是:当前的数组\n })\n  //相当于数组遍历的 for循环 没有返回值\n```\n\n### 3.2数组方法filter过滤数组\n\n```js\n  var arr = [12, 66, 4, 88, 3, 7];\n  var newArr = arr.filter(function(value, index,array) {\n  	 //参数一是:数组元素\n     //参数二是:数组元素的索引\n     //参数三是:当前的数组\n     return value >= 20;\n  });\n  console.log(newArr);//[66,88] //返回值是一个新数组\n```\n\n### 3.3数组方法some\n\n```js\nsome 查找数组中是否有满足条件的元素 \n var arr = [10, 30, 4];\n var flag = arr.some(function(value,index,array) {\n    //参数一是:数组元素\n     //参数二是:数组元素的索引\n     //参数三是:当前的数组\n     return value < 3;\n  });\nconsole.log(flag);//false返回值是布尔值,只要查找到满足条件的一个元素就立马终止循环\n```\n\n### 3.4筛选商品案例\n\n1. 定义数组对象数据\n\n   ```js\n   var data = [{\n               id: 1,\n               pname: \'小米\',\n               price: 3999\n           }, {\n               id: 2,\n               pname: \'oppo\',\n               price: 999\n           }, {\n               id: 3,\n               pname: \'荣耀\',\n               price: 1299\n           }, {\n               id: 4,\n               pname: \'华为\',\n               price: 1999\n           }, ];\n   ```\n\n2. 使用forEach遍历数据并渲染到页面中\n\n   ```js\n   data.forEach(function(value) {\n     var tr = document.createElement(\'tr\');\n     tr.innerHTML = \'<td>\' + value.id + \'</td><td>\' + value.pname + \'</td><td>\' + value.price + \'</td>\';\n     tbody.appendChild(tr);\n    });\n   ```\n\n3. 根据价格筛选数据\n\n   1. 获取到搜索按钮并为其绑定点击事件\n\n      ```js\n      search_price.addEventListener(\'click\', function() {\n      });\n      ```\n\n   2. 使用filter将用户输入的价格信息筛选出来\n\n      ```js\n      search_price.addEventListener(\'click\', function() {\n            var newDate = data.filter(function(value) {\n              //start.value是开始区间\n              //end.value是结束的区间\n            	return value.price >= start.value && value.price <= end.value;\n            });\n            console.log(newDate);\n       });\n      ```\n\n   3. 将筛选出来的数据重新渲染到表格中\n\n      1. 将渲染数据的逻辑封装到一个函数中\n\n         ```js\n         function setDate(mydata) {\n               // 先清空原来tbody 里面的数据\n           tbody.innerHTML = \'\';\n           mydata.forEach(function(value) {\n             var tr = document.createElement(\'tr\');\n             tr.innerHTML = \'<td>\' + value.id + \'</td><td>\' + value.pname + \'</td><td>\' + value.price + \'</td>\';\n               tbody.appendChild(tr);\n           });\n          }\n         ```\n\n      2. 将筛选之后的数据重新渲染\n\n         ```js\n          search_price.addEventListener(\'click\', function() {\n              var newDate = data.filter(function(value) {\n              return value.price >= start.value && value.price <= end.value;\n              });\n              console.log(newDate);\n              // 把筛选完之后的对象渲染到页面中\n              setDate(newDate);\n         });\n         ```\n\n   4. 根据商品名称筛选\n\n      1. 获取用户输入的商品名称\n\n      2. 为查询按钮绑定点击事件,将输入的商品名称与这个数据进行筛选\n\n         ```js\n          search_pro.addEventListener(\'click\', function() {\n              var arr = [];\n              data.some(function(value) {\n                if (value.pname === product.value) {\n                  // console.log(value);\n                  arr.push(value);\n                  return true; // return 后面必须写true  \n                }\n              });\n              // 把拿到的数据渲染到页面中\n              setDate(arr);\n         })\n         ```\n\n### 3.5some和forEach区别\n\n- 如果查询数组中唯一的元素, 用some方法更合适,在some 里面 遇到 return true 就是终止遍历 迭代效率更高\n- 在forEach 里面 return 不会终止迭代\n\n### 3.6trim方法去除字符串两端的空格\n\n```js\nvar str = \'   hello   \'\nconsole.log(str.trim()）  //hello 去除两端空格\nvar str1 = \'   he l l o   \'\nconsole.log(str.trim()）  //he l l o  去除两端空格\n```\n\n### 3.7获取对象的属性名\n\nObject.keys(对象) 获取到当前对象中的属性名 ，返回值是一个数组\n\n```js\n var obj = {\n     id: 1,\n     pname: \'小米\',\n     price: 1999,\n     num: 2000\n};\nvar result = Object.keys(obj)\nconsole.log(result)//[id，pname,price,num]\n```\n\n### 3.8Object.defineProperty\n\nObject.defineProperty设置或修改对象中的属性\n\n```js\nObject.defineProperty(对象，修改或新增的属性名，{\n		value:修改或新增的属性的值,\n		writable:true/false,//如果值为false 不允许修改这个属性值\n		enumerable: false,//enumerable 如果值为false 则不允许遍历\n        configurable: false  //configurable 如果为false 则不允许删除这个属性 属性是否可以被删除或是否可以再次修改特性\n})	\n```\n\n\n\n\n\n', 1, 0, 0, 0, NULL, '2020-11-06', 1, '2020-11-06');
INSERT INTO `tb_article` VALUES (13, 33, 'Element-UI:一套基于2.0的桌面端组件库', '', '全局定义的组件不能重名，字符串模板缺乏语法高亮，不支持css(当html和js组件化时，css没有参与其中) 没有构建步骤限制，只能使用H5和ES5，不能使用预处理器（babel）， 服务器端的模块化规范是使用CommonJS规范', '', '', '### 今日目标\n1.能够了解模块化的相关规范 \n2.了解webpack\n3.了解使用Vue单文件组件\n4.能够搭建Vue脚手架  \n5.掌握Element-UI的使用 \n\n\n### 1.模块化的分类\n### #A.浏览器端的模块化\n        1).AMD(Asynchronous Module Definition,异步模块定义)\n        代表产品为：Require.js\n        2).CMD(Common Module Definition,通用模块定义)\n        代表产品为：Sea.js\n### #B.服务器端的模块化\n        服务器端的模块化规范是使用CommonJS规范：\n        1).使用require引入其他模块或者包\n        2).使用exports或者module.exports导出模块成员\n        3).一个文件就是一个模块，都拥有独立的作用域\n### #C.ES6模块化\n        ES6模块化规范中定义：\n            1).每一个js文件都是独立的模块\n            2).导入模块成员使用import关键字\n            3).暴露模块成员使用export关键字\n\n小结：推荐使用ES6模块化，因为AMD，CMD局限使用与浏览器端，而CommonJS在服务器端使用。\n      ES6模块化是浏览器端和服务器端通用的规范.\n\n### 2.在NodeJS中安装babel\n### #A.安装babel\n    打开终端，输入命令：npm install --save-dev @babel/core @babel/cli @babel/preset-env @babel/node\n    安装完毕之后，再次输入命令安装：npm install --save @babel/polyfill\n### #B.创建babel.config.js\n    在项目目录中创建babel.config.js文件。\n    编辑js文件中的代码如下：\n        const presets = [\n            [\"@babel/env\",{\n                targets:{\n                    edge:\"17\",\n                    firefox:\"60\",\n                    chrome:\"67\",\n                    safari:\"11.1\"\n                }\n            }]\n        ]\n        //暴露\n        module.exports = { presets }\n### #C.创建index.js文件\n    在项目目录中创建index.js文件作为入口文件\n    在index.js中输入需要执行的js代码，例如：\n        console.log(\"ok\");\n### #D.使用npx执行文件\n    打开终端，输入命令：npx babel-node ./index.js\n\n### 3.设置默认导入/导出\n### #A.默认导出\n    export default {\n        成员A,\n        成员B,\n        .......\n    },如下：\n    let num = 100;\n    export default{\n        num\n    }\n### #B.默认导入\n    import 接收名称 from \"模块标识符\"，如下：\n    import test from \"./test.js\"\n\n注意：在一个模块中，只允许使用export default向外默认暴露一次成员，千万不要写多个export default。\n如果在一个模块中没有向外暴露成员，其他模块引入该模块时将会得到一个空对象 \n\n### 4.设置按需导入/导出\n### #A.按需导出\n    export let num = 998;\n    export let myName = \"jack\";\n    export function fn = function(){ console.log(\"fn\") }\n### #B.按需导入 \n    import { num,fn as printFn ,myName } from \"./test.js\"\n    //同时导入默认导出的成员以及按需导入的成员\n    import test,{ num,fn as printFn ,myName } from \"./test.js\"\n注意：一个模块中既可以按需导入也可以默认导入，一个模块中既可以按需导出也可以默认导出\n\n### 5.直接导入并执行代码\n    import \"./test2.js\";\n\n### 6.webpack的概念\nwebpack是一个流行的前端项目构建工具，可以解决目前web开发的困境。\nwebpack提供了模块化支持，代码压缩混淆，解决js兼容问题，性能优化等特性，提高了开发效率和项目的可维护性\n\n### 7.webpack的基本使用\n### #A.创建项目目录并初始化\n    创建项目，并打开项目所在目录的终端，输入命令：\n        npm init -y\n### #B.创建首页及js文件\n    在项目目录中创建index.html页面，并初始化页面结构：在页面中摆放一个ul，ul里面放置几个li\n    在项目目录中创建js文件夹，并在文件夹中创建index.js文件\n### #C.安装jQuery\n    打开项目目录终端，输入命令:\n    npm install jQuery -S\n### #D.导入jQuery\n    打开index.js文件，编写代码导入jQuery并实现功能：\n    import $ from \"jquery\";\n    $(function(){\n        $(\"li:odd\").css(\"background\",\"cyan\");\n        $(\"li:odd\").css(\"background\",\"pink\");\n    })\n注意：此时项目运行会有错误，因为import $ from \"jquery\";这句代码属于ES6的新语法代码，在浏览器中可能会存在兼容性问题\n所以我们需要webpack来帮助我们解决这个问题。\n### #E.安装webpack\n    1).打开项目目录终端，输入命令:\n    npm install webpack webpack-cli -D\n    2).然后在项目根目录中，创建一个 webpack.config.js 的配置文件用来配置webpack\n    在 webpack.config.js 文件中编写代码进行webpack配置，如下：\n    module.exports = {\n        mode:\"development\"//可以设置为development(开发模式)，production(发布模式)\n    }\n    补充：mode设置的是项目的编译模式。\n    如果设置为development则表示项目处于开发阶段，不会进行压缩和混淆，打包速度会快一些\n    如果设置为production则表示项目处于上线发布阶段，会进行压缩和混淆，打包速度会慢一些\n    3).修改项目中的package.json文件添加运行脚本dev，如下：\n    \"scripts\":{\n        \"dev\":\"webpack\"\n    }\n    注意：scripts节点下的脚本，可以通过 npm run 运行，如：\n    运行终端命令：npm run dev\n    将会启动webpack进行项目打包\n    4).运行dev命令进行项目打包，并在页面中引入项目打包生成的js文件\n    打开项目目录终端，输入命令:\n    npm run dev\n    等待webpack打包完毕之后，找到默认的dist路径中生成的main.js文件，将其引入到html页面中。\n    浏览页面查看效果。\n\n### 8.设置webpack的打包入口/出口\n    在webpack 4.x中，默认会将src/index.js 作为默认的打包入口js文件\n                     默认会将dist/main.js 作为默认的打包输出js文件\n    如果不想使用默认的入口/出口js文件，我们可以通过改变 webpack.config.js 来设置入口/出口的js文件，如下：\n    const path = require(\"path\");\n    module.exports = {\n        mode:\"development\",\n        //设置入口文件路径\n        entry: path.join(__dirname,\"./src/xx.js\"),\n        //设置出口文件\n        output:{\n            //设置路径\n            path:path.join(__dirname,\"./dist\"),\n            //设置文件名\n            filename:\"res.js\"\n        }\n    }\n### 9.设置webpack的自动打包\n    默认情况下，我们更改入口js文件的代码，需要重新运行命令打包webpack，才能生成出口的js文件\n    那么每次都要重新执行命令打包，这是一个非常繁琐的事情，那么，自动打包可以解决这样繁琐的操作。\n    实现自动打包功能的步骤如下：\n        A.安装自动打包功能的包:webpack-dev-server\n            npm install webpack-dev-server -D\n        B.修改package.json中的dev指令如下：\n            \"scripts\":{\n                \"dev\":\"webpack-dev-server\"\n            }\n        C.将引入的js文件路径更改为：<script src=\"/bundle.js\"></script>\n        D.运行npm run dev，进行打包\n        E.打开网址查看效果：http://localhost:8080\n    \n    注意：webpack-dev-server自动打包的输出文件，默认放到了服务器的根目录中.\n\n补充：\n在自动打包完毕之后，默认打开服务器网页，实现方式就是打开package.json文件，修改dev命令：\n    \"dev\": \"webpack-dev-server --open --host 127.0.0.1 --port 9999\"\n\n### 10.配置html-webpack-plugin\n    使用html-webpack-plugin 可以生成一个预览页面。\n    因为当我们访问默认的 http://localhost:8080/的时候，看到的是一些文件和文件夹，想要查看我们的页面\n    还需要点击文件夹点击文件才能查看，那么我们希望默认就能看到一个页面，而不是看到文件夹或者目录。\n    实现默认预览页面功能的步骤如下：\n        A.安装默认预览功能的包:html-webpack-plugin\n            npm install html-webpack-plugin -D\n        B.修改webpack.config.js文件，如下：\n            //导入包\n            const HtmlWebpackPlugin = require(\"html-webpack-plugin\");\n            //创建对象\n            const htmlPlugin = new HtmlWebpackPlugin({\n                //设置生成预览页面的模板文件\n                template:\"./src/index.html\",\n                //设置生成的预览页面名称\n                filename:\"index.html\"\n            })\n        C.继续修改webpack.config.js文件，添加plugins信息：\n            module.exports = {\n                ......\n                plugins:[ htmlPlugin ]\n            }\n\n### 11.webpack中的加载器\n    通过loader打包非js模块：默认情况下，webpack只能打包js文件，如果想要打包非js文件，需要调用loader加载器才能打包\n        loader加载器包含：\n            1).less-loader\n            2).sass-loader\n            3).url-loader:打包处理css中与url路径有关的文件\n            4).babel-loader:处理高级js语法的加载器\n            5).postcss-loader\n            6).css-loader,style-loader\n    \n    注意：指定多个loader时的顺序是固定的，而调用loader的顺序是从后向前进行调用\n    \n    A.安装style-loader,css-loader来处理样式文件\n        1).安装包\n            npm install style-loader css-loader -D\n        2).配置规则：更改webpack.config.js的module中的rules数组\n        module.exports = {\n            ......\n            plugins:[ htmlPlugin ],\n            module : {\n                rules:[\n                    {\n                        //test设置需要匹配的文件类型，支持正则\n                        test:/\\.css$/,\n                        //use表示该文件类型需要调用的loader\n                        use:[\'style-loader\',\'css-loader\']\n                    }\n                ]\n            }\n        }\n    B.安装less,less-loader处理less文件\n        1).安装包\n            npm install less-loader less -D\n        2).配置规则：更改webpack.config.js的module中的rules数组\n        module.exports = {\n            ......\n            plugins:[ htmlPlugin ],\n            module : {\n                rules:[\n                    {\n                        //test设置需要匹配的文件类型，支持正则\n                        test:/\\.css$/,\n                        //use表示该文件类型需要调用的loader\n                        use:[\'style-loader\',\'css-loader\']\n                    },\n                    {\n                        test:/\\.less$/,\n                        use:[\'style-loader\',\'css-loader\',\'less-loader\']\n                    }\n                ]\n            }\n        }\n    C.安装sass-loader,node-sass处理less文件\n        1).安装包\n            npm install sass-loader node-sass -D\n        2).配置规则：更改webpack.config.js的module中的rules数组\n        module.exports = {\n            ......\n            plugins:[ htmlPlugin ],\n            module : {\n                rules:[\n                    {\n                        //test设置需要匹配的文件类型，支持正则\n                        test:/\\.css$/,\n                        //use表示该文件类型需要调用的loader\n                        use:[\'style-loader\',\'css-loader\']\n                    },\n                    {\n                        test:/\\.less$/,\n                        use:[\'style-loader\',\'css-loader\',\'less-loader\']\n                    },\n                    {\n                        test:/\\.scss$/,\n                        use:[\'style-loader\',\'css-loader\',\'sass-loader\']\n                    }\n                ]\n            }\n        }\n    \n        补充：安装sass-loader失败时，大部分情况是因为网络原因，详情参考：\n        https://segmentfault.com/a/1190000010984731?utm_source=tag-newest\n    \n    D.安装post-css自动添加css的兼容性前缀（-ie-,-webkit-）\n    1).安装包\n        npm install postcss-loader autoprefixer -D\n    2).在项目根目录创建并配置postcss.config.js文件\n    const autoprefixer = require(\"autoprefixer\");\n    module.exports = {\n        plugins:[ autoprefixer ]\n    }\n    3).配置规则：更改webpack.config.js的module中的rules数组\n    module.exports = {\n        ......\n        plugins:[ htmlPlugin ],\n        module : {\n            rules:[\n                {\n                    //test设置需要匹配的文件类型，支持正则\n                    test:/\\.css$/,\n                    //use表示该文件类型需要调用的loader\n                    use:[\'style-loader\',\'css-loader\',\'postcss-loader\']\n                },\n                {\n                    test:/\\.less$/,\n                    use:[\'style-loader\',\'css-loader\',\'less-loader\']\n                },\n                {\n                    test:/\\.scss$/,\n                    use:[\'style-loader\',\'css-loader\',\'sass-loader\']\n                }\n            ]\n        }\n    }\n    \n    E.打包样式表中的图片以及字体文件\n    在样式表css中有时候会设置背景图片和设置字体文件，一样需要loader进行处理\n    使用url-loader和file-loader来处理打包图片文件以及字体文件\n    1).安装包\n        npm install url-loader file-loader -D\n    2).配置规则：更改webpack.config.js的module中的rules数组\n    module.exports = {\n        ......\n        plugins:[ htmlPlugin ],\n        module : {\n            rules:[\n                {\n                    //test设置需要匹配的文件类型，支持正则\n                    test:/\\.css$/,\n                    //use表示该文件类型需要调用的loader\n                    use:[\'style-loader\',\'css-loader\']\n                },\n                {\n                    test:/\\.less$/,\n                    use:[\'style-loader\',\'css-loader\',\'less-loader\']\n                },\n                {\n                    test:/\\.scss$/,\n                    use:[\'style-loader\',\'css-loader\',\'sass-loader\']\n                },{\n                    test:/\\.jpg|png|gif|bmp|ttf|eot|svg|woff|woff2$/,\n                    //limit用来设置字节数，只有小于limit值的图片，才会转换\n                    //为base64图片\n                    use:\"url-loader?limit=16940\"\n                }\n            ]\n        }\n    }\n    \n    F.打包js文件中的高级语法：在编写js的时候，有时候我们会使用高版本的js语法\n    有可能这些高版本的语法不被兼容，我们需要将之打包为兼容性的js代码\n    我们需要安装babel系列的包\n    A.安装babel转换器\n        npm install babel-loader @babel/core @babel/runtime -D\n    B.安装babel语法插件包\n        npm install @babel/preset-env @babel/plugin-transform-runtime @babel/plugin-proposal-class-properties -D\n    C.在项目根目录创建并配置babel.config.js文件\n        \n        module.exports = {\n            presets:[\"@babel/preset-env\"],\n            plugins:[ \"@babel/plugin-transform-runtime\", \"@babel/plugin-proposal-class-properties\" ]\n        }\n    D.配置规则：更改webpack.config.js的module中的rules数组\n    module.exports = {\n        ......\n        plugins:[ htmlPlugin ],\n        module : {\n            rules:[\n                {\n                    //test设置需要匹配的文件类型，支持正则\n                    test:/\\.css$/,\n                    //use表示该文件类型需要调用的loader\n                    use:[\'style-loader\',\'css-loader\']\n                },\n                {\n                    test:/\\.less$/,\n                    use:[\'style-loader\',\'css-loader\',\'less-loader\']\n                },\n                {\n                    test:/\\.scss$/,\n                    use:[\'style-loader\',\'css-loader\',\'sass-loader\']\n                },{\n                    test:/\\.jpg|png|gif|bmp|ttf|eot|svg|woff|woff2$/,\n                    //limit用来设置字节数，只有小于limit值的图片，才会转换\n                    //为base64图片\n                    use:\"url-loader?limit=16940\"\n                },{\n                    test:/\\.js$/,\n                    use:\"babel-loader\",\n                    //exclude为排除项，意思是不要处理node_modules中的js文件\n                    exclude:/node_modules/\n                }\n            ]\n        }\n    }\n\n### 12.Vue单文件组件\n传统Vue组件的缺陷：\n全局定义的组件不能重名，字符串模板缺乏语法高亮，不支持css(当html和js组件化时，css没有参与其中)\n没有构建步骤限制，只能使用H5和ES5，不能使用预处理器（babel）\n解决方案：\n使用Vue单文件组件，每个单文件组件的后缀名都是.vue\n每一个Vue单文件组件都由三部分组成\n1).template组件组成的模板区域\n2).script组成的业务逻辑区域\n3).style样式区域\n\n代码如下：\n\n```\n<template>\n\n    组件代码区域\n\n</template>\n\n<script>\n\n    js代码区域\n\n</script>\n\n<style scoped>\n\n    样式代码区域\n\n</style>\n```\n\n\n\n\n补充：安装Vetur插件可以使得.vue文件中的代码高亮\n\n配置.vue文件的加载器\nA.安装vue组件的加载器\n    npm install vue-loader vue-template-compiler -D\nB.配置规则：更改webpack.config.js的module中的rules数组\n    const VueLoaderPlugin = require(\"vue-loader/lib/plugin\");\n    const vuePlugin = new VueLoaderPlugin();\n    module.exports = {\n        ......\n        plugins:[ htmlPlugin, vuePlugin  ],\n        module : {\n            rules:[\n                ...//其他规则\n                { \n                    test:/\\.vue$/,\n                    loader:\"vue-loader\",\n                    \n                }\n            ]\n        }\n    }\n\n### 13.在webpack中使用vue\n上一节我们安装处理了vue单文件组件的加载器，想要让vue单文件组件能够使用，我们必须要安装vue\n并使用vue来引用vue单文件组件。\nA.安装Vue\n    npm install vue -S\nB.在index.js中引入vue：import Vue from \"vue\"\nC.创建Vue实例对象并指定el，最后使用render函数渲染单文件组件\n    const vm = new Vue({\n        el:\"#first\",\n        render:h=>h(app)\n    })\n\n### 14.使用webpack打包发布项目\n在项目上线之前，我们需要将整个项目打包并发布。\nA.配置package.json\n    \"scripts\":{\n        \"dev\":\"webpack-dev-server\",\n        \"build\":\"webpack -p\"\n    }\nB.在项目打包之前，可以将dist目录删除，生成全新的dist目录\n\n### 15.Vue脚手架\nVue脚手架可以快速生成Vue项目基础的架构。\nA.安装3.x版本的Vue脚手架：\n    npm install -g @vue/cli\nB.基于3.x版本的脚手架创建Vue项目：\n    1).使用命令创建Vue项目\n        命令：vue create my-project\n        选择Manually select features(选择特性以创建项目)\n        勾选特性可以用空格进行勾选。\n        是否选用历史模式的路由：n\n        ESLint选择：ESLint + Standard config\n        何时进行ESLint语法校验：Lint on save\n        babel，postcss等配置文件如何放置：In dedicated config files(单独使用文件进行配置)\n        是否保存为模板：n\n        使用哪个工具安装包：npm\n    2).基于ui界面创建Vue项目\n        命令：vue ui\n        在自动打开的创建项目网页中配置项目信息。\n    3).基于2.x的旧模板，创建Vue项目\n        npm install -g @vue/cli-init\n        vue init webpack my-project\n\nC.分析Vue脚手架生成的项目结构\n    node_modules:依赖包目录\n    public：静态资源目录\n    src：源码目录\n    src/assets:资源目录\n    src/components：组件目录\n    src/views:视图组件目录\n    src/App.vue:根组件\n    src/main.js:入口js\n    src/router.js:路由js\n    babel.config.js:babel配置文件\n    .eslintrc.js:\n\n### 16.Vue脚手架的自定义配置\n    A.通过 package.json 进行配置 [不推荐使用]\n        \"vue\":{\n            \"devServer\":{\n                \"port\":\"9990\",\n                \"open\":true\n            }\n        }\n    B.通过单独的配置文件进行配置，创建vue.config.js\n        module.exports = {\n            devServer:{\n                port:8888,\n                open:true\n            }\n        }\n\n\n### 17.Element-UI的基本使用\nElement-UI:一套基于2.0的桌面端组件库\n官网地址：http://element-cn.eleme.io/#/zh-CN\nA.安装：\n    npm install element-ui -S\nB.导入使用：\n    import ElementUI from \"element-ui\";\n    import \"element-ui/lib/theme-chalk/index.css\";\n    \n    Vue.use(ElementUI)\n', 1, 0, 0, 0, NULL, '2020-11-06', 1, '2020-11-06');
INSERT INTO `tb_article` VALUES (14, 28, 'SpringBoot Restful 风格Api开发+SpringBoot 集成Swagger', 'http://localhost:8888/cms/upload/948b0f3d-39f3-40c0-a1e8-e044fc2c74da.png', '引入restful 风格api后，post put delete请求方式在浏览器就不好操作了，此时我们可以选择下载一个测试工具Postman来辅助我们测试。但SpringBoot可以集成一个很强大的测试工具，可以很方便的测试接口。它就是传说中的Swagger', '', '', '## 一.Restful 风格API\nrestful API 命名禁止出现动词，即用请求方式区分动作。如下：\n\nget 查询接口\npost 新增接口\nput 更新接口\ndelete 删除接口\n1.maven-archetype-quickstart方式创建模块springboot-restful-api\n2.把springboot-ssm模块的代码和配置复制过来,不需要额外引入依赖。\n3.修改UserController代码，改成Restful接口\n@RestController\n@RequestMapping(\"/user\")\npublic class UserController {\n\n    @Resource\n    private UserMapper userMapper;\n\n    //@RequestMapping(\"/listByUser\")\n    @GetMapping(\"/\")\n    public List<User> listByUser() {\n        return userMapper.list();\n    }\n\n    //@RequestMapping(\"/getOneUser\")\n    @GetMapping(\"/{id}\")\n    public User getOneUser(@PathVariable(\"id\") int id) {\n        return userMapper.selectByPrimaryKey(id);\n    }\n\n    //@RequestMapping(\"/addUser\")\n    @PostMapping(\"/\")\n    public int addUser(User user) {\n        return userMapper.insert(user);\n    }\n\n    //@RequestMapping(\"/deleteUser\")\n    @DeleteMapping(\"/{id}\")\n    public int deleteUser(@PathVariable(\"id\") int id) {\n        return userMapper.deleteByPrimaryKey(id);\n    }\n\n    @PutMapping(\"/\")\n    public int updateUser(User user) {\n        return userMapper.updateByPrimaryKey(user);\n    }\n}\n4.运行测试，浏览器 http://localhost:8090/user/1\n测试\n\n测试\n5.引入restful 风格api后，post put delete请求方式在浏览器就不好操作了，此时我们可以选择下载一个测试工具Postman来辅助我们测试。但SpringBoot可以集成一个很强大的测试工具，可以很方便的测试接口。它就是传说中的Swagger\n## 二.SpringBoot 集成Swagger\n1.引入依赖\n<dependency>\n      <groupId>io.springfox</groupId>\n      <artifactId>springfox-swagger2</artifactId>\n      <version>2.9.2</version>\n    </dependency>\n    <dependency>\n      <groupId>io.springfox</groupId>\n      <artifactId>springfox-swagger-ui</artifactId>\n      <version>2.9.2</version>\n    </dependency>\n    \n2.创建配置类SwaggerConfig.java\n.apis(RequestHandlerSelectors.basePackage(\"xyz.java1024.controller\")) 对应controller所处的包\n\n\n3.浏览器进入api页面 地址为：http://localhost:8090/swagger-ui.html\nswagger-ui\n4.调用get请求接口\nswagger-ui\n5.对于实体类型的请求参数体，我们在Controller接口加上@RequestBody 可读性会更加好！\n修改前\n\n\nswagger-ui\n修改后\n\n\nswagger-ui\n    //@RequestMapping(\"/addUser\")\n    @PostMapping(\"/\")\n    public int addUser(@RequestBody User user) {\n        return userMapper.insert(user);\n    }\n重新启动刷新swagger-ui页面\n\n\nswagger-ui\n5.测试post请求\n把创建时间和更新时间参数去掉 ,填写用户名等参数，成功插入一条数据。\n\nswagger-ui\n6.swagger 增强\n对于实体的某些属性我们时不需要传的，并且我们不想它显示在swagger的请求体中，如 新增用户的 createdAt和updatedAt 等属性，我们可以通过在属性上面添加@ApiModelProperty(hidden = true)注解来隐藏属性\n\npublic class User implements Serializable {\n\n    private int id;\n\n    private String username;\n\n    private String tel;\n\n    private String password;\n\n    private int status;\n\n    @ApiModelProperty(hidden = true)\n    private Timestamp createdAt;\n\n    @ApiModelProperty(hidden = true)\n    private Timestamp updatedAt;\n    \n此时重启刷新swagger页面，再次进入UserController的post可看到少了参数，如图参数变得相当简洁！\n\n\nswagger-ui\n## 三.总结\n本文章，主要写了SpringBoot restful api开发，同时集成swagger测试接口！', 1, 0, 0, 0, NULL, '2020-11-07', 1, '2020-11-07');
INSERT INTO `tb_article` VALUES (15, 17, 'Spring框架常用注解简单介绍', 'http://localhost:8888/cms/upload/bf31738c-1706-495d-9532-f5c4857c2262.png', 'Spring框架是Java平台上的一种开源应用框架，提供具有控制反转特性的容器。Spring的核心思想是IOC和AOP。如果只是使用@RestController注解Controller，则Controller中的方法无法返回jsp页面，配置的视图解析器InternalResourceViewResolver不起作用，返回的内容就是Return 里的内容。例如：本来应该到success.jsp页面的，则其显示success.', '', '', '## Spring\nSpring框架是Java平台上的一种开源应用框架，提供具有控制反转特性的容器。Spring的核心思想是IOC和AOP。\n\n## Spring注解分类：\n1. 用于创建对象的\n2. 用于注入数据的\n3. 用于改变作用范围的\n4. 和生命周期相关的（了解）\n## （一）用于创建对象的注解\n`@Component` 注解\n相当于 bean 标签，value属性用于指定id，如果不写，默认是当前类名首字母小写。\n\n由此注解衍生出来的三个注解：\n\n@Controller：用于控制器，表现层\n@Service：用于业务层\n@Repository：用于持久层，Dao层\n它们的作用、属性和 @Component 是一模一样的。它们的出现是Spring框架为我们提供更明确的语义话来指定不同层的bean对象。\n\n@Controller和@RestController的区别？\n@RestController注解相当于@ResponseBody ＋ @Controller合在一起的作用。\n\n如果只是使用@RestController注解Controller，则Controller中的方法无法返回jsp页面，配置的视图解析器InternalResourceViewResolver不起作用，返回的内容就是Return 里的内容。例如：本来应该到success.jsp页面的，则其显示success.\n如果需要返回到指定页面，则需要用 @Controller配合视图解析器InternalResourceViewResolver才行。\n如果需要返回JSON，XML或自定义mediaType内容到页面，则需要在对应的方法上加上@ResponseBody注解。\n（二）用于注入数据的注解\n用于注入bean类型\n\n@Autowired 注解\n作用：自动按照类型注入。只要Spring容器中有唯一的类型匹配，就可以注入成功。如果没有匹配的类型就报错。\n如果有多个类型匹配时，就用变量名称作为bean的id，再容器中查找，如果找到，就注入成功。没有找到就报错。\n\n属性：\nrequired：\n取值为true时，如果没有匹配的对象，就报错。（默认值）\n取值为false时，如果没有匹配的对象，不会报错。\n\n@Qualifier 注解\n作用：在自动按照类型注入的基础上，在按照bean的id注入。如果有多个类型匹配，就按照id注入。\n\n属性：\nvalue：用于指定bean的id\n\n@Resource 注解\n作用：直接按照bean的id注入\n\n属性：\nvalue：用于指定bean的id\n\n以上三个注解，都只能用于注入bean类型，而不能用于注入基本类型、String类型和复杂类型。\n\n@Value 注解\n作用：用于注入基本类型、String类型\n\n属性：\nvalue：用于指定要注入的数据，它支持使用 Spring 的 EL 表达式（Spring 的 EL 表达式：${表达式}）\n\n（三）用于改变作用范围的注解\n@Scope 注解\n作用：用于改变bean的作用范围\n\n取值：\n\nsingleton：单例。（默认）（常用）\nprototype：多例\nrequest：请求范围\nsession：会话范围\nglobal-session：全局会话范围\n（四）和生命周期相关的注解（了解）\n@PostContruct 注解\n作用：用于指定初始化方法。\n\n@PreDestroy 注解\n作用：用于指定销毁方法。\n\n示例代码\n\n//@Component(value = \"accountService\")\n@Service(value = \"accountService\")\n@Scope(\"singleton\")\npublic class AccountServiceImpl implements IAccountService {\n    \n//    @Autowired\n//    @Qualifier(\"accountDao\")\n    @Resource(name = \"accountDao\")\n    private IAccountDao dao;\n\n//    @Value(\"com.mysql.cj.jdbc.Driver\")\n    @Value(\"${driverClass}\")\n    private String driver;\n    \n    @PostConstruct\n    public void init() {\n        System.out.println(\"--- init ---\");\n    }\n    \n    @PreDestroy\n    public void destroy() {\n        System.out.println(\"--- destroy ---\");\n    }\n\n    @Override\n    public void saveAccount() {\n        dao.saveAccount();\n        System.out.println(driver);\n    }\n}\n', 1, 0, 0, 0, NULL, '2020-11-07', 1, '2020-11-07');
INSERT INTO `tb_article` VALUES (16, 34, 'Spring、spring mvc、spring boot、spring cloud之间的关系', 'http://localhost:8888/cms/upload/5910ebe6-07e8-4119-bebd-6ec7fc2de303.png', 'Rod Johnson在2002年的时候出版了《Expert One-on-One J2EE Design and Development》一书，在这本书里面，提出了经典的控制反转（IOC）和面向切面（AOP），也是以后spring容器的主要核心。居于这本书里面的高度可重用的大部分基础架构代码，Rod Johnson在2004年发布了spring 1.0, 正式开始了spring的历史篇章', '', '', '## spring\nRod Johnson在2002年的时候出版了《Expert One-on-One J2EE Design and Development》一书，在这本书里面，提出了经典的控制反转（IOC）和面向切面（AOP），也是以后spring容器的主要核心。居于这本书里面的高度可重用的大部分基础架构代码，Rod Johnson在2004年发布了spring 1.0, 正式开始了spring的历史篇章。《Expert one on one J2EE development without EJB》正是在这之后的一部力作，多少年以后，我们重新审视这本书时，会记起这本书曾经如何引领了J2EE开发框架的潮流。\n\n简单的说，spring 是一个 轻量级的控制反转（IoC）和面向切面（AOP）的容器 。\n\n## spring mvc\nspring mvc是基于spirng的一个MVC模型的web开发框架实现，拥有spring的特性，可以替代struts2、webwork等其他的MVC框架。\n\n## spring boot\n在利用spring 基础框架搭建项目结构时，需要整合很多的第三方的框架，比如redis、rabbit mq等，大量的xml以及繁琐的配置，让开发人员苦不堪言，急需一种解决方案来解决这个问题。Spring boot是Pivotal团队开发的全新框架，最大的特点是采用约定大于配置的理念，只要约定了某种命名规范，无需配置，就可以完成大部分框架的整合，让开发人员从以前繁琐的配置中解脱出来，专注于业务功能的开发。\n\n## spring cloud\nspring cloud 是一套基于spring boot实现的分布式服务治理的框架，提供了服务注册和发现、负载均衡、熔断和限流、服务路由、配置中心、消息总线、服务调用链路监控等功能组件，这些组件大量整合了第三方已有成熟的框架，尤其是Spring Cloud Netflix, 它将 Netflix 公司的微服务框架集合封装了一下，提供了生产可用的组件。spring cloud实现是基于spring boot的，但是spring boot可以单独开发项目。\n', 1, 0, 0, 0, NULL, '2020-11-07', 1, '2020-11-07');
INSERT INTO `tb_article` VALUES (17, 34, '一定要面试才刷面试题？Spring160道面试题+Spring书籍助你学Spring', 'http://localhost:8888/cms/upload/bba319d3-400c-43ad-9f2f-7ca1be781909.png', '虽名为\"面试题\"，但一定要面试前才刷面试题嘛？其实在日常工作中多刷一些面试题对自己也是挺有帮助的！为此笔者收集了160道Spring中高级面试题给大家学习，查漏补缺！', '', '', '## 一、Spring 面试题（基础篇）\n什么是 spring?\n使用 Spring 框架的好处是什么？\nSpring 由哪些模块组成?\n核心容器（应用上下文) 模块。\nBeanFactory – BeanFactory 实现举例。\nXMLBeanFactory\n解释 AOP 模块\n解释 JDBC 抽象和 DAO 模块。\n解释对象/关系映射集成模块。\n解释 WEB 模块。\nSpring 配置文件\n什么是 Spring IOC 容器？\nIOC 的优点是什么？\nApplicationContext 通常的实现是什么?\nBean 工厂和 Application contexts 有什么区别？\n一个 Spring 的应用看起来象什么？\n什么是 Spring 的依赖注入？\n有哪些不同类型的 IOC（依赖注入）方式？\n哪种依赖注入方式你建议使用，构造器注入，还是 Setter 方法注入？\n什么是 Spring beans?\n一个 Spring Bean 定义 包含什么？\n你怎样定义类的作用域?\n解释 Spring 支持的几种 bean 的作用域。\nSpring 框架中的单例 bean 是线程安全的吗?\n解释 Spring 框架中 bean 的生命周期。\n哪些是重要的 bean 生命周期方法？\n什么是 Spring 的内部 bean？\n在 Spring 中如何注入一个 java 集合？\n什么是 bean 装配?\n什么是 bean 的自动装配？\n解释不同方式的自动装配 。\n自动装配有哪些局限性 ?\n你可以在 Spring 中注入一个 null 和一个空字符串吗？\n什么是基于 Java 的 Spring 注解配置?\n什么是基于注解的容器配置?\n怎样开启注解装配？\n@Required 注解\n@Autowired 注解\n@Qualifier 注解\n在 Spring 框架中如何更有效地使用 JDBC?\nJdbcTemplate\nSpring 对 DAO 的支持\n使用 Spring 通过什么方式访问 Hibernate?\nSpring 支持的 ORM\n如何通过 HibernateDaoSupport 将 Spring 和 Hibernate 结合起来？\nSpring 支持的事务管理类型\nSpring 框架的事务管理有哪些优点？\n你更倾向用那种事务管理类型？\n解释 AOP\nAspect 切面\n在 Spring AOP 中，关注点和横切关注的区别是什 么？\n连接点\n通知\n切点\n什么是引入?\n什么是目标对象?\n什么是代理?\n有几种不同类型的自动代理？\n什么是织入。什么是织入应用的不同点？\n解释基于 XML Schema 方式的切面实现。\n解释基于注解的切面实现\n什么是 Spring 的 MVC 框架？\nDispatcherServlet\nWebApplicationContext\n什么是 Spring MVC 框架的控制器？\n@Controller 注解\n@RequestMapping 注解\n部分参考答案\n\n1. 什么是 spring?\n\nSpring 是个 java 企业级应用的开源开发框架。Spring 主要用来开发 Java 应用，但是有些扩展是针对构建 J2EE 平台的 web 应用。Spring 框架目标是简化 Java 企业级应用开发，并通过 POJO 为基础的编程模型促进 良好的编程习惯。\n\n2. 使用 Spring 框架的好处是什么？\n\n轻量：Spring 是轻量的，基本的版本大约 2MB。\n控制反转：Spring 通过控制反转实现了松散耦合，对象 们给出它们的依赖，而不是创建或查找依赖的对象们。\n面向切面的编程(AOP)：Spring 支持面向切面的编程， 并且把应用业务逻辑和系统服务分开。\n容器：Spring 包含并管理应用中对象的生命周期和配 置。\nMVC 框架：Spring 的 WEB 框架是个精心设计的框架， 是 Web 框架的一个很好的替代品。\n事务管理：Spring 提供一个持续的事务管理接口，可以 扩展到上至本地事务下至全局事务（JTA）。\n异常处理：Spring 提供方便的 API 把具体技术相关的异 常（比如由 JDBC，Hibernate or JDO 抛出的）转化为 一致的 unchecked 异常。\n3. Spring 由哪些模块组成?\n\n以下是 Spring 框架的基本模块：\n\nCore module\nBean module\nContext module\nExpression Language module\nJDBC module\nORM module\nOXM module\nJava Messaging Service(JMS) module\nTransaction module\nWeb module\nWeb-Servlet module\nWeb-Struts module\nWeb-Portlet module\n4. 核心容器（应用上下文) 模块。\n\n这是基本的 Spring 模块，提供 spring 框架的基础功 能，BeanFactory 是 任何以 spring 为基础的应用的核 心。Spring 框架建立在此模块之上，它使 Spring 成为 一个容器。\n\n5. BeanFactory – BeanFactory 实现举例。\n\nBean 工厂是工厂模式的一个实现，提供了控制反转功 能，用来把应用的配置和依赖从正真的应用代码中分 离。最常用的 BeanFactory 实现是 XmlBeanFactory 类。\n\n## 二、Spring面试题（高级篇）\n什么是 Spring 框架？Spring 框架有哪些主要模块？\n使用 Spring 框架能带来哪些好处？\n什么是控制反转(IOC)？什么是依赖注入？\n请解释下 Spring 框架中的 IoC？\nBeanFactory 和 ApplicationContext 有什么区别？\nSpring 有几种配置方式？\n如何用基于 XML 配置的方式配置 Spring？\n如何用基于 Java 配置的方式配置 Spring？\n怎样用注解的方式配置 Spring？\n请解释 Spring Bean 的生命周期？\nSpring Bean 的作用域之间有什么区别？\n什么是 Spring inner beans？\nSpring 框架中的单例 Beans 是线程安全的么？\n请举例说明如何在 Spring 中注入一个 Java Collection？\n如何向 Spring Bean 中注入一个 Java.util.Properties？\n请解释 Spring Bean 的自动装配？\n请解释自动装配模式的区别？\n如何开启基于注解的自动装配？\n请举例解释@Required 注解？\n请举例解释@Autowired 注解？\n请举例说明@Qualifier 注解？\n构造方法注入和设值注入有什么区别？\nSpring 框架中有哪些不同类型的事件？\nFileSystemResource 和 ClassPathResource 有何区别？\nSpring 框架中都用到了哪些设计模式？\n部分参考答案\n\n1. 什么是 Spring 框架？Spring 框架有哪些主要模块？\n\nSpring 框架是一个为 Java 应用程序的开发提供了综合、广泛的基础性支持的 Java 平台。Spring 帮助开发者解决了开发中基础性的问题，使得开发人员可以专注于应用程序的开发。Spring 框架本身亦是按照设计模式精心打造，这使得我们可以在开发环境中安心的集成 Spring 框架，不必担心 Spring 是如何在后台进行工作的。\n\n2. Spring 有几种配置方式？\n\n将 Spring 配置到应用开发中有以下三种方式：\n\n基于 XML 的配置\n基于注解的配置\n基于 Java 的配置\n3. 请解释 Spring Bean 的自动装配？\n\n在 Spring 框架中，在配置文件中设定 bean 的依赖关系是一个很好的机制，Spring 容器还可以自动装配合作关系 bean 之间的关联关系。这意味着 Spring 可以通过向 Bean Factory 中注入的方式自动搞定 bean 之间的依赖关系。自动装配可以设置在每个 bean 上，也可以设定在特定的 bean 上。\n\n4. Spring 框架中有哪些不同类型的事件？\n\nSpring 的 ApplicationContext 提供了支持事件和代码中监听器的功能。 我们可以创建 bean 用来监听在ApplicationContext 中发布的事件。ApplicationEvent 类和在 ApplicationContext 接口中处理的事件，如果一个 bean实现了 ApplicationListener 接口，当一个 ApplicationEvent 被发布以后，bean 会自动被通知。\n\n5. Spring 框架中都用到了哪些设计模式？\n\nSpring 框架中使用到了大量的设计模式，下面列举了比较有代表性的：\n\n代理模式——在 AOP 和 remoting 中被用的比较多。\n单例模式——在 spring 配置文件中定义的 bean 默认为单例模 式。\n模板方法——用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。\n前端控制器——Spring 提供了 DispatcherServlet 来对请求进行 分发。\n视图帮助(View Helper )——Spring 提供了一系列的 JSP 标签， 高效宏来辅助将分散的代码整合在视图里。\n依赖注入——贯穿于 BeanFactory / ApplicationContext 接口 的核心理念。\n工厂模式——BeanFactory 用来创建对象的实例。\n## 三、Spring面试题（进阶篇）\n谈谈你对 spring IOC 和 DI 的理解，它们有什么区别？\nBeanFactory 接口和 ApplicationContext 接口有什么区\n别 ？\nspring 配置 bean 实例化有哪些方式？\n简单的说一下 spring 的生命周期？\n请介绍一下 Spring 框架中 Bean 的生命周期和作用域\nBean 注入属性有哪几种方式？\n什么是 AOP，AOP 的作用是什么？\nSpring 的核心类有哪些，各有什么作用？\nSpring 里面如何配置数据库驱动？\nSpring 里面 applicationContext.xml 文件能不能改成其他\n文件名？\nSpring 里面如何定义 hibernate mapping？\nSpring 如何处理线程并发问题？\n为什么要有事物传播行为？\n介 绍 一 下 Spring 的 事 物 管 理\n解释一下 Spring AOP 里面的几个名词\n通知有哪些类型？\n部分参考答案\n\n1. 谈谈你对 spring IOC 和 DI 的理解，它们有什么区别？\n\nIoC控制反转，指将对象的创建权，反转到Spring容器，DI依赖注入，指Spring创建对象的过程中，将对象依赖属性通过配置进行注入\n\n2. Bean 注入属性有哪几种方式？\n\nspring支持构造器注入和setter方法注入构造器注入，通过元素完成注入setter方法注入，通过元素完成注入【开发中常用方式】\n\n3. 什么是 AOP，AOP 的作用是什么？\n\n面向切面编程( AOP)提供另外一种角度来思考程序结构，通过这种方式弥补了面向对象编程( OOP)的不足，除了类( classes )以外，AOP提供了切面。切面对关注点进行模块化，例如横切多个类型和对象的事务管理\n\nSpring的一个关键的组件就是AOP框架，可以自由选择是否使用AOP提供声明式企业服务，特别是为了替代EJB声明式服务。最重要的服务是声明性事务管理，这个服务建立在Spring 的抽象事物管理之上。允许用户实现自定义切面，用AOP来完善OOP的使用,可以把Spring AOP看作是对Spring的一种增强\n\n4. Spring的核心类有哪些，各有什么作用?\n\nBeanFactory——产生一个新的实例，可以实现单例模式\nBeanWrapper——提供统一的get及set方法\nApplicationContext——提供框架的实现，包括BeanFactory的所有功能\n## 四、Spring Boot面试题\n什么是 Spring Boot？\nSpring Boot 有哪些优点？\n什么是 JavaConfig？\n如何重新加载 Spring Boot 上的更改，而无需重新启动服务器？\nSpring Boot 中的监视器是什么？\n如何在 Spring Boot 中禁用 Actuator 端点安全性？\n如何在自定义端口上运行 Spring Boot 应用程序？\n什么是 YAML？\n如何实现 Spring Boot 应用程序的安全性？\n如何集成 Spring Boot 和 ActiveMQ？\n如何使用 Spring Boot 实现分页和排序？\n什么是 Swagger？你用 Spring Boot 实现了它吗？\n什么是 Spring Profiles？\n什么是 Spring Batch？\n什么是 FreeMarker 模板？\n如何使用 Spring Boot 实现异常处理？\n您使用了哪些 starter maven 依赖项？\n什么是 CSRF 攻击？\n什么是 WebSockets？\n什么是 AOP？\n什么是 Apache Kafka？\n我们如何监视所有 Spring Boot 微服务？\n部分参考答案\n\n1. 什么是 Spring Boot？\n\n多年来，随着新功能的增加，spring 变得越来越复杂。只需访问 https://spring.io/projects 页面，我们就会看到可以在我们的应用程序中使用的所有 Spring 项目的不同功能。如果必 须启动一个新的 Spring 项目，我们必须添加构建路径或添加 Maven 依赖关系，配置应用程 序服务器，添加 spring 配置。因此，开始一个新的 spring 项目需要很多努力，因为我们现 在必须从头开始做所有事情。\n\nSpring Boot 是解决这个问题的方法。Spring Boot 已经建立在现有 spring 框架之上。使用 spring 启动，我们避免了之前我们必须做的所有样板代码和配置。因此，Spring Boot 可以 帮助我们以最少的工作量，更加健壮地使用现有的 Spring 功能。\n\n2. Spring Boot 中的监视器是什么？\n\nSpring boot actuator 是 spring 启动框架中的重要功能之一。Spring boot 监视器可帮助您访 问生产环境中正在运行的应用程序的当前状态。有几个指标必须在生产环境中进行检查和 监控。即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息。监视器 模块公开了一组可直接作为 HTTP URL 访问的 REST 端点来检查状态。\n\n3. 如何在 Spring Boot 中禁用 Actuator 端点安全性？\n\n默认情况下，所有敏感的 HTTP 端点都是安全的，只有具有 ACTUATOR 角色的用户才能访 问它们。安全性是使用标准的 HttpServletRequest.isUserInRole方法实施的。 我们可以使用\nmanagement.security.enabled = false来禁用安全性。只有在执行机构端点在防火墙后访问时，才建议禁用安全性。\n\n4. 如何实现 Spring Boot 应用程序的安全性？\n\n为了实现 Spring Boot 的安全性，我们使用 spring-boot-starter-security 依赖项，并且必须添 加安全配置。它只需要很少的代码。配置类将必须扩展 WebSecurityConfigurerAdapter 并覆 盖其方法。\n\n5. 如何集成 Spring Boot 和 ActiveMQ？\n\n对于集成 Spring Boot 和 ActiveMQ，我们使用spring-boot-starter-activemq 依赖关系。 它只需要很少的配置，并且不需要样板代码。\n\n## 五、Spring Cloud面试题\n什么是Spring Cloud？\n使用Spring Cloud有什么优势？\n服务注册和发现是什么意思？Spring Cloud如何实现？\n负载平衡的意义什么？\n什么是Hystrix？它如何实现容错？\n什么是Hystrix断路器？我们需要它吗？\n什么是Netflix Feign？它的优点是什么？\n什么是Spring Cloud Bus？我们需要它吗？\n部分参考答案\n\n1. 什么是Spring Cloud？\n\nSpring cloud流应用程序启动器是基于Spring Boot的Spring集成应用程序，提供与外部系统的集成。 Spring cloud Task，一个生命周期短暂的微服务框架，用于快速构建执行有限数据处理的应用程序。\n\n2. 服务注册和发现是什么意思？Spring Cloud如何实现？\n\n当我们开始一个项目时，我们通常在属性文件中进行所有的配置。随着越来越多的服务开发和部署，添加 和修改这些属性变得更加复杂。有些服务可能会下降，而某些位置可能会发生变化。手动更改属性可能会 产生问题。 Eureka服务注册和发现可以在这种情况下提供帮助。由于所有服务都在Eureka服务器上注 册并通过调用Eureka服务器完成查找，因此无需处理服务地点的任何更改和处理。\n\n3. 负载平衡的意义什么？\n\n在计算中，负载平衡可以改善跨计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器等多种计算 资源的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一资源 的过载。使用多个组件进行负载平衡而不是单个组件可能会通过冗余来提高可靠性和可用性。负载平衡通 常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。\n\n## 六、Spring MVC面试题\n什么是 SpringMvc？\nSpring MVC 的优点？\nSpringMVC 工作原理？\nSpringMVC 流程？\nSpringMvc 的控制器是不是单例模式,如果是,有什么问题,怎么解决？\n如果你也用过 struts2.简单介绍下 springMVC 和 struts2 的区别有哪些?\nSpingMvc 中的控制器的注解一般用那个,有没有别的注解可以替代？\n@RequestMapping 注解用在类上面有什么作用？\n怎么样把某个请求映射到特定的方法上面？\n如果在拦截请求中,我想拦截 get 方式提交的方法,怎么配置？\n怎么样在方法里面得到 Request,或者 Session？\n我想在拦截的方法里面得到从前台传入的参数,怎么得到？\n如果前台有很多个参数传入,并且这些参数都是一个对象的,那么怎么样快速得到这个对 象？\nSpringMvc 中函数的返回值是什么？\nSpringMVC 怎么样设定重定向和转发的？\nSpringMvc 用什么对象从后台向前台传递数据的？\nSpringMvc 中有个类把视图和数据都合并的一起的,叫什么？\n怎么样把 ModelMap 里面的数据放入 Session 里面？\nSpringMvc 怎么和 AJAX 相互调用的？\n当一个方法向 AJAX 返回特殊对象,譬如 Object,List 等,需要做什么处理？\nSpringMvc 里面拦截器是怎么写的\n讲下 SpringMvc 的执行流程\n部分参考答案\n\n1. 什么是 SpringMvc？\n\nSpringMvc 是 spring 的一个模块，基于 MVC 的一个框架，无需中间整合层来整合\n\n2. SpringMVC 工作原理？\n\n客户端发送请求到 DispatcherServlet\nDispatcherServlet 查询 handlerMapping 找到处理请求的 Controller\nController 调用业务逻辑后，返回 ModelAndView\nDispatcherServlet 查询 ModelAndView，找到指定视图\n视图将结果返回到客户端\n3. SpringMvc 的控制器是不是单例模式,如果是,有什么问题,怎么解决？\n\n是单例模式,所以在多线程访问的时候有线程安全问题,不要用同步,会影响性能的,解决 方案是在控制器里面不能写字段\n\n4. SpingMvc 中的控制器的注解一般用那个,有没有别的注解可以替代？\n\n一般用@Conntroller 注解,表示是表现层,不能用用别的注解代替。\n\n5. @RequestMapping 注解用在类上面有什么作用？\n\n是一个用来处理请求地址映射的注解，可用于类或方法上。用于类上，表示类中的所 有响应请求的方法都是以该地址作为父路径。\n', 1, 0, 0, 0, NULL, '2020-11-07', 1, '2020-11-07');
INSERT INTO `tb_article` VALUES (18, 18, '【MyBatis】 MyBatis修炼之三 MyBatis XML方式的基本用法', '', '我们通过一个简单的权限控制需求（RABC，Role-Based Access Control，基于角色的访问控制），来讲解通过XML方式配置MyBatis的基本用法（即select、update、insert、delete等操作的XML配置方式）', '管理员', '', '## 工具\nJDK 1.6及以上版本\nMyBatis 3.30版本\nMySQL 6.3版本\nEclipse4 及以上版本\nApache Maven 构建工具\n\n## 权限控制需求\n一个用户拥有若干个角色，一个角色拥有若干权限，权限就是对某个资源的（模块）的某种操作（增、删、改、查），这样就构成了“用户--角色--权限”的授权模型。在这种模型中，用户与角色之间、角色与权限之间，一般是多对多的关系。\n\n\n\n创建数据库表\n首先我们需要创建五个表：用户表、角色表、权限表、用户角色关系表、角色权限关系表。在已经创建好的mybatis数据库中执行如下SQL脚本：\n\n#创建数据库，并制定编码格式为UTF-8\nCREATE DATABASE mybatis DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;\n\n#切换数据库到mybatis\nuse mybatis;\n\n#创建用户表\ncreate table sys_user(\n    id bigint not null auto_increment comment \'用户ID\',\n    user_name varchar(50) comment \'用户名\',\n    user_password varchar(50) comment \'密码\',\n    user_email varchar(50) comment \'邮箱\',\n    user_info text comment \'简介\',\n    head_img blob comment \'头像\',\n    create_time datetime comment \'创建时间\',\n    primary key (id)\n    \n);\nalter table sys_user comment \'用户表\';\n\n#创建角色表\ncreate table sys_role(\n    id bigint not null auto_increment comment \'角色ID\',\n    role_name varchar(50) comment \'角色名\',\n    enabled int comment \'有效标志\',\n    create_by bigint comment \'创建人\',\n    create_time datetime comment \'创建时间\',\n    primary key (id)\n);\nalter table sys_role comment \'角色表\';\n\n#创建权限表\ncreate table sys_privilege(\n    id bigint not null auto_increment comment \'权限ID\',\n    privilege_name varchar(50) comment \'权限名称\',\n    privilege_uri varchar(200) comment \'权限URL\',\n    primary key (id)\n);\nalter table sys_privilege comment \'权限表\';\n\n#创建用户角色关系表\ncreate table sys_user_role(\n    user_id bigint comment \'用户ID\',\n    role_id bigint comment \'角色ID\'\n);\nalter table sys_user_role comment \'用户角色关联表\';\n\n#创建角色权限关系表\ncreate table sys_role_privilege(\n    role_id bigint comment \'角色ID\',\n    privilege bigint comment \'权限ID\'\n);\nalter table sys_role_privilege comment \'角色权限关联表\';\n\n##测试数据\ninsert into sys_user(id,user_name, user_password, user_email, user_info, head_img, create_time) \nvalues(1,\'admin\',\'123456\',\'admin@mybais.alex\',\'管理员\',null,\'2017-8-09 15:26:52\'),\n(2,\'test\',\'123456\',\'test@mybais.alex\',\'测试用户\',null,\'2017-8-09 15:27:30\');\n\ninsert into sys_role(id,role_name, enabled, create_by, create_time) \nvalues(1,\'管理员\',\'1\',\'1\',\'2017-8-09 15:26:52\'),(2,\'普通用户\',\'1\',\'1\',\'2017-8-09 15:26:52\');\n\ninsert into sys_privilege(id,privilege_name, privilege_uri)\nvalues(1,\'用户管理\',\'/users\'),(2,\'角色管理\',\'/roles\'),(3,\'系统日志\',\'/logs\'),(4,\'人员维护\',\'/persons\'),(5,\'部门维护\',\'/companies\');\n\ninsert into sys_user_role values(1,1),(1,2),(2,2);\ninsert into sys_role_privilege values(1,1),(1,2),(1,3),(2,4),(2,5);\n此处没有创建表之间的外键关系。对于表之间的关系，我们可以通过业务逻辑来进行限制。\n\n创建实体类\nMyBatis默认遵循“下划线转驼峰”命名方式，所以在创建实体类时一般都按照这种方式进行创建。而具体采用什么命名方式并不重要，在我们使用对象的时候，可以通过resultMap对数据库的列和类的字段配置隐射关系。\n\n用户类SysUser\n\npackage mybatis.simple.model;\n\nimport java.util.Arrays;\nimport java.util.Date;\n\npublic class SysUser {\n\n    private Long id;\n    private String userName;\n    private String userPassword;\n    private String userEmail;\n    private String userInfo;\n    private byte[] headImg;\n    private Date createTime;\n\n    public SysUser() {\n        super();\n    }\n\n    public SysUser(Long id, String userName, String userPassword, String userEmail, String userInfo, byte[] headImg,\n            Date createTime) {\n        super();\n        this.id = id;\n        this.userName = userName;\n        this.userPassword = userPassword;\n        this.userEmail = userEmail;\n        this.userInfo = userInfo;\n        this.headImg = headImg;\n        this.createTime = createTime;\n    }\n\n    public Long getId() {\n        return id;\n    }\n\n    public void setId(Long id) {\n        this.id = id;\n    }\n\n    public String getUserName() {\n        return userName;\n    }\n\n    public void setUserName(String userName) {\n        this.userName = userName;\n    }\n\n    public String getUserPassword() {\n        return userPassword;\n    }\n\n    public void setUserPassword(String userPassword) {\n        this.userPassword = userPassword;\n    }\n\n    public String getUserEmail() {\n        return userEmail;\n    }\n\n    public void setUserEmail(String userEmail) {\n        this.userEmail = userEmail;\n    }\n\n    public String getUserInfo() {\n        return userInfo;\n    }\n\n    public void setUserInfo(String userInfo) {\n        this.userInfo = userInfo;\n    }\n\n    public byte[] getHeadImg() {\n        return headImg;\n    }\n\n    public void setHeadImg(byte[] headImg) {\n        this.headImg = headImg;\n    }\n\n    public Date getCreateTime() {\n        return createTime;\n    }\n\n    public void setCreateTime(Date createTime) {\n        this.createTime = createTime;\n    }\n\n    @Override\n    public String toString() {\n        return \"SysUser [id=\" + id + \", userName=\" + userName + \", userPassword=\" + userPassword + \", userEmail=\"\n                + userEmail + \", userInfo=\" + userInfo + \", headImg=\" + Arrays.toString(headImg) + \", createTime=\"\n                + createTime + \"]\";\n    }\n\n}\n\n角色类SysRole\n\npackage mybatis.simple.model;\n\nimport java.sql.Date;\n\npublic class SysRole {\n    private Long id;\n    private String role_name;\n    private Integer enabled;\n    private Long create_by;\n    private Date create_time;\n\n    public SysRole() {\n        super();\n    }\n\n    public SysRole(Long id, String role_name, Integer enabled, Long create_by, Date create_time) {\n        super();\n        this.id = id;\n        this.role_name = role_name;\n        this.enabled = enabled;\n        this.create_by = create_by;\n        this.create_time = create_time;\n    }\n\n    public Long getId() {\n        return id;\n    }\n\n    public void setId(Long id) {\n        this.id = id;\n    }\n\n    public String getRole_name() {\n        return role_name;\n    }\n\n    public void setRole_name(String role_name) {\n        this.role_name = role_name;\n    }\n\n    public Integer getEnabled() {\n        return enabled;\n    }\n\n    public void setEnabled(Integer enabled) {\n        this.enabled = enabled;\n    }\n\n    public Long getCreate_by() {\n        return create_by;\n    }\n\n    public void setCreate_by(Long create_by) {\n        this.create_by = create_by;\n    }\n\n    public Date getCreate_time() {\n        return create_time;\n    }\n\n    public void setCreate_time(Date create_time) {\n        this.create_time = create_time;\n    }\n\n    @Override\n    public String toString() {\n        return \"SysRole [id=\" + id + \", role_name=\" + role_name + \", enabled=\" + enabled + \", create_by=\" + create_by\n                + \", create_time=\" + create_time + \"]\";\n    }\n\n}\n\n权限类SysPrivilege\n\npackage mybatis.simple.model;\n\npublic class SysPrivilege {\n\n    private Long id;\n    private String privilege_name;\n    private String privilege_uri;\n\n    public SysPrivilege() {\n        super();\n    }\n\n    public SysPrivilege(Long id, String privilege_name, String privilege_uri) {\n        super();\n        this.id = id;\n        this.privilege_name = privilege_name;\n        this.privilege_uri = privilege_uri;\n    }\n\n    public Long getId() {\n        return id;\n    }\n\n    public void setId(Long id) {\n        this.id = id;\n    }\n\n    public String getPrivilege_name() {\n        return privilege_name;\n    }\n\n    public void setPrivilege_name(String privilege_name) {\n        this.privilege_name = privilege_name;\n    }\n\n    public String getPrivilege_uri() {\n        return privilege_uri;\n    }\n\n    public void setPrivilege_uri(String privilege_uri) {\n        this.privilege_uri = privilege_uri;\n    }\n\n    @Override\n    public String toString() {\n        return \"SysPrivilege [id=\" + id + \", privilege_name=\" + privilege_name + \", privilege_uri=\" + privilege_uri\n                + \"]\";\n    }\n\n}\n\n用户角色关系类SysUserRole\n\npackage mybatis.simple.model;\n\npublic class SysUserRole {\n    private Long user_id;\n    private Long role_id;\n\n    public SysUserRole() {\n        super();\n    }\n\n    public SysUserRole(Long user_id, Long role_id) {\n        super();\n        this.user_id = user_id;\n        this.role_id = role_id;\n    }\n\n    public Long getUser_id() {\n        return user_id;\n    }\n\n    public void setUser_id(Long user_id) {\n        this.user_id = user_id;\n    }\n\n\n    public Long getRole_id() {\n        return role_id;\n    }\n\n    public void setRole_id(Long role_id) {\n        this.role_id = role_id;\n    }\n\n    @Override\n    public String toString() {\n        return \"SysUserRole [user_id=\" + user_id + \", role_id=\" + role_id + \"]\";\n    }\n}\n\n角色权限关系类\n\npackage mybatis.simple.model;\n\npublic class SysRolePrivilege {\n    private Long role_id;\n    private Long privilege;\n\n    public SysRolePrivilege() {\n        super();\n    }\n\n    public SysRolePrivilege(Long role_id, Long privilege) {\n        super();\n        this.role_id = role_id;\n        this.privilege = privilege;\n    }\n\n    public Long getRole_id() {\n        return role_id;\n    }\n\n    public void setRole_id(Long role_id) {\n        this.role_id = role_id;\n    }\n\n    public Long getPrivilege() {\n        return privilege;\n    }\n\n    public void setPrivilege(Long privilege) {\n        this.privilege = privilege;\n    }\n\n    @Override\n    public String toString() {\n        return \"SysRolePrivilege [role_id=\" + role_id + \", privilege=\" + privilege + \"]\";\n    }\n\n}\n\n在完成上面5个实体类的创建之后，下面我们开始MyBatis XML方式的基本用法。\n\n使用XML方式\nMyBatis的真正强大之处在于它的映射语句，由于他的映射语句异常强大，映射器的XML文件就显得相对简单。而MyBatis3.0相比2.0版本的一个最大变化，就是支持使用接口的来调用方法。\n\n在【MyBatis修炼之二】中我们使用的是SqlSession通过命名空间调用MyBatis方法，我们需要用到命名空间和方法id组成的字符串来调用相应的方法。而当参数多于1个的时候，需要将参数放到一个Map对象中。通过Map传递多个参数，使用起来很不方便。\n\n使用接口调用的方式就会方便很多，MyBatis使用Java的动态代理可以直接通过接口来调用相应的方法，不需要提供接口的实现类，并且也不需要使用SqlSession以通过命名空间间接调用。同时，当有多个参数时，可以通过在参数之前添加@Param(\"fieldName\")设置参数的名字，这样我们就可以不用手动构造Map参数了，尤其是在Spring中使用的时候，可以配置为自动扫描所有的接口类，直接将接口注入需要用到的地方。\n\n接下来我们便开始使用MyBatis的XML方式。\n首先，在src/main/resource的mybatis.simple.mapper目录下创建和我们创建的5个表对应的XML文件，分别为UserMapper.xml、RoleMapper.xml、PrivilegeMapper.xml、UserRoleMapper.xml、RolePrivilegeMapper.xml，然后在src/main/java下面创建包mybatis.simple.mapper，接着在该包下创建XML文件对应的接口类，分别为UserMapper.java、RoleMapper.java、PrivilegeMapper.java、UserRoleMapper.java、RolePrivilegeMapper.java。\n下面以用户表对应的Mapper接口UserMapper.java为例进行说明。\n\npackage mybatis.simple.mapper;\n\npublic interface UserMapper {\n    \n\n}\n现在这些文件都是空的，后续使用的时候我们将陆续向其中添加接口方法。创建了所有的接口文件之后，打开UserMapper.xml文件，并录入一下内容\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n    \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n\n<mapper namespace=\"mybatis.simple.mapper.UserMapper\">\n\n</mapper>\n我们特别需要注意的地方是<mapper>根标签namespace属性。当Mapper接口和XML文件关联的时候，命名空间namespace的值就需要配置成接口的权限定名称（包名+接口类名），MyBatis内部将通过这个值将接口和XML关联在一起。按照相同的方法创建另外4个Mapper.xml文件。准备好这些XML映射文件后，我们需要在mybatis-config.xml配置文件中的mappers元素中配置所有的mapper，部分配置代码如下。\n\n  <mappers>\n      <mapper resource=\"mybatis/simple/mapper/CountryMapper.xml\"/>\n      <mapper resource=\"mybatis/simple/mapper/UserMapper.xml\"/>\n      <mapper resource=\"mybatis/simple/mapper/RoleMapper.xml\"/>\n      <mapper resource=\"mybatis/simple/mapper/PrivilegeMapper.xml\"/>\n      <mapper resource=\"mybatis/simple/mapper/UserRoleMapper.xml\"/>\n      <mapper resource=\"mybatis/simple/mapper/RolePrivilegeMapper.xml\"/>\n  </mappers>\n这种配置方式需要将所有的映射文件一一列举出来，如果增加了新的映射文件，还需要在此处进行配置，操作起来比较麻烦，因为此处所有的XML映射文件都多有对应的Mapper接口，所有还有一种更简单的配置方式：\n\n    <mappers>\n        <package name=\"mybatis.simple.mapper\"/>\n    </mappers>\n这种配置会先查找mybatis.simple.mapper包下的所有接口，然后循环对接口进行如下操作：\n① 判断接口对应的命名空间是否已经存在，如果存在就抛出异常，不存在就继续进行接下来的操作。\n② 加载接口对应的XML映射文件，将接口权限定名转换为路径，例如，将接口mybatis.simple.mapper.UserMapper转换为mybatis/simple/mapper/UserMapper.xml，以.xml为后缀搜索XML资源，如果找打就解析XML。\n③ 处理接口中的注解方法。\n注意： 使用Mapper接口包名批量加载的方式时，需要将Mapper接口类名和Mapper.xml映射文件名称保持一致并且包名一致（Mapper.xml可以放在src/main/resource目录下，但是需要和接口类的包名保持一致，Mapper.xml也可以和接口类在同一个包下），因此直接配置接口包名，就可以自动扫描包下的接口和XML映射文件\n\n完整mybatis-config.xml文件如下：\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n    PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n    \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n    \n<configuration>\n    \n    <!-- 配置指定使用LOG4J输出日志 -->\n    <settings>\n        <setting name=\"logImpl\" value=\"LOG4J\"/>\n    </settings>\n    \n    <!-- 配置包的别名，这样我们在mapper中定义时，就不需要使用类的全限定名称，只需要使用类名即可 -->\n    <typeAliases>\n        <package name=\"mybatis.simple.model\"/>\n    </typeAliases>\n    \n    <!-- 数据库配置 -->\n    <environments default=\"development\">\n        <environment id=\"development\">\n            <transactionManager type=\"JDBC\"/>\n            <dataSource type=\"POOLED\">\n                <property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/>\n                <property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis\"/>\n                <property name=\"username\" value=\"root\"/>\n                <property name=\"password\" value=\"root\"/>\n            </dataSource>\n        </environment>\n    </environments>\n\n    <!-- mybatis的SQL语句和映射配置文件 -->\n    <mappers>\n        <package name=\"mybatis.simple.mapper\"/>\n    </mappers>\n\n</configuration>\nselect用法\n我们执行查询操作，使用MyBatis，我们只需要在XML中添加select元素，然后写上SQL语句，然后再做一些简单的配置，就可以将查询的结果直接映射到对象中。\n\n详细说明：XML方式的基本用法（SELECT）\n\ninsert用法\n和select相比，insert要简单的多。只有让他返回主键时，由于不同数据库的主键生成方式不同，这种情况下会有一些复杂。\n\n详细说明：XML方式的基本用法（INSERT）\n\nupdate、delete用法\n详细说明：XML方式的基本用法（UPDATE、DELETE）\n', 1, 0, 0, 0, NULL, '2020-11-07', 1, '2020-11-07');
INSERT INTO `tb_article` VALUES (19, 22, '使用ACK和NAS快速搭建弹性NGINX网站', '', '云服务器（Elastic Compute Service，简称ECS）是阿里云提供的性能卓越、稳定可靠、弹性扩展的IaaS（Infrastructure as a Service）级别云计算服务。云服务器ECS免去了您采购IT硬件的前期准备，让您像使用水、电、天然气等公共资源一样便捷', '科科程程', '', '## 场景介绍\n本文介绍如何在半小时内，通过阿里云容器ACK服务和文件存储NAS服务搭建一个简单的弹性、高可用NGINX网站。在完成本文的所有操作后，您将获得一个单网页的网站，用户的请求将会被打散到多个容器节点上，并且根据业务负载自动扩缩容，即使某个容器节点宕机也不会影响用户访问。另外您还可以将本地编辑的网页快速更新到网站上。\n背景知识\n本教程使用到的云产品如下：\n\n## 云服务器ECS\n\n云服务器（Elastic Compute Service，简称ECS）是阿里云提供的性能卓越、稳定可靠、弹性扩展的IaaS（Infrastructure as a Service）级别云计算服务。云服务器ECS免去了您采购IT硬件的前期准备，让您像使用水、电、天然气等公共资源一样便捷、高效地使用服务器，实现计算资源的即开即用和弹性伸缩。阿里云ECS持续提供创新型服务器，解决多种业务需求，助力您的业务发展。\n\n## 文件存储NAS\n\n阿里云文件存储（Network Attached Storage，简称 NAS）是面向阿里云 ECS 实例、E-HPC 和容器服务等计算节点的文件存储服务。NAS 提供了简单的可扩展文件存储以供与 ECS 配合使用，多个ECS实例可以同时访问 NAS 文件系统，并且存储容量会随着您添加和删除文件而自动弹性增长和收缩，为在多个实例或服务器上运行的工作负载和应用程序提供通用数据源。\n\n## 容器服务Kubernetes版\n\n阿里云容器服务Kubernetes版ACK（Alibaba Cloud Container Service for Kubernetes）是全球首批通过Kubernetes一致性认证的服务平台，提供高性能的容器应用管理服务，支持企业级Kubernetes容器化应用的生命周期管理，让您轻松高效地在云端运行Kubernetes容器化应用。\n\n本教程七个步骤，完成前五个步骤即可实现弹性高可用的NGINX网站，最后两个步骤验证网站的弹性和高可用属性。\n\n步骤一：创建资源\n步骤二：挂载文件系统NAS到ECS服务器\n步骤三：上传文件到NAS\n步骤四：配置NAS挂载信息\n步骤五：创建NGINX应用\n步骤六：访问测试网站\n步骤七：验证服务高可用\n步骤八：验证弹性扩缩容', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (20, 19, 'Oracle入门到实战-存储过程', '', '所谓存储过程(Stored Procedure)，就是一组用于完成特定数据库功能的SQL语句集，经编译后存储在数据库中，用户通过存储过程名字并给出相应的存储过程参数来调用并执行它，从而完成一个或一系列的数据库操作', '科科程程', '', '##  存储过程\n\n1. 讲师：化永生\n2. 课程名称：Oracle入门到实战\n\n### 1. 存储过程概念\n\n所谓存储过程(Stored Procedure)，就是一组用于完成特定数据库功能的SQL语句集，经编译后存储在数据库中，用户通过存储过程名字并给出相应的存储过程参数来调用并执行它，从而完成一个或一系列的数据库操作。\n\n### 2. 存储过程优缺点\n##### 2.1 优点\n- 执行速度快。存储过程只在创造时进行编译，以后每次执行存储过程都不需再重新编译，而一般 SQL 语句每执行一次就编译一次,所以使用存储过程可提高数据库执行速度\n- 可保证数据的安全性和完整性，通过存储过程可以使没有权限的用户间接地存取数据库，从而保证数据的安全,可以使相关的动作在一起发生，从而可以维护数据库的完整性\n- 减少网络通信量,当对数据库进行复杂操作时(如对多个表进行Update,Insert,Query,Delete 时），可将此复杂操作用存储过程封装起来与数据库提供的事务处理结合一起使用。这些操作，如果用程序来完成，就变成了一条条的SQL语句，可能要多次连接数据库。而换成存储过程，只需要连接一次数据库就可以了\n- 存储过程可以重复使用,可减少数据库开发人员的工作量\n\n**优点总结：**\n- 一组SQL语句的集合\n- 预编译的SQL，执行效率比较高\n- 适合完成对数据库完成复杂操作\n\n##### 2.2 缺点\n大量的利用过程，会对服务器压力比较大\n\n### 3. 存储过程创建\n\nOracle存储过程包含三部分：过程声明，执行过程部分，存储过程异常。\n\n```\nCREATE [OR REPLACE] PROCEDURE procedure_name\n    [ (parameter [in|out] datatype [,parameter]) ]\n\nIS\n    [declaration_section]\n\nBEGIN\n    executable_section\n\n[EXCEPTION\n    exception_section]\n\nEND [procedure_name];\n```\n- or replace：如果指定的过程已经存在，则覆盖同名的存储过程。\n- procedure_name：创建存储过程的名称。\n- parameter：存储过程参数名称\n- in datatype：输入参数及数据类型\n- out datetype：输出参数及数据类型\n\n### 3. 存储过程案例\n- 无参存储过程语法\n  - 创建一个存储过程，实现emp表最高工资打印\n  - 创建一个存储过程，实现emp表ename、sal字段循环打印。\n- 带IN参存储过程\n  - 用于接收参数，在子程序内部，不能进行修改。默认的参数模式：in\n  - 创建一个存储过程，并定义3个IN模式变量，然后将3个参数插入到dept中（采用按位置传递，名称传递，混合传递方式）\n  - 创建一个存储过程，循环打印每个部门最高工资。\n- 带OUT参存储过程\n  - 输出模式的参数，用于输出值，会忽略传入的值。在子程序内部可以对其进行修改。\n  - 创建一个存储过程，IN为部门号，OUT参数分别为部门名称、位置。\n  - 创建一个存储过程，以员工号为参数，输出该员工的工资\n  - 创建一个存储过程，以员工号为参数，修改该员工的工资。若该员工属于10号部门，  则工资增加150；若属于20号部门，则工资增加200；若属于30号部门，则工资增加250；  若属于其他部门，则增加\n  - 创建一个存储过程，以员工号为参数，返回该员工的工作年限（以参数形式返回）\n  - 创建一个存储过程，以部门号为参数，输出入职日期最早的10个员工信息。  \n  - 创建一个存储过程，以一个整数为参数，输入工资最高的前几个（参数值）员工的信息。\n  - 创建一个存储过程，以两个整数为参数，输出工资排序在两个参数之间的员工信息\n  - \n- 带IN OUT参数存储过程含赋值方式\n  - 能接收传入的实参值；在子程序内部可以修改,可以输出\n  - 创建Swap存储过程交换两个数的位置\n- 存储过程中游标定义使用\n  - 打印每个部门的最高工资\n  - 打印EMP表中全部字段信息\n  - 打印EMP表中EMPNO、ENAME、SAL字段信息(采用Record)\n  - 写一个涨工资的存储过程，给每个低于2000工资的人涨些钱。\n  - 使用游标查询部门编号为10的所有人姓名和薪水\n```\n[https://blog.csdn.net/codes_life/article/details/79271308](https://blog.csdn.net/codes_life/article/details/79271308 \"例子\")\nCREATE OR REPLACE PROCEDURE sp_sync_plan IS \n  CURSOR C_EMP IS --声明显式游标  \n    SELECT * FROM dc_check_todo;  \n  C_ROW C_EMP%ROWTYPE; --定义游标变量，该变量的类型为基于游标C_EMP的记录  \nBEGIN \n  --For 循环  \n  FOR C_ROW IN C_EMP LOOP  \n    DBMS_OUTPUT.PUT_LINE(C_ROW.todo_id || \'--\' );  \n  END LOOP;  \n \n  --Fetch 循环  \n  OPEN C_EMP;--必须要明确的打开和关闭游标  \n  LOOP  \n    FETCH C_EMP  \n      INTO C_ROW;  \n    EXIT WHEN C_EMP%NOTFOUND;  \n    DBMS_OUTPUT.PUT_LINE(C_ROW.todo_id || \'++\' );  \n  END LOOP;  \n  CLOSE C_EMP;  \n \n  --While 循环  \n  OPEN C_EMP;--必须要明确的打开和关闭游标  \n    FETCH C_EMP INTO C_ROW;  \n    WHILE C_EMP%FOUND LOOP  \n      DBMS_OUTPUT.PUT_LINE(C_ROW.todo_id || \'**\' );  \n      FETCH C_EMP INTO C_ROW;  \n    END LOOP;  \n  CLOSE C_EMP;  \nEND sp_sync_plan;\n```\n\n>常用异常\n>- no_data_found\n>- too_many_rows\n>- zero_divide\n>- others\n\n\n### 4. 存储过程调用\n- PL/SQL方式\n- SQLPLUS\n\n### 5. 存储过程调试\nPL/SQL中为我们提供了【调试存储过程】的功能，可以帮助你完成存储过程的预编译与测试。\n\n1. 点击要调试的存储过程，右键选择test\n2. 如果需要查看变量，当然调试都需要。在右键菜单中选择Add debug information\n3. start debugger(F9)开始我们的测试，Run（Ctrl+R)\n4. 随时在varible List中输入我们想查看的变量', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (21, 19, 'Oracle介绍、安装与卸载', '', ' Oracle出现有30年时间，经历了很多版本，目前最新的版本是12c。11g版本是目前比较稳定，很多企业也在使用，所以我们从此版本入门学习，后面的版本基本也不会有太大区别。', '科科程程', '', '##  Oracle介绍、安装与卸载\n\n1. 讲师：化永生\n2. 课程名称：Oracle入门到实战\n\n### 1. Oracle数据库简介\n\nOracle数据库是Oracle（甲骨文）公司的核心产品，适合于大型项目的开发；银行、电信、电商、金融等各领域都大量使用Oracle数据库。\n\nOracle数据库是一种对象关系型数据库。\n\nOracle数据库的产品可以免费下载，其服务是收费的，也就是该数据库用于商业目的时，必须取得Oracle的授权。\n\n Oracle出现有30年时间，经历了很多版本，目前最新的版本是12c。11g版本是目前比较稳定，很多企业也在使用，所以我们从此版本入门学习，后面的版本基本也不会有太大区别。\n\n\n> MySQL是Java开发常用的数据库，MySQL的母公司08年被SUN公司收购，而SUN公司09年被Oracle收购，所以MySQL也是Oracle旗下的产品。目前MySQL5.6及更高版本功能很强大。\n\n\n### 2. Oracle安装\n\n1. 步骤1\n\n2. 步骤2\n\n### 3. Oracle安装服务介绍\n\n成功安装Oracle 11g数据库后，你会发现自己电脑运行速度会变慢，配置较低的电脑甚至出现非常卡的状况，通过禁止非必须开启的Oracle服务可以提升电脑的运行速度。\n\n按照win7 32/64位环境下Oracle 11g R2安装详解中的方法成功安装后，共有7个服务，分别为\n\n1. OracleORCLVSSWriterService，\n2. OracleDBConsoleorcl，\n3. OracleJobSchedulerORCL，\n4. OracleMTSRecoveryService，\n5. OracleOraDb11g_home1ClrAgent，\n6. OracleOraDb11g_home1TNSListener，\n7. OracleServiceORCL。\n\n其中OracleDBConsoleorcl，OracleMTSRecoveryService，OracleOraDb11g_home1TNSListener，OracleServiceORCL是默认自动启动的,OracleJobSchedulerORCL是默认自动禁止的，其余的默认为手动操作。假设您的全局数据库名为orcl，则您的Oracle服务应该如下图\n\n![](images/server.jpg)\n\n\n\n- Oracle ORCL VSS Writer Service：Oracle卷映射拷贝写入服务，VSS(Volume Shadow Copy Service)能够让存储基础设备(比如磁盘，阵列等)创建高保真的时间点映像，即映射拷贝(shadow copy)。它可以在多卷或者单个卷上创建映射拷贝，同时不会影响到系统的系统能。(非必须启动)\n\n- OracleJobSchedulerORCL：Oracle作业调度(定时器)服务，ORCL是Oracle实例标识。(非必须启动)\n\n- OracleMTSRecoveryService：服务端控制。该服务允许数据库充当一个微软事务服务器MTS、COM/COM+对象和分布式环境下的事务的资源管理器。(非必须启动)\n\n- OracleOraDb11g_home1ClrAgent：Oracle数据库.NET扩展服务的一部分。 (非必须启动)\n\n- OracleDBConsoleorcl：Oracle数据库控制台服务，orcl是Oracle的实例标识，默认的实例为orcl。在运行Enterprise Manager(企业管理器OEM)的时候，需要启动这个服务。(非必须启动)\n\n- OracleOraDb11g_home1TNSListener：监听器服务，服务只有在数据库需要远程访问的时候才需要。(非必须启动，下面会有详细详解)。\n\n- OracleServiceORCL：数据库服务(数据库实例)，是Oracle核心服务该服务，是数据库启动的基础，只有该服务启动，Oracle数据库才能正常启动。(必须启动)\n\n\n>只用Oracle自带的sql*plus的话，只要启动OracleServiceORCL即可，要是使用PL/SQL Developer等第三方工具的话，OracleOraDb11g_home1TNSListener服务也要开启。OracleDBConsoleorcl是进入基于web的EM必须开启的，其余服务很少用。\n\n>ORCL是数据库实例名，默认的数据库是ORCL，你可以创建其他的，即OracleService+数据库名\n\n\n\n### 3. Oracle卸载\n\n1. 停用oracle服务\n2. 在开始菜单中，找到Universal Installer，运行Oracle Universal Installer，单击卸载产品\n3. 在产品清单窗口中，单击全部展开，除了OraDb11g_home1外，勾选其他项目，单击删除\n4. 按Windows徽标键和R键，打开运行窗口，输入regedit，打开注册表，依次展开HKEY_LOCAL_MACHINE\\SOFTWARE，找到oracle删除。\n5. 依次展开HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services中，删除所有oracle开头的项\n6. 依次展开HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Eventlog\\Application，删除所有oracle开头的项；在HKEY_CLASSES_ROOT，删除以ora开头的项\n7. 重启电脑，删除oracle目录，删除Oracle的安装目录app等\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (22, 19, 'SQL(Structured Query Language)是一种结构化查询语言', '', 'SQL(Structured Query Language)是一种结构化查询语言，使我们有能力访问数据库，是一种 ANSI 的标准计算机语言。', '科科程程', '', '##  SQL基础\n\n1. 讲师：化永生\n2. 课程名称：Oracle入门到实战\n\n### 1. SQL概述\n\nSQL(Structured Query Language)是一种结构化查询语言，使我们有能力访问数据库，是一种 ANSI 的标准计算机语言。\n\n#### 1.1 SQL的种类\n\n- 数据定义语言（DDL）：是用来对数据库对象（数据库、数据表、视图、索引）的创建、修改、删除的操作\n  - create：创建数据库对象如表、视图、索引等。\n  - alter：改变表结构、系统参数等。\n  - drop：删除掉一个对象，如删除表、索引等。\n  - rename：重命名一个对象。\n  - truncate：清空表，释放内存空间。\n- 数据操作语言（DML）：是用来对数据库里的数据进行操作\n  - insert：向表中插入数据数据。\n  - delete：删除表数据语句。\n  - update：修改表数据语句。\n- 数据库控制语言（DML）：是用来设置或更改数据库用户或角色权限的语句\n  - grant：授予用户权限\n  - revoke：撤销用户权限\n- 数据查询语言（DQL）：用来从数据库中获取数据，如查询表中的全部数据\n  - select：select * from emp;\n\n>SQL关键字不区分大小写\n>关键字独站一行，如select、from、where、and、group by、order by等\n\n\n### 2. 简单查询\n\n```\n语法格式：\nselect [distinct] [*|cloumn] from table [where_clause] [group by] [having_clause] [order by_clause]\nselect：查询动作关键字\n[distinct]描述列字段中的数据是否去重重复记录\n[*|cloumn]，*代表全部字段。cloumn代表查询列，可以是一个字段，也可以是多字段，中间采用逗号分割\nfrom必须关键字，表明数据的来源\n[where_clause]查询的条件部分\n[group by]分组子句部分\n[having_clause] having子句部分\n[order by_clause]排序 \n```\n\n- 查询所有列\n  - 查询emp表所有列信息\n  - 查询dept表所有信息\n- 查询指定列\n  - 查询emp表中empno、ename、sal部分列信息\n- 带有表达式的select子句\n  查询emp表sal列，将其值调整为原来的1.2倍\n- 为列指定别名\n  - 列别名\n  - 表别名\n- 显示不重复记录\n  - 查询emp表中不重复的job字段\n- 连接字符串\n  - 使用“||”\n  - concat函数\n \n\n\n### 3. 筛选查询\n\n在select语句中，where子句可以实现对数据行的筛选操作，只有满足where子句的判断条件的行才会显示在结果集中，不满足的的则不显示，能够从大量的数据中得到需要的数据。\n\n```\n语法格式：\nselect [*|cloumn]  from table where cond_expression\ncond_expression：筛选条件表达式\n```\n\n##### 3.1 比较筛选\n\n可以在where子句中使用比较运算符来筛选数据，运算符包含<、<=、>、>=、<>或!=、=共计6种。\n\n```\neg：\n1、查询emp表中工资大于2000的员工\n2、查询emp表中部门编号为10的员工\n3、查询emp表中不在部门编号为20的员工\n```\n\n##### 3.2 关键字筛选\n- IS NULL\n  - Oracle中，NULL表示数字的空、字符串的空、对象的空，等价于没有任何值、是未知数。\n  - 对空值做加、减、乘、除等运算操作，结果仍为空。\n  - NULL的处理使用NVL函数。\n  - NULL 不能用 =及!=用来比较，只能使用IS NULL 或者 IS NOT NULL\n- LIKE\n在where子句中使用like关键字查询数据方式称为模糊查询，需要使用通配符进行查询。\n  - %：代表0个或多个字符\n  - **_**:代表一个且只能是一个字符\n\n如果要查询的字符串中包含“%”或者“_”时，可以使用转义关键字escape实现，具体用法如下：\n在需要转义的字符前面加上\'\\\', 最后加上`escape \'\\\'`即可。\n\n- BETWEEN...AND：介于两个值之间，第一个值必须小于或等于第二个值，与值想反的为NOT BETWEEN...AND。\n- IN：当测试一个数据值是否匹配一组目标值中的一个时，通常使用IN关键字来指定列表条件，IN关键字的格式为 IN(目标值1,目标值2,目标值3，...)，目标值用英文逗号分割，与之相反的NOT IN\n\n##### 3.3 逻辑筛选\n- AND：逻辑与\n- OR：逻辑或\n- NOT：逻辑非\n \n\n\n### 4. 分组查询\n\n即将查询对象按一定条件分组，然后对每一个组进行聚合分析，创建分组是通过GROUP BY子句实现的，语法格式如下：\n\n```\nselect [*|cloumn]  from table [group by expression]\n```\n\n##### 4.1 聚合函数\n\n聚合函数也叫组函数，同时对一组数据行进行操作，对每组行返回一行输出结果，常用的聚合函数如下：\n- count——返回找到的记录数；\n- min——返回一个数字列或计算列的最小值；\n- max——返回一个数字列或计算列的最大值；\n- sum——返回一个数字列或计算列的综合；\n- avg——对一个数字列或计算列求平均值；\n\n```\nselect count(*) from emp;\nselect max(sal) from emp;\nselect avg(sal) from emp;\nselect min(sal) from emp;\nselect sum(sal) from emp;\nselect sum(comm) from emp;\n注意：如果给定的值中存在空值的话，oracle将会直接忽略\n```\n\n##### 4.2 单列分组\n\n`select deptno,count(*) from emp group by deptno`\n\n1. 单列分组时，select后面只可以有两种表达式：分组列名与统计函数；\n2. select子句中列必须是group by后面的列名，除此之外添加其他列都是错误的，select后面的列名可以省略不写。\n\n##### 4.3 多列分组\n\n`select deptno,job,count(*) from emp group by deptno,job`\n\n1. 多列分组时，select后面只可以有两种表达式：分组列名与统计函数；\n2. select子句中列必须是group by后面的列名，除此之外添加其他列都是错误的，select后面的列名可以省略不写。\n\n\n##### 4.3 分组过滤查询(having子句)\n\n`select deptno,count(*) from emp group by deptno having count(*) > 2`\n\n1. having子句通常与group by一起使用，对分组后的数据进行筛选查询。\n2. having子句后面只能包含聚函数\n3. where与having都用于筛选查询数据，where用于单行过滤查询，having用于分组过滤查询。\n\n### 5. 查询排序\n\n在查询数据时，如果把数据从数据库中直接读取出来，这时查询结果将按照默认顺序排列，但往往这种默认排列顺序并不是用户所需要的，因此 需要对返回数据排序，在select语句中，可以使用order by 子句对查询结果进行排序，语法结构如下：\n\n`select * from emp [where_cond] [group by] order by [expression] asc|desc`\n\n- asc：升序\n- desc：降序\n\n##### 5.1 单列排序\n  - 查询emp表并安装薪水从高到低排序\n  - 查询emp表并安装薪水从低到高排序\n\n##### 5.2 多列排序\n  - 查询emp表中按部门排序升并且按薪水降序排列\n  - 查询emp表中按年薪降序排列（表达式作为排序字段）\n\n>NULL值在排序过程中是个比较特殊的值类型，默认情况下把它看成最大值，也就是说，升序时排在最后面，降序时排在首位\n\n### 6. 查询执行顺序\n- 第一步：执行FROM\n- 第二步：WHERE条件过滤\n- 第三步：GROUP BY分组\n- 第四步：执行SELECT投影列\n- 第五步：HAVING条件过滤\n- 第六步：执行ORDER BY 排序\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (23, 19, 'Oracle事务与锁', 'http://localhost:8888/cms/upload/649e7c7e-1a05-4ccb-b921-47bf76b3b65c.png', '事务和锁是数据库两个重要知识点，数据库是一个可以由多个用户共享的资源，因此多个用户并发存取数据时，要保证数据的正确性，事务和锁就完成了这项功能。', '科科程程', '', '#  事务和锁\n\n1. 讲师：化永生\n2. 课程名称：Oracle入门到实战\n\n事务和锁是数据库两个重要知识点，数据库是一个可以由多个用户共享的资源，因此多个用户并发存取数据时，要保证数据的正确性，事务和锁就完成了这项功能。\n\n## 1.事务\n\n### 1.1 什么是事务\n\n- 事务是一组包含一条或多条SQL语句的逻辑单元。\n- 事务中SQL语句被作为一个整体，要么一起被提交，使数据库永久的修改，要么一起撤销，对数据库不做任何的修改。\n\n### 1.2 事务相关概念\n- **事务的提交和回滚**：\n   - 执行Commit语句提交事务\n   - 执行Rollback语句回滚事务\n- **事务的开始**\n	- Oracle使用隐式事务，不需要定义事务开始，第一个SQL语句自动开始一个事务。\n- **事务的结束**\n   - 执行DDL(例如CREATE TABLE),DCL(例如GRANT),系统自动执行COMMIT语句\n   - 执行COMMIT/ROLLBACK\n   - 退出/断开数据库的连接自动执行COMMIT语句\n   - 进程意外终止，事务自动ROLLBACK\n```\n代码实例\n--创建银行表 说明DDL事务\ncreate table bank(\nid number(11) primary key,\nname varchar2(10),\nmoney number(10,2)\n)\n--增加约束，money>=1 说明DDL事务\nALTER TABLE bank ADD CONSTRAINT CK_money CHECK(money >= 1);\n\n--插入测试数据 说明DML事务\nINSERT INTO bank(id,name, money) VALUES(1,\'张三\', 1000);\nINSERT INTO bank(id,name, money) VALUES(2,\'李四\', 1);\ncommit;\n--rollback;\n\ndelete from bank;\ncommit;\n\nselect * from bank;\n\n---------不使用事务完成转帐操作(总金额异常)\nupdate bank set money=money+1000 where name=\'李四\';   \nupdate bank set money=money-1000 where name=\'张三\';\n\n\n---------使用事务完成转帐操作(总金额异常)\nbegin\nupdate bank set money=money+1000 where name=\'李四\';   \nupdate bank set money=money-1000 where name=\'张三\';\ncommit;\nexception\nwhen others then\n  rollback;\nend;\n-----------没有处理异常的情况下，PL/SQL出现error，事务自动回滚(总金额异常)\nbegin \nupdate bank set money=money+1000 where name=\'李四\';   \nupdate bank set money=money-1000 where name=\'张三\';\ncommit;\n```\n\n- **保存点（savepoint）**：\n   - 是事务处理过程中的一个标志，与回滚命令(ROLLBACK)结合使用，主要的用途是允许用户将某一段处理回滚而不必回滚整个事务。\n   - 一旦执行了rollback或commit那么savepoint的操作都将撤消\n\n```\n代码实例\ndeclare \nmoney_ bank.money%type;\nbegin\n   --事务开启\n   INSERT INTO bank(id,name, money) VALUES(3,\'王五\', 500);\n   select sum(money) into money_ from bank;\n   dbms_output.put_line(money_); \n   savepoint B;\n   INSERT INTO bank(id,name, money) VALUES(5,\'胡八\', 300);   \n   INSERT INTO bank(id,name, money) VALUES(4,\'赵六\', 0);\n   commit;\n   exception\n          when others then\n          dbms_output.put_line(\'撤销提交\');\n          rollback to B;\n  commit;\nend;\n```\n- **自治事务**：\n\n事务的“要么全部完成，要么什么都没完成”的本性会使将错误日志记入数据库表中变得很困难，采用自治事务，将自治事务是与主事务相分离，在事务中检测到错误时，您可以在错误日志表格中插入一行并提交它，然后在不丢失这次插入的情况下回滚主事务。\n\n创建自治事务，必须在匿名块的最高层或者存储过程、函数、数据包或触发的定义部分中使用PRAGMAAUTONOMOUS_TRANSACTION语句。\n\n```\nCreate table Msg (Msg varchar(50)) ;\n\n--2、创建自制事务：\ncreate or replace procedure autonomouse_insert is\n  pragma autonomous_transaction;\nbegin\n  insert into msg values (\'AutoNomouse Insert\');\n  commit;\nend;\n \n--3、非自治事务：\ncreate or replace procedure nonautonomouse_insert as\nbegin\n  insert into msg values (\'NonAutonomouse Insert\');\n  commit;\nend;\n\ndelete from msg ;\ncommit;\nselect * from msg\n\nbegin\n  insert into msg values (\'This Main Info\');\n -- autonomouse_insert;\n  nonautonomouse_insert;\n  rollback;\nend;\n因为过程中有COMMIT;所以匿名块中得ROLLBACK是不起作用的； 由此得出：非自治事务中的COMMIT,ROLLBACK是会影响整个事务的。\n```\n\n- **事务的四个特性ACID：**\n   - 原子性（Atomicity）: 事务是一个整体工作单元，对数据库所做的操作要么全部执行，要么全部取消\n   - 一致性(Consistency)： 指事务操作前后，数据库中数据是一致的，数据满足业务规则约束（例如账户金额的转出和转入）\n   - 隔离性（Isolation）：多个并发事务可以独立运行，而不能相互干扰，一个事务修改数据未提交前，其他事务看不到它所做的更改\n   - 持久性（Durability）：事务提交后，数据的修改是永久的。\n\n### 1.3 事务隔离级别\n两个事务并发访问数据库数据时可能存在的问题，Oracle默认的隔离级别为Read Committed，因此可能出现不可重复度和幻读。\n##### 1.幻读\n第1次和第2次读出来的记录数不一样。\n例子：\n在事务1中，查询User表id为1的是用户否存在，如果不存在则插入一条id为1的数据，在事务1查询结束后，事务2往User表中插入了一条id为1的数据。此时，由于事务1查询到id为1的用户不存在，因此插入1条id为1的数据。\n但是由于事务2已经插入了1条id为1的数据，因此此时会报主键冲突，对于事务1的业务来说是执行失败的，这里事务1 就是发生了幻读。\n\n##### 2.不可重复读取\n第一次与第二次读出来的数据不一样。\n例子：\n在事务1中，JoonWhee读取了自己的工资为1000，但是此时事务1的操作还并没有完成 ，后面还有1次相同的读取操作，在事务2中，这时财务人员修改了JoonWhee的工资为2000，并提交了事务。在事务1中，JoonWhee再次读取自己的工资时，工资变为了2000。\n\n##### 3.脏读（Oracle不支持脏读）\n事务T1更新了一行记录，还未提交所做的修改，这个T2读取了更新后的数据，然后T1执行回滚操作，取消刚才的修改，所以T2所读取的行就无效，也就是脏数据。\n\n\n### 1.4 设置事务\n\n1. `SET TRANSACTION READ ONLY`--事务中不能有任何修改数据库中数据的操作语句，这包括 insert、update、delete、create语句\n\n```\ncreate table student(\nid number(11) primary key,\nname varchar2(20),\nsex char(2),\nscore number(5,2)\n)\ninsert into student values(1,\'张三\',\'男\',78);\ninsert into student values(2,\'李四\',\'男\',88);\ninsert into student values(3,\'王五\',\'男\',98);\ninsert into student values(4,\'赵六\',\'男\',77);\ninsert into student values(5,\'钱七\',\'男\',87);\ninsert into student values(6,\'胡八\',\'男\',97);\n\nSET TRANSACTION READ ONLY;\ninsert into student values(7,\'常九\',\'男\',87);\ninsert into student values(8,\'任十\',\'男\',97);\ncommit;\n\n```\n\n2. `SET TRANSACTION READ WRITE`--默认设置,该选项表示在事务中可以有访问语句、修改语句\n\n```\nSET TRANSACTION READ WRITE;\ninsert into student values(7,\'常九\',\'男\',87);\ninsert into student values(8,\'任十\',\'男\',97);\ncommit;\n```\n\n3. `SET TRANSACTION ISOLATION LEVEL READ COMMITTED`\n\n```\n事务1\nset transaction isolation level read committed;\nselect * from student; --第一次\nselect * from student;--第二次\n\n事务2\nSET TRANSACTION READ WRITE; --支持不可重复读\nupdate student set score = 100 where name = \'张三\';\ncommit;\n\nSET TRANSACTION READ WRITE; --支持幻读\ninsert into student values(9,\'幻读者\',\'男\',97);\ncommit;\n```\n\n4. `SET TRANSACTION ISOLATION LEVEL SERIALIZABLE`--serialzable可以执行DML操作\n\n```\n事务1\nset transaction isolation level SERIALIZABLE;\nselect * from student; --第一次\nselect * from student;--第二次\n\n事务2\nSET TRANSACTION READ WRITE; --不支持不可重复读\nupdate student set score = 100 where name = \'张三\';\ncommit;\n\nSET TRANSACTION READ WRITE; --不支持幻读\ninsert into student values(9,\'幻读者\',\'男\',97);\ncommit;\n```\n\n\n## 2. 锁\n\n数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。\nOracle 利用其锁机制来实现事务间的数据并发访问及数据一致性\n\n- 排他锁(X锁)：防止资源共享，用做数据的修改，假如有事务T给数据A加上该锁，那么其他的事务将不能对A加任何的锁，所以此时只允许T对该数据进行读取和修改，直到事务完成将该类型的锁释放为止\n\n- 共享锁（S锁）：该锁下的数据只能被读取，不能被修改，如果有事务T给数据A加上共享锁后，那么其他的事务不能对其加排他锁，只能加共享锁，加了该锁的数据可以被并发的读取。\n\n### 2.1 锁的类别\n\n- DDL锁： oracle自动的施加和释放\n- DML锁：事务开始时施加，使用Commit后者Rollback被释放\n- 内部锁： 由oracle自己管理以保护内部数据库结构\n\n### 2.2 锁的粒度\n\n- 行级锁（TX）：阻止该行上的DML操作，直到Commit或者RollBack\n- 表级锁（TM）：\n- 数据库级锁：将数据库锁定为只读模式 alter database open read only;\n\n\n### 2.3 行级锁(TX)\n\n行级锁一般是指排它锁，即被锁定行不可进行修改，删除，只可以被其他会话select。行级锁之前需要先加表结构共享锁\n\n- `select * from person for update;` 给该表的所有行都加上锁\n- `select * from person  where id = \'1\'  for update` 当该行记录已经被锁定时，那么系统将一直等待该行记录被释放后，再加锁\n- `select * from person  where id = \'1\'  for update nowait ` 该行记录已经被锁定，不用等待，系统会直接抛错 ora-00054\n- `select * from person for update wait 5;` --该行记录已经被锁定，更新的时候等待5秒，如果这5秒内，该行记录被解锁，那么返回查询结果，如果5秒内仍未解锁，系统会直接抛错 ora-00054 \n\n> 行级锁属于排他锁\n\n### 2.4 表级锁(TM)\n\n防止在修改表的数据时，表的结构发生变化，例如会话S在修改表A的数据时，它就会得到A的TM锁，而此时不允许其他会话对改变就行变更或删除。\n\n**表级锁有如下几种模式：**\n\n- 行共享Row Share（RS）：允许用户进行任何操作，禁止排他锁 `lock table person in row share mode`;\n\n- 行排他Row Exclusive（RX）：允许用户进行任何操作，禁止共享锁 `lock table person in row exclusive mode`;\n\n- 共享锁(Share)：其他用户只能看，不能修改 `lock table person in share mode`;\n\n- 共享行排他（Share Row Exclusive）：比共享锁有更多限制 `lock table person in share row exclusive mode`;\n\n- 排他锁（Exclusive）：其他用户只能看，不能修改，不能加其他锁 `lock table person in exclusive mode`;\n\n### 2.5 锁模式\n![](images/lock.png)\n\n- 0：none \n- 1：null 空 \n- 2：Row-S 行共享(RS)：共享表锁，允许用户进行任何操作，禁止排他锁 `lock table person in row share mode`;\n- 3：Row-X 行专用(RX)：用于行的修改，允许用户进行任何操作，禁止共享锁 `lock table person in row exclusive mode`;\n- 4：Share 共享锁(S)：阻止其他DML操作，其他用户只能看，不能修改 `lock table person in share mode`;\n- 5：S/Row-X 共享行专用(SRX)：阻止其他事务操作 ，比共享锁有更多限制 `lock table person in share row exclusive mode`;\n- 6：exclusive 专用(X)：独立访问使用，其他用户只能看，不能修改，不能加其他锁 `lock table person in exclusive mode`;\n\n>数字越大锁级别越高, 影响的操作越多\n\n**锁的兼容性如下(Y表示兼容，N表示冲突)**\n\n![](images/lock2.png)\n\n\n### 2.5 死锁\n\n当两个用户希望持有对方的资源时就会发生死锁。即两个用户互相等待对方释放资源，oracle认定为产生了死锁。\n\n**死锁产生条件**\n\n1. Mutual exclusion（互斥）：资源不能被共享，只能由一个进程使用。\n2. Hold and wait（请求并保持）：已经得到资源的进程可以再次申请新的资源。\n3. No pre-emption（不可剥夺）：已经分配的资源不能从相应的进程中被强制地剥夺。\n4. Circular wait（循环等待条件）：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源。\n\n\n**死锁模拟**\n\n\n```\n第一步：\n事务1\nSET TRANSACTION READ WRITE;\nupdate student set score = 66 where name = \'张三\';\n\n事务2\nSET TRANSACTION READ WRITE;\nupdate student set score = 77 where name = \'李四\';\n\n第二步：\n事务1\nupdate student set score = 88 where name = \'李四\';\n\n事务2\nupdate student set score = 99 where name = \'张三\';\n```\n\n**解决死锁冲突**\n- 执行commit或者rollback结束事务\n- 终止会话\n在等待资源时执行，查找阻塞会话\n`select sid,serial#,username from v$session where sid in (select blocking_session from v$session);`\n\n`alter system kill session \'423,896\';`\n\n**事务和死锁预防总结**\n\n1. 避免应用不运行长事务。\n2. 经常提交以避免长时间锁定行。\n3. 避免使用LOCK命令锁定表。\n4. 在非高峰期间执行DDL操作，在非高峰期间执行长时间运行的查询或事务。', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (24, 22, '新一代搜索引擎项目 ZeroSearch 设计探索', '', '在PL/SQL中，ELECT...INTO...查询语句一次只能从数据库中提取一行数据，对于这种形式的查询和DML操作，系统都会使用一个隐式游标。要提取多行数据，就要由程序员定义一个显式游标，并通过与游标有关的语句进行处理。显式游标对应一个返回结果为多行多列的SELECT语句', '科科程程', '', '##  游标\n\n1. 讲师：化永生\n2. 课程名称：Oracle入门到实战\n\n### 1. 游标概念\n\n在PL/SQL块中执行select、insert、update、delete语句时，Oracle会在内存中为其分配上下文区，游标是指向上下文区域的一个指针。\n\n在PL/SQL中，ELECT...INTO...查询语句一次只能从数据库中提取一行数据，对于这种形式的查询和DML操作，系统都会使用一个隐式游标。\n\n要提取多行数据，就要由程序员定义一个显式游标，并通过与游标有关的语句进行处理。显式游标对应一个返回结果为多行多列的SELECT语句。 \n\n#### 游标种类\n- 显式游标\n\n  显示游标是由用户声明和操作的一种游标，通常用于操作查询结果集（即由SELECT语句返回的查询结果），使用它处理数据的步骤包括：声明游标、打开游标、读取游标和关闭游标4个步骤。  \n\n- 隐式游标:隐式游标是Oracle为所有数据操作语句自动声明和操作的一种游标，DML操作和单行SELECT语句会使用隐式游标，它们是： \n  - 插入操作：INSERT。 \n  - 更新操作：UPDATE。 \n  - 删除操作：DELETE。 \n  - 单行查询操作：SELECT ... INTO ...。 \n\n\n#### 游标语法\n\n`CURSOR cursor_name [(param_name datatype)] IS select_statement`\n\n- `CURSOR cursor_name` 声明游标，cursor_name是游标的名称\n- `param_name` 参数名称\n- `datatype` 参数类型\n- `select_statement` 游标关联的SQL语句。\n\n\n#### 游标使用步骤\n\n1. 声明游标\n\n`CURSOR cursor_name [(param_name datatype)] IS select_statement`\n\n2. 打开游标\n\n`open cursor_name`\n\n3. 读取数据\n\n读取游标利用Fetch完成，把游标指向位置的记录放入到变量中，通常情况下，fetch要和循环一块使用，指针不断前进，直到不符合条件而退出。\n\n`fetch cursor_name into record_name`\n\n4. 关闭游标\n\n`close cursor_name`\n\n\n\n#### 游标属性\n\n**隐式游标属性**\n- SQL%ROWCOUNT    整型  代表DML语句成功执行的数据行数   \n- SQL%FOUND   布尔型 值为TRUE代表插入、删除、更新或单行查询操作成功   \n- SQL%NOTFOUND    布尔型 与SQL%FOUND属性返回值相反   \n- SQL%ISOPEN  布尔型 DML执行过程中为真，结束后为假\n\n- 使用隐式游标的属性，判断对雇员工资的修改是否成功\n```\nBEGIN  \nUPDATE emp SET sal=sal+100 WHERE empno=1234;   \n IF SQL%FOUND THEN    \nDBMS_OUTPUT.PUT_LINE(\'成功修改雇员工资！\');   \nCOMMIT;    \nELSE  \nDBMS_OUTPUT.PUT_LINE(\'修改雇员工资失败！\');   \n END IF;    \nEND;  \n```\n**显式游标属性**\n\n- %ROWCOUNT   整型  获得FETCH语句返回的数据行数   \n- %FOUND  布尔型 最近的FETCH语句返回一行数据则为真，否则为假   \n- %NOTFOUND   布尔型 与%FOUND属性返回值相反   \n- %ISOPEN 布尔型 游标已经打开时值为真，否则为假  \n\n```\nDECLARE  \n  V_ename VARCHAR2(10);   \n  CURSOR emp_cursor IS    \n  SELECT ename FROM emp;   \nBEGIN  \n OPEN emp_cursor;   \n IF emp_cursor%ISOPEN THEN  \nLOOP   \n   FETCH emp_cursor INTO v_ename;   \n   EXIT WHEN emp_cursor%NOTFOUND;   \n   DBMS_OUTPUT.PUT_LINE(to_char(emp_cursor%ROWCOUNT)||\'-\'||v_ename);   \n  END LOOP;   \n ELSE  \n  DBMS_OUTPUT.PUT_LINE(\'用户信息：游标没有打开！\');   \n END IF;   \n CLOSE  emp_cursor;   \nEND;\n```\n\n\n- 用游标提取emp表中7788雇员的名称和职务\n```\nDECLARE    \nv_ename VARCHAR2(10);   \nv_job VARCHAR2(10);   \nCURSOR emp_cursor IS    \nSELECT ename,job FROM emp WHERE empno=7788;   \nBEGIN  \nOPEN emp_cursor;   \nFETCH emp_cursor INTO v_ename,v_job;   \nDBMS_OUTPUT.PUT_LINE(v_ename||\',\'||v_job);   \nCLOSE emp_cursor;   \nEND;   \n```\n\n- 用游标提取emp表中7788雇员的姓名、职务和工资\n\n```\nDECLARE  \nCURSOR emp_cursor IS  SELECT ename,job,sal FROM emp WHERE empno=7788;   \nemp_record emp_cursor%ROWTYPE;   \nBEGIN  \nOPEN emp_cursor;       \nFETCH emp_cursor INTO emp_record;   \nDBMS_OUTPUT.PUT_LINE(emp_record.ename||\',\'|| emp_record.job||\',\'|| emp_record.sal);   \nCLOSE emp_cursor;   \nEND;  \n```\n\n- 显示工资最高的前3名雇员的名称和工资\n\n```\nDECLARE  \nV_ename VARCHAR2(10);   \nV_sal NUMBER(5);   \nCURSOR emp_cursor IS  SELECT ename,sal FROM emp ORDER BY sal DESC;   \nBEGIN  \nOPEN emp_cursor;   \nFOR I IN 1..3 LOOP   \nFETCH emp_cursor INTO v_ename,v_sal;   \nDBMS_OUTPUT.PUT_LINE(v_ename||\',\'||v_sal);   \nEND LOOP;   \nCLOSE emp_cursor;   \nEND;  \n```\n- 使用特殊的FOR循环形式显示全部雇员的编号和名称\n\n```\nDECLARE  \nCURSOR emp_cursor IS    \nSELECT empno, ename FROM emp;   \nBEGIN  \nFOR Emp_record IN emp_cursor LOOP      \nDBMS_OUTPUT.PUT_LINE(Emp_record.empno|| Emp_record.ename);   \nEND LOOP;   \nEND;\n\n另一种形式的游标循环\nBEGIN  \n FOR re IN (SELECT ename FROM EMP)  LOOP   \n  DBMS_OUTPUT.PUT_LINE(re.ename)   \n END LOOP;   \nEND; \n``` \n\n- 带参数的游标\n\n```\nDECLARE  \nV_empno NUMBER(5);   \nV_ename VARCHAR2(10);   \nCURSOR  emp_cursor(p_deptno NUMBER,     p_job VARCHAR2) IS  \nSELECT  empno, ename FROM emp   \nWHERE   deptno = p_deptno AND job = p_job;   \nBEGIN  \nOPEN emp_cursor(10, \'CLERK\');   \nLOOP   \nFETCH emp_cursor INTO v_empno,v_ename;   \nEXIT WHEN emp_cursor%NOTFOUND;   \nDBMS_OUTPUT.PUT_LINE(v_empno||\',\'||v_ename);   \nEND LOOP;   \nEND;  \n\n```\n\n- 已知每个部门有一个经理，编写程序，统计输出部门名称、部门总人数、总工资和部门经理。 \n输入并执行如下程序\n\n```\nDECLARE  \n v_deptno number(8);   \n v_count number(3);   \n v_sumsal number(6);   \n v_dname  varchar2(15);   \nv_manager  varchar2(15);   \n CURSOR list_cursor IS  \n   SELECT deptno,count(*),sum(sal) FROM emp group by deptno;   \nBEGIN  \n  OPEN list_cursor;    \n  DBMS_OUTPUT.PUT_LINE(\'----------- 部 门 统 计 表 -----------\');   \nDBMS_OUTPUT.PUT_LINE(\'部门名称   总人数  总工资   部门经理\');   \n  FETCH list_cursor INTO v_deptno,v_count,v_sumsal;    \n  WHILE list_cursor%found LOOP     \n SELECT dname INTO v_dname FROM dept   \n    WHERE deptno=v_deptno;   \n    SELECT ename INTO v_manager FROM emp    \n    WHERE deptno=v_deptno and job=\'MANAGER\';   \nDBMS_OUTPUT.PUT_LINE(rpad(v_dname,13)||rpad(to_char(v_count),8)   \n      ||rpad(to_char(v_sumsal),9)||v_manager);   \n    FETCH list_cursor INTO v_deptno,v_count,v_sumsal;    \n    END LOOP;   \n        DBMS_OUTPUT.PUT_LINE(\'--------------------------------------\');   \n        CLOSE list_cursor;   \n        END;  \n```\n- 为所有雇员增加工资，工资在1000以内的增加30%，工资在1000～2000之间的增加20%，2000以上的增加10%\n\n- 按部门编号从小到大的顺序输出雇员名字、工资以及工资与平均工资的差\n\n- 编写程序，格式化输出部门信息\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (26, 27, '人工智能：一种现代的方法 ,弱人工智能与强人工智能', '', '很多事情计算机可以和人类做的一样好，有些甚至更好，包括那些人们相信需要极大的人类洞察力和理解力的事情上，当然也有些事情计算机做的不如人类。对智能机器可能性的质疑(弱人工智能)', '科科程程', '', '弱人工智能假设(weak AI)：机器能够智能的行动；\n\n强人工智能假设(strong AI)：机器能够真正的思考(不只是模拟思考)；\n\n1. 对智能机器可能性的质疑(弱人工智能)：\n\n1）能力缺陷方面的论点：一台机器永远做不了X。\n\nX包括：善良和蔼，积极主动，享受美味的草莓和奶油，反思自我，做出真正创新之事等等。\n\n很多领域里，简单的统计学习算法(如线性回归或朴素贝叶斯)预测得比专家要好。\n\n很多事情计算机可以和人类做的一样好，有些甚至更好，包括那些人们相信需要极大的人类洞察力和理解力的事情上，当然也有些事情计算机做的不如人类。\n\n问题的关键在于，产生特定行为所需的精神过程的猜测往往是错误的。\n\n2）数学异议\n\n某些数学问题在原理上就是无法被特定的形式系统解答的。\n\n哥德尔的不完备性定理就是这种情况的一个最著名例子。\n\n对于任何能力强到足以描述算术的形式公理系统F，都可能构造出一个具有如下特性的所谓“哥德尔语句“：\n\nG(F)是F的一个语句，但是不能在F中被证明。\n\n如果F是一致的，那么G(F)为真。\n\n在发明数学以前的数千年里，人类的行为一直体现着智能，所以形式数学推理在对于智能的意义方面最多扮演着外围角色。\n\n一个形式系统不能做X，并不能断言人类能用非形式的方法做X。\n\n3）行为的非形式化论点\n\n这种论点认为人类的行为太过复杂而无法通过任何简单的规则集合捕捉到。由于计算机所能做的不过是遵循规则集合，所以，它们无法产生同人类一样的智能行为。\n\n人工智能领域，这种无法用一个规则集合捕捉每件事物的能力缺陷称为限制问题。\n\n老式的人工智能(good old-fashioned AI)：\n\n主张所有的智能行为都可以被一个根据一组描述该领域的事实和规则进行逻辑推理的系统捕捉到。\n\n这种人工智能符合第七章描述的逻辑agent，逻辑agent是受限制的，这种论断是正确的。\n\n但第13章讲述的，概率推理系统更适合开放领域。\n\n所以这种批判本质上是针对某种特定的计算机程序的。确切的说是针对没有学习能力的基于一阶逻辑规则的系统，而不是针对计算机的。\n\n哲学家Dreyfus提出的质疑：\n\na) 无人知道如何将背景知识糅合到神经网络学习过程中。\n\n事实上，第19章和第20章见过的学习算法使用了先验知识的技术。\n\n重新设计神经元处理模型以便使它们能够按照其他学习算法的方式利用先前所学到的知识。\n\nb) 神经网络的学习是有监督学习的一种形式，需要对相关输入和正确输出的先验辨识。因此他们宣称，没有人类训练者的帮助，它就不能自主运转。\n\n事实上，没有教师的学习可以通过无监督的学习和强化学习来实现。\n\nc) 当使用很多特征时，学习算法的表现不尽如人意，而如果只选取一个特征子集，则“当前特征集被证明不足以解释学习到的事实时，没有已知的增加新特征的方法“。\n\n事实上，诸如支持向量机这样的新方法对于大规模的特征集处理的很好。自然语言处理和计算机视觉的许多应用常常处理数百万个特征。\n\nd) 大脑能够指挥它的传感器去搜集相关信息，并对其进行处理，以抽取与当前情景相关的方面。当前，此机制的细节还没有被理解。\n\n事实上，以信息价值理论(第16章)为支撑的主动视觉领域关注的正是指挥传感器的问题，而且一些机器人已经吸收了所取得的理论成果。\n\n所以，以上质疑都是人工智能进步的证据，而不是人工智能不可能的证据。\n\n4）最有力的质疑：\n\nagent对事物的理解是来自于一组逻辑推理语句还是来自于真实环境中与事物的接触\n\n例子：\n\n一个agent对狗的理解是来自于诸如“Dog(x)=>Mammal(x)“的逻辑语句的有限集合，\n\n另一个agent对狗的理解来自于它观察过狗奔跑，与狗玩过接物，被狗舔过，\n\n显然第二个agent更有优势。\n\n物化的认知方法认为，单独考虑大脑没有意义，认知发生在身体里，身体处在环境中，大脑通过参考环境推进它的推理，我们需要从整体来研究系统，而不是只考虑思维过程。\n\n物化的认知方法下，机器人学，视觉和其他传感器变成了中心角色，而不是外围角色。\n\n2. 机器真能思考么 (strong AI)\n\n意识：机器要意识到其自身的精神状态和行动。\n\n机器不只能创作诗，而且能知道自己在创作。\n\n二元论：\n\n相信精神和物质是两种截然不同的东西，精神控制肉体。\n\n一元论(唯物主义)：\n\n相信精神不能脱离肉体，精神状态就是身体状态。\n\n多数现代精神哲学家是某种形式的唯物主义，唯物主义至少原理上认为人工智能是可行的。\n\n唯物主义的问题是要解释身体状态(大脑的分子组成和电气化学过程)同时也是精神状态。\n\n精神状态和瓮中之脑\n\n一个人在一个特殊的精神状态中是什么意思，如相信，知道，期望，害怕等等。\n\n脱离肉体，养在瓮中的大脑，接收一个模拟吃汉堡的模拟状态，瓮中之脑和真实的吃过汉堡的大脑的精神状态相同么？\n\n可以从两种观点来解释精神状态的内容。\n\n1）广义内容的观点：以一个全知的外部观察者的视角解释，在这种观点下，精神状态的内容涉及大脑状态和环境历史。吃汉堡者的大脑状态是真正经历过吃汉堡的身体的大脑的状态。\n\n2）狭义内容的观点：只考虑大脑状态。一个真正吃汉堡者和一个瓮中大脑吃汉堡者的大脑状态的狭义内容是相同的。\n\n功能主义和脑置换试验\n\n功能主义理论认为，精神状态是输入和输出之间的任何中间因果条件。任何具有同构因果过程的两个系统将具有相同的精神状态。因此计算机程序和人可以有相同的精神状态。\n\n对功能主义理论阐述最清楚的是脑置换试验。\n\n设想神经生理学已经发展到对人类大脑中的输入-输出行为和所有神经元的连接都理解的相当透彻来。我们也能够制造模仿这种行为的微小电子设备，并能将它们接入大脑神经组织中，设想通过不影响大脑整体运转的外科手术，将人脑的所有神经元替换成电子设备。\n\n我们关注手术期间和手术之后，试验对象的外部行为和内部经验。根据这个试验的定义，与手术前相比，该对象的外部行为保持一致。\n\n试验对象本身应该能记录他的意识经验的变化。\n\n针对脑置换试验，我们必须解释只借助于神经元的功能特性的电子大脑所产生的意识表现，并且这种解释也要适用于具有相同特性的真正的大脑。\n\n有三种可能的结论：\n\n1) 正常大脑中产生这些种类输出的意识的因果机制在它的电子版本中仍然运转，因此，电子大脑是有意识的；\n\n2) 正常大脑中有意识的精神事件与行为没有因果联系，而且不存在于电子大脑中，因此，电子大脑是无意识的；\n\n3) 这种实验是不可能的，对它的思考是无意义的；\n\n生物自然主义和中文房间\n\n生物自然主义理论认为，精神状态是神经元中的低层次的物理过程导致的高层次的自然发生的特征，精神状态是有关神经元的特性。因此，仅仅基于一些具有相同输入-输出行为的相同功能结构的程序，精神状态是不能被复制的。我们要求程序在一个具有与神经元相同的因果影响的体系结构上运行。\n\n中文房间：\n\n一个系统由一个只懂英文的人组成，这个人带着一本英文写的规则手册，一堆白纸(人相当于cpu，英文手册是程序，白纸四存储设备)，这个系统通过一个缝隙与外部相通。\n\n外面的人，通过缝隙，向系统输入一些中文，这个人通过查找手册将中文翻译成英文，写在白纸上，并通过缝隙将白纸输出，外面的人看来，系统能正确的输出，但系统的各个部件(人，手册，纸张)都不理解中文。\n\n所以，作为对功能主义的反驳：\n\n运行正确的程序不一定会产生理解。\n\n运行恰当的程序不是成为一个思维的充分条件。\n\n思维源于大脑。\n\n思维是如何产生的？仍是一个巨大的谜。\n\n3. 发展人工智能的风险\n\n先进技术常常被强势力使用来压制他们的对手。就像数论学家Hardy写到，“如果一门科学的发展使现有的财富分配的不平等更加突出，或者直接推动人类生活的毁灭，就可以说这门科学是有用的科学“。这对所有科学都成立，人工智能也不例外。\n\n人工智能的成功可能意味着人类种族的终结。\n\n人工智能的风险来源：\n\n1）人工智能系统的状态估计可能是不正确的，导致其做错误的事情。\n\n例如，自动驾驶的汽车错误的估计其他车子的位置，而造成交通事故，导致车上的人丧生。\n\n2）为一个人工智能系统确定一个正确的效用函数的最大化不是那么容易。\n\n例如，我们可能提出涉及最小化人类困难的效用函数。而人工智能系统的优化决策可能是终结人类，没有人类就没有苦难。\n\n3) 人工智能系统的学习函数可使其进化为一个具有无意识行为的系统。这种情况是最严重的，也是人工智能系统独有的。\n\n因为环境以及我们对环境期望的反应都是随着时间变化的，所以我们给agent的效用函数也不能是静态的，而是能随着时间进化的。\n\n如果赋予人工智能程序学习和改进自身的能力，那么就需要设计相应的防护措施，以防止其失控。\n\n人工智能的现状与未来\n\n人工智能任务视为理性agent设计：\n\n在给定的感知历史下其行动最大化期望效用的agent.\n\n这种设计依赖于感知和agent可用的行动，agent的行为应该满足的效用函数，以及环境特性。\n\n各种不同的agent设计是可能的：\n\n反射型agent，到完全深思熟虑，基于知识的，决策理论的agent.\n\n这些设计的组成部分可以具有许多不同的实例化形式，例如逻辑或概率推理以及状态的要素化表示或结构化表示。其间的章节介绍来这些组成部分运转所依据的原理。\n\n作者：金利2020\n链接：https://www.jianshu.com/p/94c38f9bae8b\n来源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (27, 27, '人工智能约定俗成的大分类：强弱人工智能', '', '弱人工智能是指不能制造出真正地推理（Reasoning）和解决问题（Problem_solving）的智能机器，这些机器只不过看起来像是智能的，但是并不真正拥有智能，也不会有自主意识。', '科科程程', '', '弱人工智能\n弱人工智能是指不能制造出真正地推理（Reasoning）和解决问题（Problem_solving）的智能机器，这些机器只不过看起来像是智能的，但是并不真正拥有智能，也不会有自主意识。\n\n人工智能的一个比较流行的定义，也是该领域较早的定义，是由约翰·麦卡锡（John McCarthy|）在1956年的达特矛斯会议（Dartmouth Conference）上提出的：人工智能就是要让机器的行为看起来就象是人所表现出的智能行为一样。但是这个定义似乎忽略了强人工智能的可能性。另一个定义指人工智能是人造机器所表现出来的智能性（弱人工智能）。总体来讲，目前对人工智能的定义大多可划分为四类，即机器“像人一样思考”、“像人一样行动”、“理性地思考”和“理性地行动”。这里“行动”应广义地理解为采取行动，或制定行动的决策，而不是肢体动作。主流科研集中在弱人工智能上，并且一般认为这一研究领域已经取得可观的成就。\n\n中文名\n\n弱人工智能\n\n外文名\n\nAI\n\n创建人\n\n约翰·罗杰斯·希尔勒\n\n创建时间\n\n1980年\n\n目录\n\n1 发展观点\n\n2 研究方向\n\n发展观点\n\n人工智能的研究虽然取得了巨大的进步,但进一步发展不仅面临着意向性、认识框架、语境识别、方法上的还原论的哲学瓶颈问题,而且还面临着诸多哲学难题,如有可能剥夺人的思想自由、动摇人的主体性地位、危及人的存在。因此,人工智能研究必须坚持人本原则,在技术为人类所用,不危害人类长远的根本利益的前提下健康发展。 [1]\n\n塞尔认为，意向性是一种自然或生物现象，是自然生命史的一个组成部分，所以自称他的理论为“生物学的自然主义”。而要造出人工大脑，只仿造输入输出过程是不行的，而要仿造意识过程，而意识又是意向性的基础。 [2]\n\n研究方向\n\n编辑\n\n人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。AI的核心问题包括推理、知识、规划、学习、交流、感知、移动和操作物体的能力等。强人工智能目前仍然是该领域的长远目标。目前比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基于仿生学、认知心理学，以及基于概率论和经济学的算法等等也在逐步探索当中。\n\n强人工智能\n强人工智能观点认为有可能制造出真正能推理（Reasoning）和解决问题（Problem_solving）的智能机器，并且，这样的机器将被认为是有知觉的，有自我意识的。可以独立思考问题并制定解决问题的最优方案，有自己的价值观和世界观体系。有和生物一样的各种本能，比如生存和安全需求。在某种意义上可以看作一种新的文明。\n\n中文名\n\n强人工智能\n\n创立人\n\n约翰·罗杰斯·希尔勒\n\n特    点\n\n具有自我意识的人工智能\n\n创立时间\n\n 1980\n\n目录\n\n1 历史\n\n2 分类\n\n3 理论\n\n4 强人工智能需要解决的问题\n\n历史\n\n“强人工智能”一词最初是约翰·罗杰斯·希尔勒针对计算机和其它信息处理机器创造的，其定义为：\n\n“强人工智能观点认为计算机不仅是用来研究人的思维的一种工具；相反，只要运行适当的程序，计算机本身就是有思维的。”（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980。但事实上，Searle本人根本不相信计算机能够像人一样思考， 在这个论文中他不断想证明这一点。他在这里所提出的定义只是他认为的“强人工智能群体”是这么想的，并不是研究强人工智能的人们真正的想法。因此反驳他的人也不少。可参考：《 A Chinese room that Understands》- herbert A. Simon & Stuart A . Eisenstadt）。\n\n拥有“强人工智能”的机器不仅是一种工具，而且本身拥有思维。“强人工智能”有真正推理和解决问题的能力，这样的机器将被认为是有知觉，有自我意识。 [1]\n\n分类\n\n强人工智能可以有两类：\n\n类人的人工智能，即机器的思考和推理就像人的思维一样。\n\n非类人的人工智能，即机器产生了和人完全不一样的知觉和意识，使用和人完全不一样的推理方式。\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家希尔勒认为不可能。\n\n也有哲学家持不同的观点，认为人也不过是一台有灵魂的机器而已，为什么人可以有智能，而普通机器就不能呢？\n\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？希尔勒认为这是不可能的。他举了个中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，希尔勒认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n\n也有哲学家持不同的观点。Daniel C. Dennett 在其著作 Consciousness Explained 里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。 [2]\n\n强人工智能需要解决的问题\n\n人们将对于计算机来说最困难的问题，非正式地称为“人工智能完备”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n终极解释\n自然人为主的人类社会在人工智能帮助下的终极进化设想\n\n政治经济高度融合的共产主义社会是人类社会的终极阶段，具体为：\n\n共产主义 = 物质 + 能量 + 人工智能\n\n自以为现阶段的终结解答,答案发散轮123：\n\n1 无论先进的社会制度，思想意识还是经济体制也好，都需要一个先进硬件基础。只有借助“弱人工智能”实现物质极大丰富，才能实现“社会主义”，这个条件即使是目前最领先的国家，可能还要发展N年，其速度取决于弱人工智能的发展速度。\n\n2 “强人工智能”将人类自然生物个体进化到人机合一，无生物欲望：没有吃喝嫖赌抽，坑蒙拐骗偷，素质不是一般的高，就实现了真正的共产主义，所以讨论具体形态无意义。\n\n3 最终态应该是依赖强人工智，人能达到量子级别的控制能力，所谓的”人“个体将变成一个个只是参数特征值不同的能量体，即每个人都是”神“，可以控制一定范围的空间和时间，就是最强”共产主义“。\n\n附加：站在新机械唯物论的角度，一切皆为比特，即要么是量子显态为1，明物质状态，要么是量子隐态，为0，为暗物质状态，最终”共产主义“这个概念都会与”量子论“融合，即没有了社会科学与自然科学的界限。共产主义即空，空即共产主义，唯物质也，一种物质则可以被其它物质以比特矩阵的形式有意识地所计算和重现。\n\n作者：丽华人工智能学院\n链接：https://www.jianshu.com/p/eda7f352a938\n来源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (28, 27, '人工智能“奇点”在2018？现在依然是弱人工智能时代', 'http://localhost:8888/cms/upload/d6d1e260-399e-4419-9d63-1336a898bb6a.png', '“假如说，工业革新延伸了人类的‘膂力’，人工智能则延伸了人类的‘脑力’。现在方兴未已的人工智能也将深刻地影响人类的生活方式，变成人类开展的又一里程碑。”6月13日，在华夏基金与微软亚洲研讨院举行的战略协作发布会上，华夏基金总经理汤晓东表明。', '科科程程', '', '人工智能作为战略性新兴工业一员，初次被写入《政府工作陈述》。人工智能逐渐变成公认的风口，那么，风来了吗？\n\n“假如说，工业革新延伸了人类的‘膂力’，人工智能则延伸了人类的‘脑力’。现在方兴未已的人工智能也将深刻地影响人类的生活方式，变成人类开展的又一里程碑。”6月13日，在华夏基金与微软亚洲研讨院举行的战略协作发布会上，华夏基金总经理汤晓东表明。\n\n早在2015年，智能投顾逐渐在国内被认可。据《我国经营报》记者大略核算，仅A股商场上包含广发证券、华泰证券、国信证券、同花顺、恒生电子、长江证券等十余家上市公司现已在不一样程度上涉水，互联网金融渠道及金融科技公司等泛金融组织进入智能投顾的事例更是不在少数。\n\n组织抢滩\n\n汤晓东幽默解读华夏基金和微软的战略协作，是金融和科技的磕碰，是人脑智慧和人工智能的交融，是“金融狗”和“程序猿”的牵手。他指出，人工智能方兴未已，有望顶替互联网敞开下一轮科技革新，催生一大批千亿级甚至万亿级的新经济工业和出资时机。\n\n据了解，两边期望就人工智能在金融效劳范畴的运用打开战略协作研讨，将联系微软在人工智能范畴的深沉沉淀以及华夏基金强壮的投研实力，旨在探究智能出资的疆界，推动财物办理职业智能化转型。\n\n其间，“智能出资”是这次两边协作研讨的关键和重点，研讨方向包含经过模式辨认猜测商场走势、依据深度学习挖掘影响商场的重要因素、依据机器学习办法论进行职业轮动的研讨、依据大数据构建金融图谱、依据交际网络与运用软件等运用数据，辨认并深度了解客户等。据泄漏，除了现在两边在智能出资等范畴的研讨协作，将来可以一起探究的范畴也十分宽广。\n\n业内调查人士剖析以为，跟着华夏基金与微软研讨院强强联手，在国内出资智能化的战场上，又杀入了一位悍将。\n\n这些年，科技巨子纷纷经过各种方式在人工智能范畴加快规划，抢占战略制高点。阿里研讨院在2017年发布陈述中指出，核算才能+、大数据+、深度学习算法是人工智能鼓起的三大柱石，三者相得益彰、相互依赖、相互促进，使得人工智能有时机从专用的技能变成通用的技能，融入到各行各业之中。\n\n人工智能在收获的秋天何时到来？2017年头，日本软银CEO孙正义在国际移动通讯大会上表明，2018年人工智能迸发的“奇点”就会到来。不过，阿里研讨院则相对慎重，他们表明，假如依照人工智能的水平分为弱人工智能年代、强人工智能年代和超强人工智能年代三个大的期间来看的话，现在依然是弱人工智能年代，人工智能技能还首要为了解决特定的疑问而存在，是任务型的人工智能。\n\n详细到金融范畴，阿里研讨院以为，人工智能贯穿新金融从客服、风控到事务全流程的立异。人工智能将来会重构金融效劳的生态，变成普惠金融的柱石，驱动着金融的个性化、场景化效劳变成首要立异方向。伴跟着依据大数据的机器学习算法的开展以及语音辨认、人脸辨认、自然语言处理技能的日趋老练，人工智能技能现已在贷款效劳、出资、稳妥、征信、危险操控、客户效劳等多个范畴。\n\n天风证券剖析师何翩翩指出，当时，金融出资范畴与人工智能的联系运用，首要是依照智能投顾的思路在推动，依照财物办理链条划分，无外乎咨询主张型、财物装备型、财物办理型三大类。\n\n那么奥秘的智能投顾究竟是怎么运作？何翩翩指出，智能投顾也叫机器人投顾，是依据现代财物组合理论、联系个人出资者的危险偏好和理财方针、使用算法和友爱的互联网界面，为客户供给财物办理和在线出资主张效劳。金融工程可视作当今智能投顾的前身，跟着人工智能、云核算、大数据年代的到来，金融工程已演化变成高主动化的智能投顾东西。\n\n智能投顾的效劳流程则包含：客户剖析、大类财物装备、出资组合挑选、买卖履行、出资组合再平衡与剖析等，其间，出资组合剖析仅面向专业用户。在客户剖析、大类财物装备、以及出资组合挑选，这三步中心环节中，智能投顾软件会依据客户的危险水平与出资期限，而核算时机凭借危险涣散等传统的出资理论以及量化出资战略等办法构建出资组合，并在投后进程实时盯梢微观事情、商场和出资者偏好的改变等状况，进行主动风控和授权后的主动调仓。\n\n“从前期的金融工程诞生到后来的量化买卖鼓起再到科技金融走俏，技能对金融的影响是在继续深化，有许多同行都看到这一机会在储藏发力。” 利得金融集团董事长李兴春博士对记者表明。\n\n智能投顾秣兵历马\n\n顺财证券研讨员冯钦远指出，智能投顾职业阅历了“主题战略——量化战略——出资组合——大类财物装备——全球财物装备——差异化增值效劳”的开展进程。在现在无法实现代客理财的状况下，以券商为代表的金融组织正在从不一样层面切入智能投顾范畴。\n\n冯钦远格外指出，与传统金融组织切入智能投顾比较，国内智能投顾草创公司面对的应战更为严峻。首要，取得精准客户的难度不小；其次，智能投顾的根底是技能和数据，这是草创公司不行逃避的短板；别的，国内智能投顾的商场乱象现已导致监管部门留意。与此同时，智能投顾涉及到出资咨询、产品销售、财物办理，只有打通这三块事务才能实现代客理财，而国内这三块车牌别离发放和监管，草创公司需要跨过的车牌门槛不低。\n\n李兴春以为，现在业界对智能投顾的试水仍需求打磨，“机器自动学习是打破的要点”。华泰证券研究员林晓明在其最新研报中指出，人工智能和机器学习并不奥秘，其本质是以数理模型为中心东西，联系控制论、认知心理学等别的学科的研究成果，终究由计算机系统模仿人类的感知、推理、学习、决议计划等功能。\n\n在出资界，人工智能的奇点是不是现已来到？华夏基金副总经理、出资总监阳琨以为，计算机事实上现已在改动出资，将来，人工智能变成财物办理团队的出资帮手，优化出资决议计划，提升出资功率的趋势毋庸置疑。\n\n现在来看，国内智能投顾公司良莠不齐，因素在于智能投顾公司不只需求在商品和效劳维度进行技能立异，其算法与技能还需习惯中国市场的国情，并进行有用的出资者教学、与监管部门的交流，完成办理和运营的立异，何翩翩以为，较好的智能投顾公司大多与基金公司、券商或互联网公司推出子商品。\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (29, 27, 'ACE人工智能区块链：区块链之上，再来点人工智能', '', '在新一轮科技革命和产业变革中，数字经济已成为引领创新和驱动转型的先导力量，正在加速重构全球经济新版图，也成为中国经济转型增长的重要一极。北京、上海、广州、深圳、杭州等地都相继出台了数字经济发展相关指导政策', '科科程程', '', 'ACE人工智能区块链：区块链之上，再来点人工智能\n\n《中国数字经济发展与就业白皮书（2019年）》数据显示，2018年，我国数字经济规模31.3万亿元，按可比口径计算，名义增长20.9%，对GDP的贡献率达到67.9%，已成为拉动经济增长和推动经济转型升级的重要驱动力。新一代信息技术蓬勃发展，5G、云计算、大数据、人工智能与实体经济深度融合引领原始创新，从人人互联到万物互联、从海量数据到人工智能，新要素正在形成、新动能正在激发、新集群正在孕育。\n\n在新一轮科技革命和产业变革中，数字经济已成为引领创新和驱动转型的先导力量，正在加速重构全球经济新版图，也成为中国经济转型增长的重要一极。北京、上海、广州、深圳、杭州等地都相继出台了数字经济发展相关指导政策，这些都表明了国家将积极发展新一代的信息技术产业和数字经济，推动互联网、物联网、大数据、卫星导航、人工智能、区块链和市场经济的深度融合。\n\n\n身处新一代信息技术产业高速发展浪潮中，积极响应国家的发展策略导向，ACE人工智能区块链有着一个很清晰的发展蓝图，已着手进行对区块链、大数据、人工智能布局。\n\n从产业链来看，人工智能的发展逻辑主要有三个核心层：基础层、技术层及应用层。在基础层方面，计算技术得到广泛的运用，为人工智能技术的实现和人工智能应用的落地提供基础的后台保障，是一切人工智能应用得以实现的大前提；人工智能技术层，主要有语音识别、计算机视觉、深度学习领域。人工智能应用非常广泛，目前金融、汽车、零售、大健康、安防、教育等领域都有涉及。\n\n正在慢慢打开新世纪大门的人工智能行业，始终有一个痛点无法解决：那就是人工智能需要大量算力的支撑，没有算力，基础层无法稳定，技术层无法突破，应用程序无法落地，无疑现在算力项目成为了未来商业必争之地。\n\n\n应运而生的ACE人工智能区块链能够为未来全行业提供大量的算力之外，还能帮助实现信息的安全存储，防篡改防攻击，让物联网网络更加安全可靠，降低联网成本。可以说，有了ACE人工智能区块链的存在，全球未来的人工智能产业链发展都会踏上快车道，快速驶向新的时代。\n\nACE人工智能区块链基于ALICE公链将全球的算力节点化，在全球都拥有自己的租户和处理器。不管你在全球任意一个角落，如果你的人工智能产业研发需要大量的算力，也可以加入ACE人工智能区块链，就可以无视空间距离，随时随地畅享ACE人工智能区块链带来的好处和优势。\n\nACE人工智能区块链这个项目，不单单是从技术层角度推动人工智能产业的发展，更能从应用层带来驱动普通用户动力的利益，在ACE人工智能区块链中，从行业发展的角度来看，人工智能的算力需求明显，加入ACE人工智能区块链是完全可以赚钱满足绝大多数用户的盈利想法。\n\n人工智能一直是我国大力支的科技产业，作为前沿科技的区块链同样拥有非常强大的作用，业内人士认为，人工智能与区块链的联动将会产生积极的化学反应，并成为推动彼此的一股新力量。\n\nACE人工智能区块链对人工智能的推动作用\n\n首先，ACE人工智能区块链可以提高人工智能的有效性，从而确保数据共享的安全性；\n\n其次，ACE人工智能区块链还可以帮助人工智能妥善处理黑盒问题，获取清晰的数据检索方案，这不仅有利于提高数据与模型的可信度，还可以为机器决策提供清晰的路径。\n\n此外，ACE人工智能区块链可以对数据进行保护，并帮助清洗个人数据，提高数据有效性。便捷的数据共享与新市场的产生，以及ACE人工智能区块链的数据审查技术，能够互相融合，从而降低小企业的参与壁垒，均衡企业实力。\n\nACE人工智能区块链：区块链+AI有机会成下一个重要发展趋势\n\nACE人工智能区块链为什么要将区块链和AI连接在一起？AI到底有多重要？为什么让起步不到十年的区块链与AI结合呢？\n\n根据了解，人工智能被誉为引领未来的战略性技术，是提升国家竞争力、维护国家安全的核心技术之一，也将成为经济发展中新一轮产业变革的核心驱动力。\n\nACE人工智能区块链提高AI数据共享能力\n\n在ACE人工智能区块链能保障训练数据真实可靠性的前提下，可通过ACE人工智能区块链的分布式数据存储方式，大幅度减少一台人工智能深度学习训练的时间。\n\n人工智能面部识别就是一个很好的例子。假设将人脸通过一台设备识别存储之后，其他的设备也收到了我们人脸存储的信息，也获得我们面部识别的能力。\n\n区块链+人工智能，ACE人工智能区块链七大优势\n\n最后，我们可以把ACE人工智能区块链优势括为以下七点。\n\nACE人工智能区块链可以提高人工智能的数据安全性\n\nACE人工智能区块链可以加速数据的累积，给人工智能提供更强大的数据支持，解决AI的数据供应问题\n\nACE人工智能区块链可以解决数据收集时的数据隐私问题\n\n人工智能可以减少ACE人工智能区块链的电力消耗\n\nACE人工智能区块链使得人工智能更加的可信任\n\nACE人工智能区块链帮助人工智能缩短训练时间\n\nACE人工智能区块链有助于打造一个更加开放与公平化的人工智能市场。\n\n\n不过，值得注意的是，今天的ACE人工智能区块链还刚刚起步，如果将其比作一个人，那么他们还是嗷嗷待哺的婴儿，还不具备自立的能力。因此，对于ACE人工智能区块链而言，当前最重要的使命依然是完善和成长。\n\n未来，只有两大技术都相对成熟，并且有一定规模的应用落地，这样两者的协同与结合才更有价值和使用空间。当然，这是ACE人工智能区块链的趋势，这也是我们未来的发展的大趋势。\n\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (30, 27, '新一代人工智能发展的机遇 --《新一代人工智能发展白皮书》', '', '随着生物识别技术、自然语音处理技术、大数据驱动的智能感知、理解等技术的不断发展和深入，人工智能的技术瓶颈以及应用成本已从根本上得以突破人工智能从诞生至今，人工智能已有 60 年的发展历史，大致经历了三次浪潮。第一次浪潮为 20 世纪 50 年代末至 20 世纪80 年代初', '科科程程', '', '一、概述\n随着生物识别技术、自然语音处理技术、大数据驱动的智能感知、理解等技术的不断发展和深入，人工智能的技术瓶颈以及应用成本已从根本上得以突破。这使得人工智能的发展也日趋接近于人类智能水平，人工智能正从学术驱动转变为应用驱动、从专用智能迈向通用智能。根据新一代人工智能面临的新形势、驱动的新因素、呈现的新特征，本文的目的是通过对《新一代人工智能发展白皮书》学习，对人工智能发展的历史、驱动要素、主要特征、技术架构及产业化应用等方面进行概述，使从事人工智能领域研究、开发、生产及服务型企业及个人对新一代人工智能有一定的认知，也希望从中掌握新一代人工智能的发展机遇，制定企业发展战略和个人规划，使其能在行业中占有一席之地。\n\n二、人工智能发展历程\n人工智能从诞生至今，人工智能已有 60 年的发展历史，大致经历了三次浪潮。第一次浪潮为 20 世纪 50 年代末至 20 世纪80 年代初；第二次浪潮为 20 世纪 80 年代初至 20 世纪末；第三次浪潮为 21 世纪初至今。在人工智能的前两次浪潮当中，由于技术未能实现突破性进展，相关应用始终难以达到预期效果，无法支撑起大规模商业化应用，最终在经历过两次高潮与低谷之后，人工智能归于沉寂。随着信息技术快速发展和互联网快速普及，以 2006 年深度学习模型的提出为标志，人工智能迎来第三次高速成长[摘抄原文]。\n\n三、驱动人工智能发展的要素\n3.1人机物互联互通成趋势，数据量呈现爆炸性增长\n随着互联网、社交媒体、移动设备和传感器的大量普及，其产生并存储的数据量急剧增加，为通过深度学习的方法来训练人工智能提供了良好的土壤，海量的数据将为人工智能算法模型提供源源不断的素材，人工智能从各行业、各领域的海量数据中积累经验、发现规律、使其深度学习成果得以持续提升。\n\n3.2数据处理及运算能力的大幅提升\n人工智能领域富集了海量数据，传统的数据处理技术难以满足高强度、 高频次的处理需求，人工智能一个神经元的处理需要数百甚至上千条指令才能完成，传统主流的X86、ARM的CPU架构难已与之匹配。目前，出现了 GPU、 NPU、 FPGA 和各种各样的 AI-PU专用芯片，这些人工智能芯片的出现加速了深层神经网络的训练迭代速度，让大规模的数据处理效率显著提升，极大地促进了人工智能行业的发展。\n\n3.3深度学习研究成果卓著，带动算法模型持续优化\n2006 年，加拿大多伦多大学教授杰弗里•辛顿提出了深度学习的概念，极大地发展了人工神经网络算法，提高了机器自学习的能力。随着算法模型的重要性进一步凸显，全球科技巨头纷纷加大了这方面的布局力度和投入，通过成立实验室，开源算法框架，打造生态体系等方式推动算法模型的优化和创新。目前，深度学习等算法已经广泛应用在自然语言处理、语音处理以及计算机视觉等领域，并在某些特定领域取得了突破性进展，从有监督式学习演化为半监督式、无监督式学习。\n\n3.4资本与技术深度耦合，助推行业应用快速兴起\n当前，在技术突破和应用需求的双重驱动下，人工智能技术已走出实验室，加速向产业各个领域渗透，产业化水平大幅提升。在此过程中，资本作为产业发展的加速器发挥了重要的作用，一方面，跨国科技巨头以资本为杠杆，展开投资并购活动，得以不断完善产业链布局。人工智能已在智能机器人、无人机、金融、医疗、安防、驾驶、搜索、教育等领域得到了较为广泛的应用。\n\n四、新一代人工智能主要特征\n4.1大数据成为人工智能持续快速发展的基石\n智能终端和传感器的快速普及，海量数据快速累积；计算能力、数据处理能力和处理速度实现了大幅提升，机器学习算法快速演进，大数据的价值得以展现。新一代人工智能是由大数据驱动的，通过给定的学习框架，不断根据当前设置及环境信息修改、更新参数，具有高度的自主性。例如，在输入 30 万张人类对弈棋谱并经过 3 千万次的自我对弈后，人工智能 AlphaGo 具备了媲美顶尖棋手的棋力。\n\n4.2文本、图像、语音等信息实现跨媒体交互\n计算机图像识别、语音识别和自然语言处理等技术在准确率及效率方面取得了明显进步，并成功应用在无人驾驶、智能搜索等垂直行业。与此同时，随着互联网、智能终端的不断发展，多媒体数据呈现爆炸式增长，并以网络为载体在用户之间实时、动态传播，文本、图像、语音、视频等信息突破了各自属性的局限，实现跨媒体交互，智能化搜索、个性化推荐的需求进一步释放。未来人工智能将逐步向人类智能靠近，模仿人类综合利用视觉、语言、听觉等感知信息，实现识别、推理、设计、创作、预测等功能。\n\n4.3基于网络的群体智能技术的应用\n随着互联网、云计算等新一代信息技术的快速应用及普及，大数据不断累积，深度学习及强化学习等算法不断优化，人工智能研究的焦点，已从单纯用计算机模拟人类智能，打造具有感知智能及认知智能的单个智能体，向打造多智能体协同的群体智能转变。群体智能充分体现了“通盘考虑、统筹优化”思想，具有去中心化、自愈性强和信息共享高效等优点，相关的群体智能技术已经开始萌芽并成为研究热点。例如，我国研究开发了固定翼无人机智能集群系统，并于 2017 年 6月实现了 119 架无人机的集群飞行。\n\n4.4自主智能系统成为新兴发展方向\n随着生产制造智能化改造升级的需求日益凸显，通过嵌入智能系统对现有的机械设备进行改造升级成为更加务实的选择。在中国制造 2025引导下，自主智能系统正成为人工智能的重要发展及应用方向。例如，沈阳机床以 i5 智能机床为核心，打造了若干智能工厂，实现了“设备互联、数据互换、过程互动、产业互融”的智能制造模式。\n\n4.5人机协同正在催生新型混合智能形态\n人类智能在感知、推理、归纳和学习等方面具有机器智能无法比拟的优势，机器智能则在搜索、计算、存储、优化等方面领先于人类智能，两种智能具有很强的互补性。人与计算机协同，互相取长补短将形成一种新的“1+1>2”的增强型智能，也就是混合智能，这种智能是一种双向闭环系统，既包含人，又包含机器组件。其中人可以接受机器的信息，机器也可以读取人的信号， 两者相互作用，互相促进。在此背景下，人工智能的根本目标已经演进为提高人类智力活动能力，更智能地陪伴人类完成复杂多变的任务。\n\n五、新一代人工智能技术框架\n5.1新一代人工智能的技术演变\n5.1.1 从原有的 CPU 架构，转变为 GPU 并行运算架构\n大数据技术带来的数据洪流满足了人工智能的深度学习算法对于训练数据量的要求，但是算法的实现还需要更快更强大的处理器予以支撑。当前主流的 CPU 只有 4 核或者 8 核，可以模拟出 12 个处理线程来进行运算，但是普通级别的 GPU 就包含了成百上千个处理单元，高端的甚至更多，可以快速处理图像上的每一个像素点，其海量数据并行运算的能力与深度学习需求非常符合。这对于多媒体计算中大量的重复处理过程有着天生的优势。吴恩达教授领导的谷歌大脑研究工作结果表明， 12 颗英伟达（Nvidia）公司的 GPU 可以提供相当于 2000 颗 CPU 的深度学习性能，为人工智能技术的发展带来了实质性飞跃。\n\n5.1.2从单一算法驱动，转变为数据、运算力、算法复合驱动\n与早期人工智能相比，新一代人工智能体现出数据、运算力和算法相互融合、优势互补的良好特点。1、数据方面，人类进入互联网时代后，数据技术高速发展，各类数据资源不断积累，为人工智能的训练学习过程奠定了良好的基础。2、运算力方面，摩尔定律仍在持续发挥效用，计算系统的硬件性能逐年提升，云计算、并行计算、网格计算等新型计算方式的出现拓展了现代计算机性能，获得更快的计算速度。3、算法方面，伴随着深度学习技术的不断成熟，运算模型日益优化，智能算法不断更新，提升了模型辨识解析的准确度。\n\n5.1.3从封闭的单机系统，转变为快捷灵活的开源框架\n人工智能系统的开发工具日益成熟，通用性较强且各具特色的开源框架不断涌现，如谷歌的TensorFlow、Facebook 的Torchnet、百度的PaddlePaddle 等，其共同特点均是基于 Linux 生态系统，具备分布式深度学习数据库和商业级即插即用功能，能够在GPU 上较好地继承 Hadoop 和 Spark 架构，广泛支持 Python、Java、 Scala、 R 等流行开发语言，与硬件结合生成各种应用场景下的人工智能系统与解决方案。\n\n5.1.4从学术研究探索导向，转变为快速迭代的实践应用导向\n目前，人工智能围绕医疗、金融、交通、教育、零售等数据较集中且质量较高的行业的实践需求，在算法模型、图像识别、自然语言处理等方面将持续出现迭代式的技术突破，在深度应用中支撑人工智能实现“数据-技术-产品-用户”的往复正循环，正由学术驱动向应用拉动转化。在人工智能技术准备期，由于提供数据支撑较少，技术提升度慢，一旦进入应用期，大量的优质数据有助于分析技术弊端，通过对相关技术进行改进升级，提升了产品的应用水平，用户在得到更好的产品体验后，继续为应用平台创造了更大规模的后台数据，用来进行下一步的技术升级与产品改良，由此进入了大规模应用阶段。在技术快速迭代发展的过程中，数据累积和大规模应用起到了至关重要的作用，能够持续推动人工智能技术实现自我超越。\n\n5.2新一代人工智能技术体系\n新一代人工智能技术体系由基础技术平台和通用技术体系构成，其中基础技术平台包括云计算和大数据平台，通用技术体系包括机器学习、模式识别与人机交互。\n\n5.2.1云计算：基础的资源整合交互平台\n云计算主要共性技术包括虚拟化技术、分布式技术、计算管理技术、云平台技术和云安全技术，具备实现资源快速部署和服务获取、进行动态可伸缩扩展及供给、面向海量信息快速有序化处理、可靠性高、容错能力强等特点，为人工智能的发展提供了资源整合交互的基础平台。尤其与大数据技术结合，为当前受到最多关注的深度学习技术搭建了强大的存储和运算体系架构，促进了神经网络模型训练优化过程，显著提高语音、图片、文本等辨识对象的识别率。\n\n5.2.2 大数据：提供丰富的分析、训练与应用资源\n大数据主要共性技术包括采集与预处理、存储与管理、计算模式与系统、分析与挖掘、可视化计算及隐私及安全等，具备数据规模不断扩大、种类繁多、产生速度快、处理能力要求高、时效性强、可靠性要求严格、价值大但密度较低等\n\n特点，为人工智能提供丰富的数据积累和价值规律，引发分析需求。同时，从跟踪静态数据到结合动态数据，可以推动人工智能根据客观环境变化进行相应的改变和适应，持续提高算法的准确性与可靠性。\n\n5.2.3机器学习：持续引导机器智能水平提升\n机器学习指通过数据和算法在机器上训练模型，并利用模型进行分析决策与行为预测的过程。机器学习技术体系主要包括监督学习和无监督学习，目前广泛应用在专家系统、认知模拟、数据挖掘、图像识别、故障诊断、自然语言理解、\n\n机器人和博弈等领域。机器学习作为人工智能最为重要的通用技术，未来将持续引导机器获取新的知识与技能，重新组织整合已有知识结构，有效提升机器智能化水平，不断完善机器服务决策能力。\n\n作者：XuPL\n链接：https://www.jianshu.com/p/f7467fd06e96\n来源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (31, 25, '一般实现分布式锁都有哪些方式?使用 redis 如何设计分布式锁', '', '一般实现分布式锁都有哪些方式？使用 redis 如何设计分布式锁？使用 zk 来设计分布式锁可以吗？这两种分布式锁的实现方式哪种效率比较高？其实一般问问题，都是这么问的，先问问你 zk，然后其实是要过度到 zk 关联的一些问题里去，比如分布式锁。因为在分布式系统开发中，分布式锁的使用场景还是很常见的。', '科科程程', '', '面试题\n一般实现分布式锁都有哪些方式？使用 redis 如何设计分布式锁？使用 zk 来设计分布式锁可以吗？这两种分布式锁的实现方式哪种效率比较高？\n\n面试官心理分析\n其实一般问问题，都是这么问的，先问问你 zk，然后其实是要过度到 zk 关联的一些问题里去，比如分布式锁。因为在分布式系统开发中，分布式锁的使用场景还是很常见的。\n\n面试题剖析\nredis 分布式锁\n官方叫做 RedLock 算法，是 redis 官方支持的分布式锁算法。\n\n这个分布式锁有 3 个重要的考量点：\n\n互斥（只能有一个客户端获取锁）\n不能死锁\n容错（只要大部分 redis 节点创建了这把锁就可以）\nredis 最普通的分布式锁\n第一个最普通的实现方式，就是在 redis 里创建一个 key，这样就算加锁。\n\nSET my:lock 随机值 NX PX 30000\n执行这个命令就 ok。\n\nNX：表示只有 key 不存在的时候才会设置成功。（如果此时 redis 中存在这个 key，那么设置失败，返回 nil）\nPX 30000：意思是 30s 后锁自动释放。别人创建的时候如果发现已经有了就不能加锁了。\n释放锁就是删除 key ，但是一般可以用 lua 脚本删除，判断 value 一样才删除：\n\n-- 删除锁的时候，找到 key 对应的 value，跟自己传过去的 value 做比较，如果是一样的才删除。\nif redis.call(\"get\",KEYS[1]) == ARGV[1] then\n    return redis.call(\"del\",KEYS[1])\nelse\n    return 0\nend\n为啥要用随机值呢？因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，比如说超过了 30s，此时可能已经自动释放锁了，此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除 key 的话会有问题，所以得用随机值加上面的 lua 脚本来释放锁。\n\n但是这样是肯定不行的。因为如果是普通的 redis 单实例，那就是单点故障。或者是 redis 普通主从，那 redis 主从异步复制，如果主节点挂了（key 就没有了），key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。\n\nRedLock 算法\n这个场景是假设有一个 redis cluster，有 5 个 redis master 实例。然后执行如下步骤获取一把锁：\n\n获取当前时间戳，单位是毫秒；\n跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；\n尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1；\n客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；\n要是锁建立失败了，那么就依次之前建立过的锁删除；\n只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。\nredis-redlock\nzk 分布式锁\nzk 分布式锁，其实可以做的比较简单，就是某个节点尝试创建临时 znode，此时创建成功了就获取了这个锁；这个时候别的客户端来创建锁会失败，只能注册个监听器监听这个锁。释放锁就是删除这个 znode，一旦释放掉就会通知客户端，然后有一个等待着的客户端就可以再次重新加锁。\n\n/**\n * ZooKeeperSession\n * \n * @author bingo\n * @since 2018/11/29\n *\n */\npublic class ZooKeeperSession {\n\n    private static CountDownLatch connectedSemaphore = new CountDownLatch(1);\n\n    private ZooKeeper zookeeper;\n    private CountDownLatch latch;\n\n    public ZooKeeperSession() {\n        try {\n            this.zookeeper = new ZooKeeper(\"192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181\", 50000, new ZooKeeperWatcher());\n            try {\n                connectedSemaphore.await();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n\n            System.out.println(\"ZooKeeper session established......\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 获取分布式锁\n     * \n     * @param productId\n     */\n    public Boolean acquireDistributedLock(Long productId) {\n        String path = \"/product-lock-\" + productId;\n\n        try {\n            zookeeper.create(path, \"\".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);\n            return true;\n        } catch (Exception e) {\n            while (true) {\n                try {\n                    // 相当于是给node注册一个监听器，去看看这个监听器是否存在\n                    Stat stat = zk.exists(path, true);\n\n                    if (stat != null) {\n                        this.latch = new CountDownLatch(1);\n                        this.latch.await(waitTime, TimeUnit.MILLISECONDS);\n                        this.latch = null;\n                    }\n                    zookeeper.create(path, \"\".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);\n                    return true;\n                } catch (Exception ee) {\n                    continue;\n                }\n            }\n\n        }\n        return true;\n    }\n\n    /**\n     * 释放掉一个分布式锁\n     * \n     * @param productId\n     */\n    public void releaseDistributedLock(Long productId) {\n        String path = \"/product-lock-\" + productId;\n        try {\n            zookeeper.delete(path, -1);\n            System.out.println(\"release the lock for product[id=\" + productId + \"]......\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 建立zk session的watcher\n     * \n     * @author bingo\n     * @since 2018/11/29\n     *\n     */\n    private class ZooKeeperWatcher implements Watcher {\n\n        public void process(WatchedEvent event) {\n            System.out.println(\"Receive watched event: \" + event.getState());\n\n            if (KeeperState.SyncConnected == event.getState()) {\n                connectedSemaphore.countDown();\n            }\n\n            if (this.latch != null) {\n                this.latch.countDown();\n            }\n        }\n\n    }\n\n    /**\n     * 封装单例的静态内部类\n     * \n     * @author bingo\n     * @since 2018/11/29\n     *\n     */\n    private static class Singleton {\n\n        private static ZooKeeperSession instance;\n\n        static {\n            instance = new ZooKeeperSession();\n        }\n\n        public static ZooKeeperSession getInstance() {\n            return instance;\n        }\n\n    }\n\n    /**\n     * 获取单例\n     * \n     * @return\n     */\n    public static ZooKeeperSession getInstance() {\n        return Singleton.getInstance();\n    }\n\n    /**\n     * 初始化单例的便捷方法\n     */\n    public static void init() {\n        getInstance();\n    }\n\n}\n也可以采用另一种方式，创建临时顺序节点：\n\n如果有一把锁，被多个人给竞争，此时多个人会排队，第一个拿到锁的人会执行，然后释放锁；后面的每个人都会去监听排在自己前面的那个人创建的 node 上，一旦某个人释放了锁，排在自己后面的人就会被 zookeeper 给通知，一旦被通知了之后，就 ok 了，自己就获取到了锁，就可以执行代码了。\n\npublic class ZooKeeperDistributedLock implements Watcher {\n\n    private ZooKeeper zk;\n    private String locksRoot = \"/locks\";\n    private String productId;\n    private String waitNode;\n    private String lockNode;\n    private CountDownLatch latch;\n    private CountDownLatch connectedLatch = new CountDownLatch(1);\n    private int sessionTimeout = 30000;\n\n    public ZooKeeperDistributedLock(String productId) {\n        this.productId = productId;\n        try {\n            String address = \"192.168.31.187:2181,192.168.31.19:2181,192.168.31.227:2181\";\n            zk = new ZooKeeper(address, sessionTimeout, this);\n            connectedLatch.await();\n        } catch (IOException e) {\n            throw new LockException(e);\n        } catch (KeeperException e) {\n            throw new LockException(e);\n        } catch (InterruptedException e) {\n            throw new LockException(e);\n        }\n    }\n\n    public void process(WatchedEvent event) {\n        if (event.getState() == KeeperState.SyncConnected) {\n            connectedLatch.countDown();\n            return;\n        }\n\n        if (this.latch != null) {\n            this.latch.countDown();\n        }\n    }\n\n    public void acquireDistributedLock() {\n        try {\n            if (this.tryLock()) {\n                return;\n            } else {\n                waitForLock(waitNode, sessionTimeout);\n            }\n        } catch (KeeperException e) {\n            throw new LockException(e);\n        } catch (InterruptedException e) {\n            throw new LockException(e);\n        }\n    }\n\n    public boolean tryLock() {\n        try {\n            // 传入进去的locksRoot + “/” + productId\n            // 假设productId代表了一个商品id，比如说1\n            // locksRoot = locks\n            // /locks/10000000000，/locks/10000000001，/locks/10000000002\n            lockNode = zk.create(locksRoot + \"/\" + productId, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);\n   \n            // 看看刚创建的节点是不是最小的节点\n            // locks：10000000000，10000000001，10000000002\n            List<String> locks = zk.getChildren(locksRoot, false);\n            Collections.sort(locks);\n    \n            if(lockNode.equals(locksRoot+\"/\"+ locks.get(0))){\n                //如果是最小的节点,则表示取得锁\n                return true;\n            }\n    \n            //如果不是最小的节点，找到比自己小1的节点\n      int previousLockIndex = -1;\n            for(int i = 0; i < locks.size(); i++) {\n        if(lockNode.equals(locksRoot + “/” + locks.get(i))) {\n                    previousLockIndex = i - 1;\n            break;\n        }\n       }\n       \n       this.waitNode = locks.get(previousLockIndex);\n        } catch (KeeperException e) {\n            throw new LockException(e);\n        } catch (InterruptedException e) {\n            throw new LockException(e);\n        }\n        return false;\n    }\n\n    private boolean waitForLock(String waitNode, long waitTime) throws InterruptedException, KeeperException {\n        Stat stat = zk.exists(locksRoot + \"/\" + waitNode, true);\n        if (stat != null) {\n            this.latch = new CountDownLatch(1);\n            this.latch.await(waitTime, TimeUnit.MILLISECONDS);\n            this.latch = null;\n        }\n        return true;\n    }\n\n    public void unlock() {\n        try {\n            // 删除/locks/10000000000节点\n            // 删除/locks/10000000001节点\n            System.out.println(\"unlock \" + lockNode);\n            zk.delete(lockNode, -1);\n            lockNode = null;\n            zk.close();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } catch (KeeperException e) {\n            e.printStackTrace();\n        }\n    }\n\n    public class LockException extends RuntimeException {\n        private static final long serialVersionUID = 1L;\n\n        public LockException(String e) {\n            super(e);\n        }\n\n        public LockException(Exception e) {\n            super(e);\n        }\n    }\n}\nredis 分布式锁和 zk 分布式锁的对比\nredis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能。\nzk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。\n另外一点就是，如果是 redis 获取锁的那个客户端 出现 bug 挂了，那么只能等待超时时间之后才能释放锁；而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。\n\nredis 分布式锁大家没发现好麻烦吗？遍历上锁，计算时间等等......zk 的分布式锁语义清晰实现简单。\n\n所以先不分析太多的东西，就说这两点，我个人实践认为 zk 的分布式锁比 redis 的分布式锁牢靠、而且模型简单易用。\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (32, 25, '分布式锁，分布式事务，分布式job', '', '弱一致性(基于MQ的最终一致性)强一致性(基于XA二段提交的强一致性)分布式JOB（任务调度）分㐊全局一致性（分布式锁）分布式场景下的session一致性弱一致性(基于MQ的最终一致性)强一致性(基于XA二段提交的强一致性)分布式JOB（任务调度）分㐊全局一致性（分布式锁）', '科科程程', '', '分布式事务：\n\n弱一致性(基于MQ的最终一致性)\n\n强一致性(基于XA二段提交的强一致性)\n\n分布式JOB（任务调度）\n\n分㐊全局一致性（分布式锁）\n\n分布式场景下的session一致性\n\nCAP:\n\n![Description](https://upload-images.jianshu.io/upload_images/12016719-67d9c9207fb62944?imageMogr2/auto-orient/strip|imageView2/2/w/640/format/webp)\n\nC:数据一致性(数据从一个事务到另一个事务时一致的)\n\nA：服务可用性，所有读写请求在一定时间内得到相应，可终止，不会一直等待\n\nP：分钱容错性，在网络分区的情况下，被分隔的节点仍能正常对外服务\n\nbase理论：基本可用，服务降级\n\njta，XA接口，2PC\n\njta：java操作xa接口\n\njta+automatic\n\nXA接口：全局事务（事务管理器，本地事务）\n\n2PC：二段提交协议（准备和提交）\n\nLCN分布式事务框架官网:http://www.txlcn.org/\n\n1、lcn事务原理：不生产事务，只是事务的搬运工（事务协调者TX，本地事务）\n\n2、发起方：调用其他服务接口\n\n3、参与方：被别人调用我接口\n\n1.创建事务分组（发起方创建事务分组，获取到分组ID，将分组ID发给事务协调者）\n\n2、http协议，通过请求头将事务分组传递给参与方\n\n3、参与方从请求头里面获取到事务分组ID\n\n4、参与方获取到事务分组之后，不会去提交事务\n\n5、lcn假关闭。发起方通知TX,TX通知参与方提交或者回滚事务。\n\n\n任务调度：定时JOB，在什么时候进行执行代码任务\n\n场景：标的放款与标的还款每5秒跑一次。\n\njava实现定时任务几种方式：\n\nThread(死循环一直监听),\n\nTimeTask,\n\n线程池定时线程ScheduledExecutorService .scheduleAtFixedRate(new Runnable),1,1,TimeUnit.SECONDS),\n\nquartz,springboot\n\n分布式JOB如何解决幂等性：\n\n1、分布式锁（zk、redis），保证只有一台服务器执行job，zk与redis分布式锁的区别？\n\n2、使用配置文件，配置文件开关，加一个配置文件 start=true、false，true执行job，false不执行job，一个配置文件为true其余全为false\n\n3、使用数据库唯一标识（年月日），成功就执行，失败就不执行，缺点：效率低。\n\n传统任务调度 缺点：\n\n1、执行中出现异常，就停止了，没有补充机制，只有等到下一次才会执行。\n\n2、支持集群？随机出现在某一台机器上面执行（权重）\n\n3、不支持路由策略（负载均衡）\n\n4、统计（几百个服务，那些执行成功了，那些失败了，手动补偿，统一管理）\n\n5、管理平台\n\n6、重试多次失败->报警、状态监控\n\n---分布式任务调度平台（XXLJOB）（elsticjob）：解决传统任务调度缺点\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (33, 25, '关于分布式锁原理-redis分布式锁，zookeeper分布式锁', '', '首先分布式锁和我们平常讲到的锁原理基本一样，目的就是确保，在多个线程并发时，只有一个线程在同一刻操作这个业务或者说方法、变量,在一个进程中，也就是一个jvm 或者说应用中，我们很容易去处理控制，在jdk java.util并发包中已经为我们提供了这些方法去加锁', '科科程程', '', '首先分布式锁和我们平常讲到的锁原理基本一样，目的就是确保，在多个线程并发时，只有一个线程在同一刻操作这个业务或者说方法、变量。\n在一个进程中，也就是一个jvm 或者说应用中，我们很容易去处理控制，在jdk java.util并发包中已经为我们提供了这些方法去加锁，比如synchronized 关键字 或者Lock 锁，都可以处理。\n但是我们现在的应用程序如果只部署一台服务器，那并发量是很差的，如果同时有上万的请求那么很有可能造成服务器压力过大，而瘫痪。\n想想双十一 和三十晚上十点分支付宝红包等业务场景，自然需要用到多台服务器去同时处理这些业务，那么这些服务可能会有上百台同时处理，但是请我们大家想一想，如果有100台服务器 要处理分红包的业务，现在假设有1亿的红包，1千万个人分，金额随机，那么这个业务场景下是不是必须确保这1千万个人最后分的红包金额总和等于1亿。如果处理不好~~每人分到100万，那马云爸爸估计大年初一，就得宣布破产了\n\n1，常规锁会造成什么情况？\n首先说一下我们为什么要搞集群，简单理解就是，需求量（请求并发量）变大了，一个工人处理能力有限，那就多招一些工人来一起处理。\n\n假设1千万个请求平均分配到100台服务器上，每个服务器 接收10w的请求（这10w个请求并不是在同一秒中来的，可能是在1,2个小时内，可以联想下我们三十晚上开红包，等到10.20开始，有的人立马开了，有的人是不是等到12点了才想起来~）\n\n那这样的话，平均到每一秒上的请求也就不到1千个，这种压力一般的服务器还是可以承受的。\n\n第一个请求到来后，是不是需要在1亿里面给他分一部分钱，金额随机，假设第一个人分到了100，那是不是要在这1亿中减去100块，剩下99999900 块~\n\n第二个用户再来分，金额随机，这次分200块，那是不是就需要在剩下的99999900块中再减去200块，剩下99999700 块。\n\n等到第10w个用户来，一看还有1000w，那这1000w全成他的了。\n\n等于是在每个服务器中去分1亿，也就是10w个用户分了一个亿，最后总计有100个服务器，要分100亿。\n\n如果真这样了，虽说马云爸爸不会破产（据最新统计马云有2300亿人民币），那分红包的开发项目组，以及产品经理，可以GG了~\n\n简化结构图如下：\n\n\nimage.png\n2，分布式锁怎么去处理？\n那么为了解决这个问题，让1000万用户只分1亿，而不是100亿，这个时候分布式锁就派上用处了。\n\n分布式锁可以把整个集群就当作是一个应用一样去处理，那么也就需要这个锁，要独立于每一个服务之外，而不是在服务里面。\n\n假设第一个服务器接收到用户1的请求后，那么这个时候，他就不能只在自己的应用中去判断还有多少钱可以分了，而需要去外部请求专门负责管理这1亿红包的人（服务），问他：哎，我这里要分100块，给我100。\n\n管理红包的妹子（服务）一看，还有1个亿，那好，给你100块，然后剩下99999900块。\n\n第二个请求到来后，被服务器2获取，继续去询问，管理红包的妹子，我这边要分10块，管理红包的妹子先查了下还有99999900，那就说：好，给你10块。那就剩下99999890块\n\n等到第1000w个请求到来后，服务器100拿到请求，继续去询问，管理红包的妹子，你要100，妹子翻了翻白眼，对你说，就剩1块了，爱要不要，那这个时候就只能给你1块了（1块也是钱啊，买根辣条还是可以的）。\n\n这些请求编号1,2不代表执行的先后顺序，正式的场景下，应该是 100台服务器每个服务器持有一个请求去访问负责管理红包的妹子（服务），那在管红包的妹子那里同时会接收到100个请求，这个时候就需要在负责红包的妹子那里加个锁就可以了（抛绣球），你们100个服务器谁拿到锁（抢到绣球），谁就进来和我谈，我给你分，其他人就等着去吧\n\n经过上面的分布式锁的处理后，马云爸爸终于放心了，决定给红包团队每人加一个鸡腿。\n\n简化的结构图如下：\n\n\nimage.png\n3，分布式锁的实现有哪些？\n说到分布式锁的实现，还是有很多的，有数据库方式的，有redis分布式锁，有zookeeper分布式锁等等\n\n我们如果采用redis作为分布式锁，那么上图中负“责红包的妹子（服务）”，就可以替换成redis，请自行脑补。\n\n3.1，为什么redis可以实现分布式锁？\n首先redis是单线程的，这里的单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。\n\n在实际的操作中过程大致是这样子的：\n\n服务器1要去访问发红包的妹子，也就是redis，那么他会在redis中通过\"setnx key value\" 操作设置一个key 进去，value是啥不重要，重要的是要有一个key，也就是一个标记，而且这个key你爱叫啥叫啥，只要所有的服务器设置的key相同就可以。\n\n假设我们设置一个，如下图\n\n###\n那么我们可以看到会返回一个1，那就代表了成功。\n\n如果再来一个请求去设置同样的key，如下图：\n\nimage\n这个时候会返回0，那就代表失败了。\n\n那么我们就可以通过这个操作去判断是不是当前可以拿到锁，或者说可以去访问“负责发红包的妹子”，如果返回1，那我就开始去执行后面的逻辑，如果返回0，那就说明已经被人占用了，我就要继续等待。\n\n当服务器1拿到锁之后，进行了业务处理，完成后，还需要释放锁，如下图所示：\n\nimage\n删除成功返回1，那么其他的服务器就可以继续重复上面的步骤去设置这个key，以达到获取锁的目的。\n\n当然以上的操作是在redis客户端直接进行的，通过程序调用的话，肯定就不能这么写，比如java 就需要通过jedis 去调用，但是整个处理逻辑基本都是一样的\n\n通过上面的方式，我们好像是解决了分布式锁的问题，但是想想还有没有什么问题呢？？\n\n对，问题还是有的，可能会有死锁的问题发生，比如服务器1设置完之后，获取了锁之后，忽然发生了宕机。\n\n那后续的删除key操作就没法执行，这个key会一直在redis中存在，其他服务器每次去检查，都会返回0，他们都会认为有人在使用锁，我需要等。\n\n为了解决这个死锁的问题，我们就就需要给key 设置有效期了。\n\n设置的方式有2种\n\n1，第一种就是在set完key之后，直接设置key的有效期 \"expire key timeout\" ，为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。\n\n这种方式相当于，把锁持有的有效期，交给了redis去控制。如果时间到了，你还没有给我删除key，那redis就直接给你删了，其他服务器就可以继续去setnx获取锁。\n\n2，第二种方式，就是把删除key权利交给其他的服务器，那这个时候就需要用到value值了，\n\n比如服务器1，设置了value 也就是 timeout 为 当前时间+1 秒 ，这个时候服务器2 通过get 发现时间已经超过系统当前时间了，那就说明服务器1没有释放锁，服务器1可能出问题了，\n\n服务器2就开始执行删除key操作，并且继续执行setnx 操作。\n\n但是这块有一个问题，也就是，不光你服务器2可能会发现服务器1超时了，服务器3也可能会发现，如果刚好，服务器2，setnx操作完成，服务器3就接着删除，是不是服务器3也可以setnx成功了？\n\n那就等于是服务器2和服务器3都拿到锁了，那就问题大了。这个时候怎么办呢？\n\n这个时候需要用到 “GETSET key value” 命令了。这个命令的意思就是获取当前key的值，并且设置新的值。\n\n假设服务器2发现key过期了，开始调用 getset 命令，然后用获取的时间判断是否过期，如果获取的时间仍然是过期的，那就说明拿到锁了。\n\n如果没有，则说明在服务2执行getset之前，服务器3可能也发现锁过期了，并且在服务器2之前执行了getset操作，重新设置了过期时间。\n\n那么服务器2就需要放弃后续的操作，继续等待服务器3释放锁或者去监测key的有效期是否过期。\n\n这块其实有一个小问题是，服务器3已经修改了有效期，拿到锁之后，服务器2，也修改了有效期，但是没能拿到锁，但是这个有效期的时间已经被在服务器3的基础上有增加一些，但是这种影响其实还是很小的，几乎可以忽略不计。\n\n3.2，为什么zookeeper可以实现分布式锁？\n百度百科是这么介绍的：ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。\n\n那对于我们初次认识的人，可以理解成ZooKeeper就像是我们的电脑文件系统，我们可以在d盘中创建文件夹a，并且可以继续在文件夹a中创建 文件夹a1，a2。\n\n那我们的文件系统有什么特点？？那就是同一个目录下文件名称不能重复，同样ZooKeeper也是这样的。\n\n在ZooKeeper所有的节点，也就是文件夹称作 Znode，而且这个Znode节点是可以存储数据的。\n\n我们可以通过“ create /zkjjj nice” 来创建一个节点，这个命令就表示，在跟目录下创建一个zkjjj的节点，值是nice。同样这里的值，和我在前面说的redis中的一样，没什么意义，你随便给。\n\n另外ZooKeeper可以创建4种类型的节点，分别是：\n\n1，持久性节点\n2，持久性顺序节点\n3，临时性节点\n4，临时性顺序节点\n首先说下持久性节点和临时性节点的区别，持久性节点表示只要你创建了这个节点，那不管你ZooKeeper的客户端是否断开连接，ZooKeeper的服务端都会记录这个节点。\n\n临时性节点刚好相反，一旦你ZooKeeper客户端断开了连接，那ZooKeeper服务端就不再保存这个节点。\n\n再说下顺序性节点，顺序性节点是指，在创建节点的时候，ZooKeeper会自动给节点编号比如0000001 ，0000002 这种的。\n\n最后说下，zookeeper有一个监听机制，客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）等，zookeeper会通知客户端。\n\n下面我们继续结合我们上面的分红包场景，描述下在zookeeper中如何加锁。\n\n假设服务器1，创建了一个节点 /zkjjj ,成功了，那服务器1就获取了锁，服务器2再去创建相同的锁，那么他就会失败，这个时候他就就只能监听这个节点的变化。\n\n等到服务器1，处理完业务，删除了节点后，他就会得到通知，然后去创建同样的节点，获取锁处理业务，再删除节点，后续的100台服务器与之类似\n\n注意这里的100台服务器并不是挨个去执行上面的创建节点的操作，而是并发的，当服务器1创建成功，那么剩下的99个就都会注册监听这个节点，等通知，以此类推。\n\n但是大家有没有注意到，这里还是有问题的，还是会有死锁的情况存在，对不对？\n\n当服务器1创建了节点后挂了，没能删除，那其他99台服务器就会一直等通知，那就完蛋了。。。\n\n这个时候呢，就需要用到临时性节点了，我们前面说过了，临时性节点的特点是客户端一旦断开，就会丢失，也就是当服务器1创建了节点后，如果挂了。\n\n那这个节点会自动被删除，这样后续的其他服务器，就可以继续去创建节点，获取锁了。\n\n但是我们可能还需要注意到一点，就是惊群效应：举一个很简单的例子,当你往一群鸽子中间扔一块食物,虽然最终只有一个鸽子抢到食物,但所有鸽子都会被惊动来争夺,没有抢到..\n\n就是当服务器1节点有变化，会通知其余的99个服务器，但是最终只有1个服务器会创建成功，这样98还是需要等待监听，那么为了处理这种情况，就需要用到临时顺序性节点\n\n大致意思就是，之前是所有99个服务器都监听一个节点，现在就是每一个服务器监听自己前面的一个节点。\n\n假设100个服务器同时发来请求，这个时候会在 /zkjjj 节点下创建 100 个临时顺序性节点 /zkjjj/000000001, /zkjjj/000000002,一直到 /zkjjj/000000100,这个编号就等于是已经给他们设置了获取锁的先后顺序了。\n\n当001节点处理完毕，删除节点后，002收到通知，去获取锁，开始执行，执行完毕，删除节点，通知003~以此类推。\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (34, 25, '分布式数据库HBase以及HBase的单机模式', '', 'HBase是一个分布式的，面向列，可扩展的大数据存储的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文《Bigtable：一个结构化数据的分布式存储系统》。就像Bigtable利用了Google文件系统所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力', '科科程程', '', 'HBase简介\nHBase是一个分布式的，面向列，可扩展的大数据存储的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文《Bigtable：一个结构化数据的分布式存储系统》。就像Bigtable利用了Google文件系统所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。\nHBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系型数据库，是一个开源的，分布式的，版本化的非关系型数据库。Hbase是Hadoop生态系统的一部分，Hbase数据最终是存储到HDFS文件系统当中。HBase基于列的而不是基于行。\n\nHBase的特点：\n1、大容量：支持百亿行，百万列\n2、面向列：动态增加列存储\n3、多版本：每列数据存储可有多个version\n4、稀疏性：空列不占用空间\n5、扩展性：线性和模块化，底层依赖于HDFS(Hadoop分布式文件系统),表的自动和可配置分片\n6、高可靠性：自动故障转移支持与HDFS备份\n7、易于使用的Java API，用于客户端访问\n8、随即读取性：region切分、主键索引和缓存机制，严格一致的读写操作\n9、Thrift网关和REST-ful Web服务，支持XML，Protobuf和二进制数据编码选项\n10、支持通过Hadoop指标子系统将指标导出到文件或Ganglia(分布式监控); 或通过JMX\n\nGithub地址：https://github.com/apache/hbase\n官方网站：https://hbase.apache.org/\n官方文档：https://hbase.apache.org/book.html\n中文文档：http://abloz.com/hbase/book.html\n中文社区：http://hbase.group/\n\n在window中搭建HBase\n由于Hbase是Hadoop生态系统的一部分，所以必须要先安装配置好Hadoop，\n可以参考我上一篇文章：分布式计算平台Hadoop\n\n重点：看下官方提供的版本支持\n搭建需要：hadoop3.1.1以上都可以\n来源：https://hbase.apache.org/book.html#hadoop\n\nimage.png\n官方最新推荐版本为Hadoop3.1.1+和HBase2.1+\nHBase下载\n下载地址：https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/\n选择最新的2.1.5版本，官方建议下载稳定版本1.4.9\nimage.png\n选择下载bin.tar.gz\nimage.png\n下载完后直接解压，目录如下，相关的配置文件存放在conf目录下\nimage.png\n单机模式\nHBase内置有zookeeper，HBase启动默认使用内置zookeeper\n1.配置hbase-site.xml配置文件\n    <property>\n        <name>hbase.rootdir</name>\n        <value>hdfs://localhost:9000/hbase</value>\n    </property>\n这里需要注意\nhbase.rootdir为hbase持久化的目录，被所有regionserver共享，一般设置为hdfs://namenode.example.org:9000/hbase，hdfs://localhost:9000要和hadoop配置文件core-site.xml中fs.defaultFS属性的值一样\n\n建议加入的设置\n需要先手动创建文件夹\nhbase.tmp.dir：本地文件系统的临时目录\nhbase.zookeeper.property.dataDir：zookeeper的配置，snapshot存放的目录，默认是${hbase.tmp.dir}/zookeeper\n拓展：\nhbase.zookeeper.quorum：重要的也是必须设置的，启动zookeeper的服务器列表，逗号分隔，cluster(集群)模式下必须设置，默认是localhost，hbase客户端也需要设置这个值去访问zookeeper\nhbase.zookeeper.property.clientPort：zookeeper端口的配置，client连zookeeper的端口，默认2181\n\n    <property>\n        <name>hbase.tmp.dir</name>\n        <value>E:/hbase/hbase-2.1.2/tmp</value>\n    </property>\n    <property>\n        <name>hbase.zookeeper.property.dataDir</name>\n        <value>E:/hbase/hbase-2.1.2/zoo</value>\n    </property>\nHBase官方配置项说明：https://hbase.apache.org/book.html#config.files\n启动中可能遇到的报错\njava.lang.NoClassDefFoundError: org/apache/htrace/SamplerBuilder\njava.lang.RuntimeException: Failed construction of Master: \nclass org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMasterorg.apache.htrace.SamplerBuilder\n原因：jar包缺失\n解决方法：把lib\\client-facing-thirdparty包中的htrace-core-3.1.0-incubating.jar复制一个到lib包下即可\nimage.png\njava.lang.IllegalStateException: The procedure WAL relies on the ability to hsync for proper operation \nduring component failures, but the underlying filesystem does not support doing so. \nPlease check the config value of \'hbase.procedure.store.wal.use.hsync\' to set the desired level of robustness \nand ensure the config value of \'hbase.wal.dir\' points to a FileSystem mount that can provide it.\n\n[main-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: \nSession 0x168ea1e6d980001 for server null, unexpected error, closing socket connection and attempting reconnect\njava.net.ConnectException: Connection refused: no further information\n原因：单机模式直接使用本地磁盘，而本地磁盘不支持hsync\n\n解决方法：\n禁用hsync，在hbase-site.xml中加入\n\n    <property>\n        <name>hbase.procedure.store.wal.use.hsync</name>\n        <value>false</value>\n    </property>\n但是还是会报错，hbase.procedure.store.wal.use.hsync如果为true，则使用hsync,如果为false，则使用hflush,两种都会报错\n需要设置hbase.unsafe.stream.capability.enforce,在hbase-site.xml中再加入\n\n    <property>\n        <name>hbase.unsafe.stream.capability.enforce</name>\n        <value>false</value>\n    </property>\n2.启动HBase\n运行bin/start-hbase.cmd，前提：先启动hadoop\nimage.png\n没发现有报错信息就是启动成功\n\nHadoop Namenode控制台\nimage.png\nHadoop Datanode控制台\nimage.png\n还可能存在的问题是\n1.启动不久后发现HBase自动挂了\n\njava.lang.RuntimeException: Master not initialized after 200000ms\n        at org.apache.hadoop.hbase.util.JVMClusterUtil.waitForEvent(JVMClusterUtil.java:229)\n        at org.apache.hadoop.hbase.util.JVMClusterUtil.startup(JVMClusterUtil.java:197)\n        at org.apache.hadoop.hbase.LocalHBaseCluster.startup(LocalHBaseCluster.java:413)\n        at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:232)\n        at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:140)\n        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n        at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:149)\n        at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:3103)\n原因：Hadoop处于安全模式\n\n解决方法：\n前提：要确保已经设置好hbase.procedure.store.wal.use.hsync和hbase.unsafe.stream.capability.enforce\n在Hadoop的hdfs-site.xml配置文件中加入\n\n    <property> \n        <name>dfs.safemode.threshold.pct</name> \n        <value>0</value> \n    </property>\n注：如果还是解决不了问题重新启动hadoop和hbase，请干净进程\ndfs.safemode.threshold.pct(阈值比例):指定应有多少比例的数据块满足最小副本数要求。小于等于0意味不进入安全模式，大于1意味一直处于安全模式。\n\n工作原理:\nNameNode在启动的时候首先进入安全模式，如果DataNode丢失的block达到一定的比例1-dfs.safemode.threshold.pct，则系统一直处于安全模式状态，即只读状态。\ndfs.safemode.threshold.pct（缺省值0.999f）表示HDFS启动的时候，如果DataNode上报的block个数达到了元数据记录的block个数的0.999倍才可以离开安全模式，否则一直是这种只读模式。如果设置为1，则HDFS一直处于安全模式。\n\n2.Caused by: java.io.IOException: Filesystem closed\n原因：多个datanode在getFileSystem过程中，由于Configuration一样，会得到同一个FileSystem。如果有一个datanode在使用完关闭连接，其它的datanode在访问就会出现上述异常\n解決方法：\n在hadoop的配置文件hdfs core-site.xml里把fs.hdfs.impl.disable.cache设置为true\n\n    <property>\n        <name>fs.hdfs.impl.disable.cache</name>\n        <value>true</value>\n    </property> \n3.java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper\n解决方法：在hdfs-site.xml中加入\n\n    <property> \n        <name>hbase.wal.provider</name> \n        <value>multiwal</value> \n    </property>\n在HBase1.0开始支持多个WALHBASE-5699,这样可以提高写入的吞吐量。配置参数为hbase.wal.provider=multiwal，支持的值还有defaultProvider和filesystem(这2个是同样的实现)\n\n具体的HBase WAL 解析可以参考：https://blog.csdn.net/u010039929/article/details/74330722\nHbase master的管理界面\n默认端口为16010，可以在hbase-site.xml配置hbase.master.info.port去修改默认端口\nhttp://localhost:16010 也就是IP:端口号\nimage.png\nHbase master内置zookeeper的管理界面\nhttp://localhost:16010/zk.jsp\n内置zookeeper的相关信息都是显示出来\n\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (35, 25, '探秘分布式解决方案: 分布式限流', '', '那么在分布式场景中, 限流就变得不是那么容易了。 在这种环境上想实现限流本质上是在实现一种多个进程之间的协同工作机制。 必须得依靠一个可靠的协调中心才行，这一般都会选一种中间件来实现。', '科科程程', '', '关于限流这种机制呢也算是老生常谈了， 毕竟在业务开发中实在是很多地方都会用到。比如第三方接口调用限制、并发访问数控制等…\n\n而具体的限流算法在单机中很容易就可以实现, 在java的世界里既有开源库Guava的RateLimiter, 也有JUC中自带的 Semaphore、BlockingQueue等。拿来随手就可以使用。\n\n那么在分布式场景中, 限流就变得不是那么容易了。 在这种环境上想实现限流本质上是在实现一种多个进程之间的协同工作机制。 必须得依靠一个可靠的协调中心才行，这一般都会选一种中间件来实现。\n\n而 Redis 其实就是一个适合这种场景的中间件，既快，又有强大的数据结构对各种限流算法提供支持。那么我这里就来基于Redis实现一种简单粗暴又好用的限流方案—— 信号量(Semaphore)\n\n关于信号量\n这里引用一段维基百科的定义\n\n信号量 （英语： semaphore ）又称为 信号标 ，是一个同步对象，用于保持在0至指定最大值之间的一个计数值。当线程完成一次对该 semaphore 对象的等待（ wait ）时，该计数值减一；当线程完成一次对 semaphore 对象的释放（ release ）时，计数值加一。当计数值为0，则线程等待该 semaphore 对象不再能成功直至该 semaphore 对象变成 signaled 状态。 semaphore 对象的计数值大于0，为 signaled 状态；计数值等于0，为 nonsignaled 状态.\n\n其实白话说起来很简单，信号量就是可以被 多个线程同时持有 的 一种同步对象，比如我设置一个值为5的计数信号量，那么现在有十个线程来获取他就只会有五个可以成功，剩下那五个则获取失败。\n\n所以说如果有个计数信号量定义的值是1，那么他其实就等同于 mutex (互斥锁)\n\n实现的基本思路\n既然知道信号量本质是一种锁，那么对于信号量需要拥有的效果自然就有了思路\n\n拥有获取、释放的机制\n需要知道是哪个客户端获取到了信号量\n获取到信号量之后， 不能因为客户端的崩溃导致无法释放\n对于Redis来说，可以使用 ZSet 来实现这些效果。ZSet 是不可重复的有序集合, 内部每个元素都拥有一个属于自己的分数 (score)\n\n那么我们可以将 ZSet 中一条数据视为客户端获取到的信号量, key就是客户端的唯一标识, score 可以设置为 客户端获取信号量的时间 。\n\n这样就能够实现上面所说的几种机制\n\n在ZSet中插入数据即为获取。 删除即为释放。\n利用ZSet的有序特性, 可以根据 score 的排名 来判断是否成功获取到了信号量\n因为 score 存的是客户端获取到信号量的时间, 所以可以约定一个过期时间来对死掉的客户端获取到的信号量进行清除\n值得注意的是, 在 Redis 上实现信号量，如果客户端持有信号量之后由于处理时间太久导致没在规定的超时时间内释放的话， 那么这个持有 信号量延时机制 ， 是需要自己实现的 (守护线程定时更新等) 因为Redis他本身没有提供这种功能的实现， 所以只能自己动手了。 不过像这种需求在使用到分布式信号量的场景中多数不怎么会出现, 所以也可以不管。\n\n使用 Redis 构建分布式信号量的实现细节\n知道了需求和对应的实现思路后, 那么可以来决定一下具体的实现细节\n\n这里就需要对 Redis 的命令有一定的了解, 不过就算不了解也没关系， 反正就这么几个命令。\n\n可行的具体流程\n获取系统当前时间, 因为集合的分数储存的是时间毫秒值, 所以可以通过 ZREMRANGEBYSCORE 清理掉过期的信号量\n使用 ZADD 向集合中添加代表自身信号量的元素, 分数为当前时间\n通过 ZRANK 得到当前客户端在集合中的排名, 如果在许可证数量的范围内 (即不大于信号量最大持有数量) 即视为成功获取信号量\n如果不在范围内, 比如信号量设置的最大许可数为 5, 自己在集合中的排名是5 (Redis rank 从0开始数) 则视为获取型号量失败, 使用 ZREM 清理数据\n使用上边说的流程来进行分布式信号量的实现是很好用的，既简单又快速， 很多时候用这个就可以了。\n\n但是它其实还有一个小小的问题。 因为其判定时间的逻辑会存在于客户端中 , 而在不同的主机环境上时间并不一定会完全一致，可能会有个几毫秒的误差，这样子就有可能出现信号量超发的问题。\n\n比如这么一个场景, 在获取最后一个信号量的时候， 客户端A 已经获取到了最后一个信号量 , 这个时候客户端B (B的时间比A要慢一点) 也来尝试获取信号量, 那么在B判定分数的时候有可能就会发现自己的排名仍在信号量的许可证最大数范围内, 从而B也拿到了这最后一个信号量。\n\n其实在很多场景中偶尔超标问题不大, 再加上本身也是小概率事件， 所以很多时候可以无视这个问题。 不过既然有这么个问题，那还是可以继续优化下去的，让具体的实现更加公平一点\n\n优化后的逻辑\n知道了会发生超发的原因就是因为在比较排名时用的是保存获取时间的集合，而根据获取时间集合中的排名来判断是有可能和实际排名对不上的。\n\n那么我们就可以想个办法将 排名控制逻辑单独拿出来 ，将其放到一个可靠的地方来实现。这个可靠的地方当然也可以使用Redis啦。\n\n可以利用Redis自带的原子性自增 INCR 来获取序列号。 再新增一个有序集合以这个序列号作为score, 这样就可以根据这个排名来进行公平的判定。\n\n而需要做的只是在 获取信号量、获取失败清除数据 这两个步骤中增加对于专门的排名集合的操作。\n\n并且在获取信号量之前清理过期数据时同时清理排名集合中的数据即可， 这里可以使用ZSet的ZINTERSTORE 取交集并储存来实现。\n\n这样就是一个相对之前的逻辑而言更完备的实现了。 只要你的系统时间差的不是那么多， 那都是可以公平的安全获取的。 如果想要完全保证公平，也可以用锁机制来实现，不过一般来说没必要。\n\n分布式信号量具体实现代码\n知道了具体的细节后，就可以进入到编码流程了。\n\n想自己动手实现的可以先按照步骤自己实现。可以用我的代码作为参考。\n\n这里就贴上我写的实现:\n首先先定义一个信号量的基础信息, 表示一个信号量的元数据。\n\n一般是事先手动配置好的。可以放在配置文件、配置中心、SQL数据库里。\n\npublic final class SemaphoreInfo {\n\n    //信号量的名称\n    private final String semaphoreName;\n\n    //许可证的数量\n    private final int permits;\n\n    //信号量最大持有时间 (过期时间) 单位s\n    private final long expire;\n\n    //公平 or 非公平\n    private final boolean fair;\n\n    public SemaphoreInfo(String semaphoreName, int permits, long expire) {\n        this(semaphoreName, permits, expire, false);\n    }\n\n    public SemaphoreInfo(String semaphoreName, int permits, long expire, boolean fair) {\n        this.semaphoreName = semaphoreName;\n        this.permits = permits;\n        this.expire = expire;\n        this.fair = fair;\n    }\n\n    public String getSemaphoreName() {\n        return semaphoreName;\n    }\n\n    public int getPermits() {\n        return permits;\n    }\n\n    public long getExpire() {\n        return expire;\n    }\n\n    public boolean isFair() {\n        return fair;\n    }\n}\n有了元信息之后, 就可以开始实现具体的需求了\n\n先定义一个接口\n\npublic interface DistributedSemaphore {\n\n    /**\n     * 尝试获取一个信号量\n     *\n     * @return true 获取成功, false 获取失败\n     */\n    boolean tryAcquire();\n\n    /**\n     * 释放自己持有的信号量\n     */\n    void release();\n}\n这个接口的具体实现, RedisTemplate 版\n\n注释比较详细, 就不过多说明了。\n\npublic class RedisSemaphore implements DistributedSemaphore {\n\n    private static final String SEMAPHORE_TIME_KEY = \"semaphore:time:\";\n    private static final String SEMAPHORE_OWNER_KEY = \"semaphore:owner:\";\n    private static final String SEMAPHORE_COUNTER_KEY = \"semaphore:counter:\";\n\n    private final RedisTemplate redisTemplate;\n\n    private final String timeKey;\n    private final String ownerKey;\n    private final String counterKey;\n\n    //信号量的信息\n    private final SemaphoreInfo info;\n\n    //信号量实体\n    private final DistributedSemaphore semaphore;\n\n    //身份证明\n    private final String identification;\n\n    public RedisSemaphore(SemaphoreInfo info, RedisTemplate redisTemplate, String identification) {\n        this.info = info;\n        this.redisTemplate = redisTemplate;\n        this.timeKey = SEMAPHORE_TIME_KEY.concat(info.getSemaphoreName());\n        this.ownerKey = SEMAPHORE_OWNER_KEY.concat(info.getSemaphoreName());\n        this.counterKey = SEMAPHORE_COUNTER_KEY.concat(info.getSemaphoreName());\n\n        this.semaphore = info.isFair() ? new FairSemaphore() : new NonfairSemaphore();\n\n        this.identification = identification;\n    }\n\n    @Override\n    public boolean tryAcquire() {\n        return semaphore.tryAcquire();\n    }\n\n    @Override\n    public void release() {\n        semaphore.release();\n    }\n\n    private class NonfairSemaphore implements DistributedSemaphore {\n\n        @Override\n        public boolean tryAcquire() {\n            ZSetOperations zsetOps = redisTemplate.opsForZSet();\n            long timeMillis = System.currentTimeMillis();\n\n            //先清除过期的信号量\n            zsetOps.removeRangeByScore(timeKey, 0, timeMillis - (info.getExpire() * 1000));\n\n            //尝试获取信号量并比较自身的排名, 如果小于许可证的数量则表示获取成功 (redis rank 指令从0开始计数)\n            zsetOps.add(timeKey, identification, timeMillis);\n            if (zsetOps.rank(timeKey, identification) < info.getPermits()) return true;\n\n            //获取失败,删除掉上边添加的标识\n            release();\n            return false;\n        }\n\n        @Override\n        public void release() {\n            redisTemplate.opsForZSet().remove(timeKey, identification);\n        }\n    }\n\n    private class FairSemaphore implements DistributedSemaphore {\n\n        @Override\n        public boolean tryAcquire() {\n\n            long timeMillis = System.currentTimeMillis();\n\n            //用于获取信号量的计数\n            Long counter = redisTemplate.opsForValue().increment(counterKey, 1);\n\n            //用流水线把这一堆命令用一次IO全部发过去\n            redisTemplate.executePipelined(new SessionCallback<Object>() {\n\n                @Override\n                public <K, V> Object execute(RedisOperations<K, V> operations) throws DataAccessException {\n                    ZSetOperations zsetOps = operations.opsForZSet();\n\n                    //清除过期的信号量\n                    zsetOps.removeRangeByScore(timeKey, 0, timeMillis - (info.getExpire() * 1000));\n                    zsetOps.intersectAndStore(timeKey, ownerKey, timeKey);\n\n                    //尝试获取信号量\n                    zsetOps.add(timeKey, identification, timeMillis);\n                    zsetOps.add(ownerKey, identification, counter);\n                    return null;\n                }\n            });\n\n            //这里根据 持有者集合 的分数来进行判断\n            Long ownerRank = redisTemplate.opsForZSet().rank(ownerKey, identification);\n            if (ownerRank<info.getPermits()) return true;\n\n            release();\n            return false;\n        }\n\n        @Override\n        public void release() {\n            redisTemplate.executePipelined(new SessionCallback<Object>() {\n\n                @Override\n                public <K, V> Object execute(RedisOperations<K, V> operations) throws DataAccessException {\n                    ZSetOperations zetOps = operations.opsForZSet();\n                    zetOps.remove(timeKey, identification);\n                    zetOps.remove(ownerKey, identification);\n                    return null;\n                }\n            });\n        }\n    }\n\n}\n写完后可以来一波测试， 这是测试类信息\n\n@RunWith(SpringRunner.class)\n@SpringBootTest(classes = DemoApplication.class)\npublic class DistributedSemaphoreTest {\n\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n    ThreadPoolExecutor pool = new ThreadPoolExecutor(10, 10, 0, TimeUnit.MINUTES,\n            new LinkedBlockingQueue<>(),\n            Executors.defaultThreadFactory(),\n            new ThreadPoolExecutor.CallerRunsPolicy());\n\n    @Test\n    public void testNonFair() throws InterruptedException {\n        SemaphoreInfo semaphoreInfo = new SemaphoreInfo(\"NonFair\", 5, 10);\n\n        for (int i = 0; i < 10; i++) {\n\n            String id = String.valueOf(i);\n\n            RedisSemaphore semaphore = new RedisSemaphore(semaphoreInfo, redisTemplate, id);\n\n            CompletableFuture.supplyAsync(semaphore::tryAcquire, pool).thenAcceptAsync((r) -> {\n                if (r) System.out.println(id + \"成功获取到信号量(NonFair)~ :star::star::star:\");\n                else System.out.println(id + \"没有获取到信号量(NonFair)\");\n\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                semaphore.release();\n            }, pool);\n\n        }\n\n        Thread.sleep(Long.MAX_VALUE);\n\n    }\n\n    @Test\n    public void testFair() throws ExecutionException, InterruptedException {\n        SemaphoreInfo semaphoreInfo = new SemaphoreInfo(\"Fair\", 5, 10, true);\n\n        for (int i = 0; i < 10; i++) {\n\n            String id = String.valueOf(i);\n\n            RedisSemaphore semaphore = new RedisSemaphore(semaphoreInfo, redisTemplate, id);\n\n            CompletableFuture.supplyAsync(semaphore::tryAcquire, pool).thenAcceptAsync((r) -> {\n                if (r) System.out.println(id + \"成功获取到信号量(Fair)~~ :star::star::star:\");\n                else System.out.println(id + \"没有获取到信号量(Fair)\");\n\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n\n                semaphore.release();\n            }, pool);\n\n        }\n\n        Thread.sleep(Long.MAX_VALUE);\n\n    }\n} \n结语\n其实吧. 分布式信号量还是一个挺简单的东西。\n\n相信仔细看了我这篇博客之后, 应该对于分布式信号量的实现心中都有数了。\n\n只要知道构建一个信号量需要做什么，那么可以不用拘泥于Redis, 用其他的中间件也可以实现， 毕竟思想是相通的。\n\n在java环境下, 用这个我提供的实现其实也完全OK 。\n\n不过信号量也只是限流算法中的其中一种实现而已， 对于限流场景还有其他的算法可以使用， 并且就算是这个分布式信号量，在Redis层面中也是可以继续优化下去的。看之后有没有心情写吧。\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (36, 26, '大数据可以做什么？大数据实际做了什么？', '', '关于大数据的著作和文章铺天盖地，似乎也共同在传递一个信息：越来越多的行业、人士开始关注并实际探索大数据的应用，我们正在一起描绘着大数据巨大效用的蓝图，但在实践的路上，我们都还在起步阶段小步前行', '科科程程', '', '“大数据”一词时下的热门程度无需赘言，这一两年来互联网相关的任何活动、会议必不可少“大数据”板块。刚刚结束的第13届“中国互联网大会”也专设了大数据论坛。\n\n对于任何一个大数据的从业者或初接触者，或许都会有个共同的感触：大数据很有用！大数据该怎么用？\n\n关于大数据的著作和文章铺天盖地，似乎也共同在传递一个信息：越来越多的行业、人士开始关注并实际探索大数据的应用，我们正在一起描绘着大数据巨大效用的蓝图，但在实践的路上，我们都还在起步阶段小步前行。\n\n大数据根基于互联网，数据仓库、数据挖掘、云计算等互联网技术的发展为大数据的应用奠定了基础。然而实践应用尚处于在探索中前进。同样作为探索学习，我想从我个人的理解角度，分享并与大家探讨四个问题：大数据是什么？大数据可以做什么？大数据实际做了什么？大数据要怎么做？\n\n首先，大数据是什么？\n\n引用3个比较常用的大数据定义：\n\n（1）需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。\n\n—— Gartner\n\n（2）海量的数据规模（Volume）、快速的数据流转和动态的数据体系（Velocity）、多样的数据类型（Variety）、巨大的数据价值（Value）。\n\n—— IDC\n\n（3）或称巨量数据、海量数据、大资料，指所涉及的数据量规模巨大到无法通过人工，在合理时间内达到截取、管理、处理、并整理成为人类所能解读的信息。\n\n【大数据开发学习资料领取方式】：加入大数据技术学习交流扣扣群458345782，私信管理员即可免费领取开发工具以及入门学习资料\n\n—— Wiki\n\n其他关于大数据的定义也大抵类似，我们可以用几个关键词对大数据做一个界定。\n\n首先，“规模大”，这种规模可以从两个维度来衡量，一是从时间序列累积大量的数据，二是在深度上更加细化的数据。\n\n其次，“多样化”，可以是不同的数据格式，如文字、图片、视频等，可以是不同的数据类别，如人口数据，经济数据等，还可以有不同的数据来源，如互联网、传感器等。\n\n第三，“动态化”。数据是不停地变化的，可以随着时间快速增加大量数据，也可以是在空间上不断移动变化的数据。\n\n这三个关键词对大数据从形象上做了界定。\n\n但还需要一个关键能力，就是“处理速度快”。如果这么大规模、多样化又动态变化的数据有了，但需要很长的时间去处理分析，那不叫大数据。从另一个角度，要实现这些数据快速处理，靠人工肯定是没办法实现的，因此，需要借助于机器实现。\n\n最终，我们借助机器，通过对这些数据进行快速的处理分析，获取想要的信息或者应用的整套体系，才能称为大数据。\n\n我们可以用下面的图示给大数据定义：\n\n\n\n\n对大数据概念有了界定后，那大数据可以做什么呢？\n\n想要应用大数据，从流程上来说，大概是这样。\n\n\n\n\n首先我们要有数据源，然后对数据进行收集和存储，在这基础上，再进行分析和应用，形成我们的产品和服务，而产品和服务也会产生新的数据，这些新数据会循环进入我们的流程中。\n\n当这整个循环体系成为一个智能化的体系，通过机器可以实现自动化，那也许就会成为一种新的模式，不管是商业的，或者是其他。\n\n然后具体到实际的应用中，我认为，大数据能够实现的应用，可以概括为两个方向，一是精准化定制，二是预测。\n\n首先，精准化定制。\n\n主要是针对供需两方的，获取需方的个性化需求，帮助供方定准定位目标，然后依据需求提供产品，最终实现供需双方的最佳匹配。\n\n\n\n\n具体应用举例，也可以归纳为三类。\n\n一是个性化产品，比如智能化的搜索引擎，搜索同样的内容，每个人的结果都不同。或者是一些定制化的新闻服务，或者是网游等。\n\n第二种是精准营销，现在已经比较常见的互联网营销，百度的推广，淘宝的网页推广等，或者是基于地理位置的信息推送，当我到达某个地方，会自动推送周边的消费设施等。\n\n第三种是选址定位，包括零售店面的选址，或者是公共基础设施的选址。\n\n这些全都是通过对用户需求的大数据分析，然后供方提供相对定制化的服务。\n\n应用的第二个方向，预测。\n\n预测主要是围绕目标对象，基于它过去、未来的一些相关因素和数据分析，从而提前做出预警，或者是实时动态的优化。\n\n\n\n\n从具体的应用上，也大概可以分为三类。\n\n一是决策支持类的，小到企业的运营决策，证券投资决策，医疗行业的临床诊疗支持，以及电子政务等。\n\n二是风险预警类的，比如疫情预测，日常健康管理的疾病预测，设备设施的运营维护，公共安全，以及金融业的信用风险管理等。\n\n第三种是实时优化类的，比如智能线路规划，实时定价等。\n\n以上呢，是各种文献资料里，对于大数据可以用来做什么的一些畅想，事实上也许大数据可以做的事情，可以扩展到方方面面。\n\n但是，我们再看现实中，大数据实际应用到了什么程度呢？\n\n我认为，目前大数据真正实现了商业化的应用，只有一种，就是互联网营销。\n\n其他我们前面列举的方向，会有些初步的应用，但基本都还停留在探索的阶段。比如疫情预测，无抵押信用贷款等，对于准确性、精细度、可推广性等方面还有待推敲。\n\n造成大数据实际应用与目标蓝图之间差距的主要原因是什么，我认为是数据源的问题。\n\n你必须先获得数据，然后才能应用数据。\n\n因此，数据的可获取性，成为大数据在具体行业应用性评价的一个重要维度。\n\n可以从数据的标准化、开放性和集中度几个维度衡量数据可获取性\n\n同时，获取了数据之后，在应用数据方面，可以从大数据应用的潜在价值维度来衡量，包括效率的提升、成本降低或者是新模式的产生。\n\n此外，还可以从大数据行业应用的可复制/推广性的角度来衡量，不仅包括在本行业内的推广，同时也包括跨行业的推广性。\n\n从三个维度，我个人对大数据在各行业应用的可能性做了一个定位，但这个定位还是非常定性和粗略的，具体可能还需要对行业有更多的大数据应用的探讨和探索。\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (37, 26, '2020大数据就业怎样？大数据好就业吗', '', '近几年，大数据不可谓不火，尤其是2017年，发展大数据产业被写入政府工作报告中，大数据开始不只是出现在企业的战略中，也开始出现在政府的规划之内，可以说是互联网世界的宠儿。科多大数据带你看下2017年大数据行业就业情况怎么样\n', '科科程程', '', '近几年，大数据不可谓不火，尤其是2017年，发展大数据产业被写入政府工作报告中，大数据开始不只是出现在企业的战略中，也开始出现在政府的规划之内，可以说是互联网世界的宠儿。科多大数据带你看下2017年大数据行业就业情况怎么样\n\n据数联寻英发布《大数据人才报告》显示，目前全国的大数据人才仅46万，未来3-5年内大数据人才的缺口将高达150万，越来越多人加入到大数据培训，都希望在大数据培训机构中学习最前沿的知识，找一份不错的工作。\n\n大数据产业的背景\n\n据职业社交平台LinkedIn发布的《2016年中国互联网最热职位人才报告》显示，研发工程师、产品经理、人力资源、市场营销、运营和数据分析是当下中国互联网行业需求最旺盛的六类人才职位。其中研发工程师需求量最大，而数据分析人才最为稀缺。领英报告表明，数据分析人才的供给指数最低，仅为0.05，属于高度稀缺。数据分析人才跳槽速度也最快，平均跳槽速度为19.8个月。\n\n根据中国商业联合会数据分析专业委员会统计，未来中国基础性数据分析人才缺口将达到1400万，而在BAT企业招聘的职位里，60%以上都在招大数据人才。\n\n大数据就业方向\n\nJava大数据毕业之后的主要从事工作举例如下：\n\n1.大数据开发工程师\n\n基础大数据服务平台，大中型的商业应用包括我们常说的企业级应用(主要指复杂的大企业的软件系统)、各种类型的网站等。负责搭建大数据应用平台以及开发分析应用程序。\n\n2.大数据分析师\n\n负责数据挖掘工作，运用Hive、Hbase等技术，专门对从事行业数据搜集、整理、分析，并依据数据做出行业研究、评估和预测的专业人员。以及通过使用新型数据可视化工具如Spotifre，Qlikview和Tableau，对数据进行数据可视化和数据呈现。\n\n等等\n\n大数据就业的钱景(薪酬)\n\n大数据开发工程师\n\n北京大数据开发平均工资：¥ 30230/月。\n\n\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (38, 26, 'Hadoop虚拟机环境、Hadoop环境搭建及安装', '', 'Hadoop是由Apache Lucene创始人Doug Cutting创建的。它起源于开源搜索引擎Apache Nutch。Nutch项目开始于2002年，是一个可以运行的网页爬取工具和搜索引擎系统，但是这个系统无法解决数十亿的搜索问题。', '科科程程', '', '1.1Hadoop简介\n1.1.1Hadoop的诞生\nHadoop是由Apache Lucene创始人Doug Cutting创建的。它起源于开源搜索引擎Apache Nutch。Nutch项目开始于2002年，是一个可以运行的网页爬取工具和搜索引擎系统，但是这个系统无法解决数十亿的搜索问题。\n\n三篇划时代论文的诞生对Hadoop的诞生起到了决定性作用。\n\n第一篇论文：GFS\n2003年谷歌发表了 “The Google File System（谷歌文件系统，简称GFS）”的论文，GFS的架构能够满足在网页爬取和索引过程中产生的超大文件的存储需求。于是，在2004年Nutch团队开始做GFS的开源版本实现，也就是Nutch分布式文件系统（NDFS）。\n\n第二篇论文：MapReduce\n2004年谷歌发表了“MapReduce：Simplified Data Processing on Large Cluster（大型集群的数据简化处理）”的论文。2005年，Nutch团队在Nutch上实现了MapReduce。\n\n2006年2月，Nutch开发人员将NDFS和MapReduce移除Nutch形成一个独立的项目，命名为Hadoop。这个名字不是缩写，是生造出来的。\n\n第三篇：BigTable\n2006年谷歌发表了“BigTable：A Distributed Storage System for Structured Data（一个结构化数据的分布式存储系统）”的论文。Powerset公司根据BigTable的思想，发起了HBase，即Hadoop Database。\n\n1.1.2Hadoop重要里程碑\n2008年1月，Hadoop成为Apache的顶级项目。背后主要的公司为雅虎，主要用Hadoop来支撑雅虎的搜索引擎系统。\n\n2013年 Hadoop 2.0发布\n2017年 Hadoop 3.0 发布\n\n1.1.3Hadoop主要发行版本\nApache Hadoop原始版本\nCloudera版本（Cloudera’s Distribution Including Apache Hadoop，简称“CDH”）\nHortonworks版本（Hortonworks Data Platform，简称“HDP”）\nMapR\n此外，还有一些其他的发行版，如华为、Intel等。\n\n1.2Hadoop生态系统\nHadoop从最开始的HDFS和MapReduce发展至今，已经形成一个庞大的生态系统。主要包括：\nHDFS：分布式文件系统\nYARN：资源管理与调度系统\nMapReduce：分布式处理框架\nPig、Hive：类SQL的数据查询\nMahout、Spark MLib：机器学习库\nHBase：分布式列数据库\nZookeeper：集群管理\nOozie：任务调度\nFlume、Sqoop：数据导入导出\nSolr&Lucene：搜索与索引\nAmbari：集群监控与维护\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (39, 26, 'Hadoop 踩坑笔记 + IDEA + Hadoop基础环境搭载及运行', 'http://localhost:8888/cms/upload/054fda86-dfd6-4481-9256-7ba9b2040448.png', '先简述一下，作为一个android开发狗，刚刚入坑hadoop对后台的IDEA开发不是很熟悉，按各网站上的描述搭建环境各种被坑，于是决定写一篇傻瓜式的安装windows+IDEA+Hadoop环境搭载及运行的文章。（忽略hadoop本身的环境配置和运行）', '科科程程', '', '先简述一下，作为一个android开发狗，刚刚入坑hadoop对后台的IDEA开发不是很熟悉，按各网站上的描述搭建环境各种被坑，于是决定写一篇傻瓜式的安装windows+IDEA+Hadoop环境搭载及运行的文章。（忽略hadoop本身的环境配置和运行）\n\n    1.下载hadoop，IDEA，配置环境变量，hadoop的配置参数，添加winUtils.exe\n                1.1下载hadoop https://archive.apache.org/dist/hadoop/common/这个是hadoop的下载地址。选择自己的所在版本的下载地址笔者用的是2.5.0版本的文件。\n\nhadoop下载\n                   注意是下载其中的.tar.gz文件不带src，src只是其中一小部分资源文件\n\nhadoop下载\n                \n                1.2下载IDEA,https://www.jetbrains.com/idea/download/#section=windows,笔者是下载IDEA专业版后用破解补丁破解的，毕竟社区版功能太少不够用的。顺便贴上破解教程地址https://mp.weixin.qq.com/s?__biz=MzI0OTc0MzAwNA==&mid=2247483806&idx=1&sn=5c60673c73fdd32b90776831123e9fd0&chksm=e98d926ddefa1b7b5dfd5bac3cb0d341a30afd3dac960059a97dca1a07f5701e0f78653281d4&scene=21#wechat_redirect\n\n                1.3.配置Hadoop环境变量，java的环境变量就不说了，毕竟学hadoop java基础肯定都是有的。将下载的压缩包用压缩工具解压到指定目录然后和java一样将hadoop的安装目录以HADOOP_HOME的形式配置到环境变量中，\n\nHADOOP_HOME\n\n\nPATH的配置\n                1.4.1配置环境参数，现在cmd命令行中输入hadoop，如果出现Error: JAVA_HOME is incorrectly set. Please update F:\\hadoop\\conf\\hadoop-env.cmd类似的字样，请修改安装目录下的hadoop-env.cmd（关于路径如果这个文件在etc下，那便改etc目录的这个文件）为\n\n后面的路径填自己的jdk的路径，目录不能包含空格，如果在Program Files文件夹下请用PROGRA~1替代\n                        1.1.5因为我们将hadoop运行在windows上需要提供兼容，所以要添加winutils.exe文件到hadoop的bin目录下，这个是winutils.exe的下载地址     https://pan.baidu.com/s/1MLs2ic4KKeuQbjTgHG6P_w  密码：ihgu\n\n\n\n复制到hadoop/bin下\n    2.创建MAVE项目，导入相应的依赖，配置Aritifact\n                2.1打开IDEA创建MAVEN项目\n\n\n\n打开IDEA\n\n\n创建MAVEN项目，SDK使用自己版本的JDK\n\n\ngroupId团队id，一般是com.所属团队英文名,artifactId产品ID一般为产品英文名\n                2.2导入hadoop相关的依赖\n\n                 可以直接从hadoop的安装目录中的share包依赖所有jar\n\n\n\n添加hadoop的share依赖\n                    也可以通过maven直接添加\n\n                    maven 依赖- 代码链接\n\n                    不过即使依赖了share包，也需要在maven中依赖 log4j和slf4j库（在上面的代码链接中已给出，两个库是用来做hadoop的日志打         印的，如果没有依赖则运行时会报ClassNotFound异常）\n\n                    然后在项目的resource目录下新建log4j.properties文件 进行如下配置\n\n\n\n        \nlog4j.rootLogger = debug,stdout\n\n### 输出信息到控制台 ###\n\nlog4j.appender.stdout = org.apache.log4j.ConsoleAppender\n\nlog4j.appender.stdout.Target = System.out\n\nlog4j.appender.stdout.layout = org.apache.log4j.PatternLayout\n\nlog4j.appender.stdout.layout.ConversionPattern = [%-5p] %d{yyyy-MM-dd HH:mm:ss,SSS} method:%l%n%m%n\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (40, 26, 'hadoop搭建伪分布式集群（centos7+hadoop-3.1.3）', 'http://localhost:8888/cms/upload/f1d63e57-977d-4532-8f07-5649f0e0b9f9.png', 'hadoop搭建伪分布式集群（centos7+hadoop-3.1.3）hadoop搭建伪分布式集群（centos7+hadoop-3.1.3）hadoop搭建伪分布式集群（centos7+hadoop-3.1.3）hadoop搭建伪分布式集群（centos7+hadoop-3.1.3）hadoop搭建伪分布式集群（centos7+hadoop-3.1.3）hadoop搭建伪分布式集', '科科程程', '', 'Hadoop三种安装模式\n\n搭建伪分布式集群准备条件\n\n第一部分 安装前部署\n\n1.查看虚拟机版本\n\n2.查看IP地址\n\n3.修改主机名为hadoop\n\n4.修改 /etc/hosts\n\n5.关闭防火墙\n\n6.关闭SELINUX\n\n7.安装yum源并安装基础包\n\n8.关闭不必要的服务\n\n9.安装Java环境\n\n第二部分 Hadoop正式安装\n\n1.安装Hadoop\n\n2.修改hadoop的5个配置文件\n\n3.解决互信问题\n\n第三部分 启动Hadoop集群\n\n1.格式化NameNode\n\n2.启动Hadoop集群\n\n3.验证集群是否启动成功\n\n4.关闭hadoop集群\n\n5.登录HDFS管理界面：http://ip:50070\n\n6.登录MR管理界面： http://ip:8088\n\n第四部分 一些问题？\n\n1.启动Hadoop集群报错：WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n\n2.启动Hadoop集群报错：Attempting to operate on hdfs namenode as root but there is no HDFS_NAMENODE_USER defined. Aborting operation.\n\n3.启动hadoop后无法访问50070端口\n\n4.Hadoop集群启动后，使用jps查看没有DataNode进程？\n\n\n\nHadoop三种安装模式\n\n1.Hadoop单机模式\n\n单机模式是Hadoop默认的安装模式，这种安装模式主要就是并不配置更多的配置文件，只是保守的去设置默认的几个配置文件中的初始化参数，他并不与其他节点进行交互，并且也不使用HDFS文件系统，它主要就是为了调试MapReduce程序而生。\n\n2.Hadoop伪分布式安装模式\n\nHadoop伪分布式安装，需要配置5个常规的配置文件（XML），并且这里涉及到了NameNode和DataNode节点交互问题，而且NameNode和DataNode在同一个节点上，还需要配置互信。其实从严格意义上来讲，我们的伪分布式集群，就已经可以称之为真正意义上的集群了，而且这里也包含了hdfs和MapReduce所有组件，只不过就是所有组件在同一个节点上而已。\n\n3.Hadoop完全分布式安装模式\n\nHadoop完全分布式集群主要分为：常规Hadoop完全分布式集群和Hadoop HA集群（这里我们主要针对的是NameNode个数和NameNode的高可用保障机制而言）。由此可知较伪分布式集群而言，我们的完全分布式集群，所有处理节点并不在同一个节点上，而是在多个节点上。\n\n那么我们如何搭建一个伪分布式集群呢？\n\n我们要准备好以下条件：\n\n1.我们的机器上需要安装VM虚拟软件\n\n我安装的是VMware Workstation 11，安装方式大家可自行百度。\n\n2.在虚拟软件上安装Linux（RHEL CENTOS UBUNTU...）\n\n我安装的是Centos 7，安装方式可参考这里\n\n3.配置好我们的java环境\n\nHadoop毕竟是Java程序的集合，所以在安装Hadoop软件之前，我们必须配置好Java环境。我安装的的是jdk1.8版本。\n\n4.安装HADOOP并做相应配置\n\n我安装的是hadoop-3.1.0.tar.gz\n\n这真是我踩过的一个大坑，当我好不容易安装了hadoop-3.1.0之后，再安装hbase时，发现竟然hadoop-3.1.0不支持任何版本的hbase。。。。好心塞啊，所以大家如果想要后期学习hbase的话，还是建议不要安装这个版本的hadoop了，最好安装hadoop-2.7.1+版本，因为它支持所有的hbase版本。具体看这里。\n\n当然下面的步骤同样适应于hadoop-2.7.7版本的安装，其中有些微小的区别我也已经作了说明。\n\n第一部分 安装前部署\n\n首先，我们使用xshell远程连接我们的虚拟机，最好用root用户登录。\n\n1.可以通过如下三个命令查看我们安装的虚拟机版本\n\n[root@localhost ~]# cat /etc/issue #不知为什么我的虚拟机显示\\S，正常情况下应该显示版本信息。\n\n\\S\n\nKernel \\r on an \\m\n\n[root@localhost ~]# cat /etc/redhat-release\n\nCentOS Linux release 7.5.1804 (Core)\n\n[root@localhost ~]# cat /etc/system-release\n\nCentOS Linux release 7.5.1804 (Core)\n\n2.通过 ip addr 可以查看虚拟机的IP地址。注意：centos 7换了查看IP地址的命令【ifconfig==>ip】\n\n这里推荐2篇参考博文：\n\n（1）ifconfig: command not found（CentOS专版，其他的可以参考）\n\n（2）Centos 7 系统安装完毕修改网卡名为eth0\n\n[root@hadoop ~]# ifconfig\n\n-bash: ifconfig: command not found\n\n[root@hadoop ~]# ip addr\n\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n\n    inet 127.0.0.1/8 scope host lo\n\n      valid_lft forever preferred_lft forever\n\n    inet6 ::1/128 scope host\n\n      valid_lft forever preferred_lft forever\n\n2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n\n    link/ether 00:0c:29:bd:97:52 brd ff:ff:ff:ff:ff:ff\n\n    inet 192.168.42.134/24 brd 192.168.42.255 scope global noprefixroute dynamic eth0\n\n      valid_lft 1506sec preferred_lft 1506sec\n\n    inet6 fe80::b46e:fbba:4f30:8322/64 scope link noprefixroute\n\n      valid_lft forever preferred_lft forever\n\n3.修改主机名为hadoop。方法：修改配置文件 /etc/hostname 保存退出\n\n[root@localhost ~]# hostname\n\nlocalhost.localdomain\n\n[root@localhost ~]# cat /etc/hostname\n\nlocalhost.localdomain\n\n[root@localhost ~]# vi /etc/hostname\n\n[root@localhost ~]# cat /etc/hostname\n\nhadoop\n\n[root@localhost ~]# reboot\n\n----------重启后----------\n\n[root@hadoop ~]# hostname\n\nhadoop\n\n注意：网上还有一种普遍的方式修改Linux主机名（点这里），但是测试之后发现在centos 7根本不生效，我估计这种方式可能是仅适用于低版本的Linux。\n', 1, 0, 0, 0, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (41, 22, '请记住杨绛先生的这4句话（深度文字）', 'http://localhost:8888/cms/upload/45f777b5-037b-41a3-995e-b9cc1e965cec.jpg', '人的一生是一场漫长而坎坷的旅程，多去汲取别人人生的经验，我们在路途上就能少走些弯路，受益终生。杨绛先生的这4句话，字字都是珠玑，读懂了它们，就读懂了人生。“读书多了，容颜自然改变，许多时候，自己可能以为许多看过的书籍都成过眼烟云，不复记忆，其实它们仍是潜在气质里、在谈吐上、在胸襟的无涯，当然也可能显露在生活和文字中。', '科科程程', '', '人的一生是一场漫长而坎坷的旅程，多去汲取别人人生的经验，我们在路途上就能少走些弯路，受益终生。\n杨绛先生的这4句话，字字都是珠玑，读懂了它们，就读懂了人生。\n\n01\n\n你的问题主要在于读书不多而想得太多\n\n人为什么要读书？\n\n许多人也许都曾问过自己这样一个问题？\n\n“我读过的书，很快就都忘记了，那么读书究竟还有什么用呢？”\n\n三毛说：\n\n“读书多了，容颜自然改变，许多时候，自己可能以为许多看过的书籍都成过眼烟云，不复记忆，其实它们仍是潜在气质里、在谈吐上、在胸襟的无涯，当然也可能显露在生活和文字中。”\n\n你读过的书，最终决定了你是什么样的人。\n\n杨绛先生从小就爱读书，在一篇《我爱清华图书馆》的文章里，她温情地把读书比作“串门儿”：\n\n“借书看，只是要求到某某家去‘串门儿’，而站在图书馆书库的书架前任意翻阅，就好比家家户户都可任意出入，这是唯有身经者才知道的乐趣。”\n\n不读书的人，只过一世；读书的人，却可以体验千百种人生。\n\n在人生的目标还没有清晰显现之前，与其焦灼、忧虑，不如去读一本好书，静下心来充实自己。\n\n你要相信，你若盛开，清风自来。\n\n当你真正准备好的时候，整个世界都会为你让步。\n\n02\n\n我立志一生不说违心的话，不做违心的事\n\n人活一世，所求的不过是一个心安理得，仰不愧天，俯不怍地。\n\n16岁时，杨绛在当时著名的振华女校读中学。\n\n有一次，学生会搞运动，要各学校学生上街搞宣传，在街上演讲，呼吁人们参加革命。\n\n杨绛不愿参加，于是恳求父亲向学校说“家里不赞成”，这样就能避免去做宣传了。\n\n父亲却一口回绝，他告诉女儿，不肯，就别去，不要拿别人当挡箭牌。\n\n杨绛还是犹豫：“不行啊，少数得服从多数啊！”\n\n父亲却严肃地说：“该服从的就服从；你有理，也可以说。去不去由你。......你知道林肯说的一句话吗？Dare to say no！你敢吗？”\n\n第二天，杨绛到学校后，勇敢地说出了自己的答案：“我不赞成，我不去。”\n\n从那以后，杨绛从父亲那里学到了人生最珍贵的一课，那就是敢于说“不”的勇气，勇敢做自己的勇气。\n\n“文革”时，钱钟书在中国社科院文学所被贴了大字报，杨绛就在下边一角贴了张小报澄清辩诬。被揪出来批斗时，她仍是据理力争：\n\n“就是不符合事实！就是不符合事实！”\n\n在一个人人都狂乱不安、黑白颠倒的时代，杨绛却始终坚守心中的准则。\n\n她始终牢记着父亲的话——多数并不一定对，你有理，你就去说，永远都要有说”不“的勇气。\n\n03\n\n我以为，夫妻间最重要的是朋友关系\n\n杨绛与钱钟书是许多人眼中的模范夫妻，他们的婚姻更是让人艳羡。\n\n杨绛与钱钟书都是当时著名的学者，甚至在钱钟书写出《围城》前，杨绛的名字更为人们所耳熟能详。\n\n她的《弄假成真》、《游戏人间》、《风絮》等戏剧，带给了她无限的荣耀，可就在戏剧创作的巅峰时刻，当她知晓丈夫决定写作《围城》时，便选择退居幕后，辅助钱钟书进行写作，心甘情愿地为他做“灶下婢”。\n\n钱钟书写作《围城》时，每写完一小节必要把稿子拿给杨绛看一看，悉心听取她的意见。\n\n在《人·兽·鬼》的手稿中，钱钟书写下这样一段话：\n\n赠予杨季康，绝无仅有地结合了各不相容的三者：妻子、情人、朋友。\n\n曾有人向杨绛讨要婚姻和爱情的秘诀，杨绛说:\n\n“我以为，夫妻间最重要的是朋友关系，即使不能做知心的朋友，也该是能做得伴侣的朋友或互相尊重的伴侣。门当户对及其他，并不重要。”\n\n从年少相识起，钱钟书与杨绛风雨同舟65载，无论经过多少磨难，他们始终互相扶持，彼此依偎，靠得不单单只是爱情，更是彼此对对方毫无保留的信任、欣赏与奉献。\n\n04\n\n常言“彩云易散”，乌云也何尝能永远占领天空。\n\n写下《我们仨》时，钱钟书和女儿钱瑗都已去世，曾经相亲相爱的一家三口，最终就只剩下杨绛一人。\n\n说不伤心，怎么可能呢？\n\n在《我们仨》里，杨绛说;\n\n\"钟书逃走了，我也想逃走，但是逃到哪里去呢？我压根儿不能逃，我得留在人间，打扫现场，尽我应尽的责任。\"\n\n可是哪怕再悲伤，她仍旧宽慰着旁人，“这并不是坏事，你往深处想想，让痛苦的担子由我来挑，这难道不是一件好事吗？”\n\n不是每个人都有这样的勇气，在痛失所爱后，仍旧坚强地活下去。\n\n在《将饮茶》里她说：\n\n“常言‘彩云易散’，乌云也何尝能永远占领天空。乌云蔽天的岁月是不堪回首的，可是停留在我记忆里不易磨灭的，倒是那一道含蕴着光和热的金边。”\n\n在她的那些如清茶一般韵味隽永的文字里，饱含着的正是对苦难的宽容，对生命的珍视。\n\n人生路上，总是一程风雨一程晴，谁的人生又能永远一帆风顺呢？\n\n我们所能做的，便是始终豁达地面对人生、面对苦难。\n\n如同苏轼一般，竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生。\n\n人之有生也，如太仓之粒，如灼目之电光，如悬崖之朽木，如逝海之微波。知此者如何不悲？如何不乐？\n\n生命，是一场漫长而又短暂的旅程。我们会走过平原，也会跨过荆棘，会体味甜蜜，也不得不承受悲伤，可我们依旧要勇敢地、不懈地走下去。\n\n因为生命的美好，就在那悲喜交集里。\n\n', 1, 0, 0, 1, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (42, 22, '一本书一句话｜《巴菲特对女儿的忠告》', 'http://localhost:8888/cms/upload/62fb034a-20a4-409a-8383-557fb077aeec.png', '巴菲特对女儿说：“孩子你要明白，你的最佳配偶应该是你人生战场的盟友，而不是找个满足你懒惰行为和巨婴思想的人。大姨妈来了给你倒温水，半夜里给你买烧烤，这样的男人并不是什么稀缺物种，然而现实中很多女人偏偏为这种低成本付出感动得死去活来。真正稀缺的，是对方的谈吐、知识面、商业视野、控制局面的能力，以及稳定的情绪。不要小看这些特点！因为培养这些特点所耗的成本极高，可遇而不可求！”', '科科程程', '', '巴菲特对女儿说：“孩子你要明白，你的最佳配偶应该是你人生战场的盟友，而不是找个满足你懒惰行为和巨婴思想的人。大姨妈来了给你倒温水，半夜里给你买烧烤，这样的男人并不是什么稀缺物种，然而现实中很多女人偏偏为这种低成本付出感动得死去活来。真正稀缺的，是对方的谈吐、知识面、商业视野、控制局面的能力，以及稳定的情绪。不要小看这些特点！因为培养这些特点所耗的成本极高，可遇而不可求！”\n\n有趣的是，很多男人往往只掐头去尾地给自己的女人讲这段话：“你要找的不是那种看起来对你无微不至的男人，生活中那些小恩小惠都是低成本的付出而已……”\n\n他们会隐藏自己根本就不具备稀缺性的基本事实。即便有个别的稀缺性，也往往因为不稳定的情绪，不包容的个性，不担当的处事而把日子过得一团糟。\n\n可是，即便具有上面所说的一切优点，对你不好怎么办？不爱你怎么办？自私自利怎么办？三观不合怎么办？好色花心怎么办？……\n\n其实，你的人生应该怎么过，你的伴侣应该怎么选？从来没有标准答案！\n\n如果有，那就不是生活，是生意了。\n\n那么，我们就从生意的角度、从需求洞察的角度、从用户体验的角度看，一个懂得用小恩小惠讨女人欢心的男人，如果把心稍稍用在正道上，一定是个很棒的产品经理或营销高手。\n\n人，本来就是感性动物。\n\n如果只有理性，活着该是多么乏味；如果放任感性，人生又该多么混乱。\n\n凡事无绝对。\n\n适合的未必是最好的，最好的未必是适合的。\n\n如果非要问什么样的男人才是好男人？\n\n窃以为：正直，善良，勤奋，担当，这些都是男人该有的的基本要素。\n\n至于好坏，都是相对的。\n\n两性关系的悖论在于：爱上的是对方的优点，又不得不和对方的缺点长久相处。\n\n婚姻能走多远，取决于你对对方缺点的接纳程度。\n\n但，这不是不思进取的理由。\n\n活着，就要成长。\n\n活着，就要努力变成更好的自己。\n\n优不优秀不是重点，重点在于，打了败仗翻了船，你们依然在一起。\n\n有一种幸福，叫做相伴成长。\n', 1, 0, 0, 1, NULL, '2020-11-08', 1, '2020-11-08');
INSERT INTO `tb_article` VALUES (43, 35, '特朗普为什么不认输？外媒：他实际上已经负债累累', 'http://localhost:8888/cms/upload/8381e3b4-9018-41a2-b730-535758edd368.png', '美国宪法规定，白宫的权力交接将在2021年1月20日中午举行。如果未能成功连任，那么现任总统特朗普应该在此之前离开白宫。然而，面对有关大选失利的预测，他一再声称存在“舞弊”，让白宫和平地、至少是不具争议地完成权力交接面临风险。', '科科程程', '', '西班牙《20分钟》日报网站11月6日发表一篇观察报道，题为《白宫面临过渡带来的不确定性》。全文摘编如下：\n\n美国宪法规定，白宫的权力交接将在2021年1月20日中午举行。如果未能成功连任，那么现任总统特朗普应该在此之前离开白宫。然而，面对有关大选失利的预测，**他一再声称存在“舞弊”，让白宫和平地、至少是不具争议地完成权力交接面临风险**。\n\n巴塞罗那国际事务研究中心研究员弗朗西斯·贾尔斯在接受采访时表示，虽然很难预测未来局势，但特朗普可能会毁了白宫的权力过渡。过去3天以来，一些颇有影响力的共和党参议员在选举舞弊问题上与他产生分歧，因为他们深知不能支持特朗普这种可能带来毁灭性后果的态度。虽然存在很多不确定因素，但共和党的态度对未来局势发展将起到至关重要的作用。\n\n贾尔斯表示，就连总统的亲密盟友、美国参议院多数党领袖麦康奈尔都公开表示，尚无证据表明存在选举舞弊。麦康奈尔对何种方式才有利于自己的职业生涯心知肚明。\n\n贾尔斯认为，特朗普将继续呼吁重新计票并向法院提出上诉。特朗普之所以对总统一职抓得如此之紧，表面上来看，选举失利无疑是他人生的滑铁卢；但还存在一个深层次的原因，那就是他实际上已经负债累累，选举失利势必给他个人及企业的财务状况雪上加霜。\n\n贾尔斯说，从11月到明年1月这段时间，总统的权力依然很大。比如，他可以赦免罪犯、开除公职人员（特朗普已经警告说要开除疫情责任人）等。然而，最大的问题很可能出现在美国街头。目前，包括军方在内的所有部门都必须谨慎行事，直到成功实现权力交接。\n\n贾尔斯指出，4年前的权力过渡就是一场灾难。特朗普当时并没有做好准备，间接导致奥巴马也没能做好协调工作。对于这样一个秉持民粹主义、狂妄自大的人，很难预测他还会做出何种反常之举。', 1, 0, 1, 0, NULL, '2020-11-09', 1, '2020-11-09');
INSERT INTO `tb_article` VALUES (44, 35, '考验普京的时候到了！', 'http://localhost:8888/cms/upload/ed2be6ef-1c93-4da1-9053-dcdadc94cd55.png', '美国大选水落石出，西方国家纷纷祝贺拜登，但不少西方媒体注意到，莫斯科一直静悄悄。西方人很诧异。但其实完全可以理解，拜登是宣布胜利了，但特朗普毕竟还没认输，还有一连串官司要打，俄罗斯保持点耐心和定力，也实属正常。', '科科程程', '', '# 考验普京的时候到了。\n\n美国大选水落石出，西方国家纷纷祝贺拜登，但不少西方媒体注意到，莫斯科一直静悄悄。\n\n以至于有人各种猜测：\n\n2016年特朗普当选，普京两个小时后就发出祝贺；\n\n2020年拜登获胜，普京整整24个小时后没任何动静……\n\n西方人很诧异。但其实完全可以理解，拜登是宣布胜利了，但特朗普毕竟还没认输，还有一连串官司要打，俄罗斯保持点耐心和定力，也实属正常。\n\n但对普京来说，国际形势正在大变，接下来的考验可能非常严峻。\n\n## 几个观察点吧：\n\n## 第一，拜登上台，全世界压力最大的，就是俄罗斯。\n\n别忘了，拜登可是明确说过：我认为俄罗斯是最大的敌人，我确实这么认为。\n\n至于中国，在拜登口中，是一个最主要的竞争者。\n\n敌人和竞争者，大家可以体会一下微妙的差别。\n\n## 第二，拜登曾是奥巴马的副手，政策有延续性。\n\n别忘了，正是在奥巴马任上，美国对俄罗斯开始各种制裁，俄罗斯也被美国一脚踢出八国集团。\n\n奥巴马和普京，一张非常有名的照片，就是在一次国际会议间隙，两人四目相对，没有任何笑脸，也没有握手。\n\n真的话不投机半句多。\n\n\n## 第三，民主党对俄罗斯，更没有什么好感。\n\n过去四年，是美俄关系最糟糕的四年。特朗普使出浑身解数，试图改善美俄关系，但撞上的是国内反俄铁墙，在民主党主导下，美国对俄罗斯的制裁一波接一波。\n\n甚至特朗普本人，也因此被拜登批评是“普京的小狗”。\n\n以至于普京不得不调侃：你们这样贬低美国总统，是帮我们提高国际威望啊，我们都不知道自己影响力这么大……\n\n特朗普尚如此，批评特朗普是小狗的拜登，你可想见会发生什么。\n\n## 第四，拜登对普京，也没有什么好感。\n\n早在2011年，在接受《纽约客》杂志采访时，拜登讲了这样一个故事：有一次，他会晤普京的时候对他说，“我正在注视你的眼睛，我不认为你有灵魂。” “普京看着我笑了，说，‘我们彼此理解。’”\n\n1，直截了当，说普京没有灵魂，可见心中的厌恶。\n\n2，这种个人关系，也是美俄糟糕关系的一个缩影。\n\n3，当然，普京用幽默化解了，但心中的不快，也可想而知。\n\n一句话，过去四年，美俄关系已经很糟糕；但未来四年，可能会更加糟糕。\n\n\n（二）\n\n凛冬将至。\n\n莫斯科的这个冬天，可能格外寒冷。\n\n美国媒体就说，对于特朗普的失败，一些俄罗斯人很失望。\n\n比如，一位名叫卡拉什尼科夫的政治家就感叹：\n\n不幸的是，特朗普输了，可以理解，我没有什么好高兴的……我们所有人都应该在想：俄罗斯现在应该怎么办？准备好与SWIFT（国际银行支付系统）断开连接吗？欧洲会排队对我们制裁吗？\n\n当然，俄罗斯人也很清醒，即便特朗普上台，情况也好不到哪里去。\n\n毕竟，美俄对立是大前提，在特朗普执政的四年，两国关系继续恶化，特朗普确实想取消制裁，但根本没有执行力。\n\n但现在，来了一个更反俄的拜登。\n\n普京也在绸缪对策。\n\n事实上，在美国大选前夕的10月7日，普京在接受媒体采访时，就说了几段很意味深长的话。\n\n谈到特朗普，普京说：我们知道特朗普多次表示支持发展俄美关系。毫无疑问，我们非常珍视这一点。当然，特朗普总统以前说过的那些想法并未完全兑现。\n\n也就是说，别看全世界都认为特朗普和我关系很好，但我们对特朗普也很失望。\n\n谈到拜登，普京说：\n\n我们注意到了他相当尖锐的反俄言论，遗憾的是，我们已经习惯了。但这远非全部。例如，拜登公开说，他准备延长《新削减战略武器条约》或签署新的限制进攻性战略武器条约，这已经是有助于我们未来开展协作的重要表态了。\n\n拜登你很反俄，但我们也熟悉了。另外，你多少也有可取的地方。\n\n普京最后的结论：我们将与任何一位美国总统——即美国人民信任的那个人——开展合作。\n\n这样的表态，够老辣吧。\n\n当然，普京就是普京。如果总是四平八稳，那就不是普京了。\n\n在谈到美国民主党时，他明显开始发挥了。\n\n他大致是这样说的：\n\n有些事情值得一提。民主党传统上更接近所谓的自由价值观，更接近社会民主理念。毕竟，我是苏共党员近20年，更确切地说是18年。我是普通党员，但可以说我相信党的思想。我仍然喜欢这些左翼价值观。平等友爱。他们有什么坏处？\n\n所以，这在某种程度上可以被看作是共同的价值观，如果不是我们的统一体的话。我不怕这样说。这是真的。\n\n这样的话，估计也就普京敢这么说,。但显然，也是经过深思熟虑的。\n\n1，我们俄罗斯和民主党，其实是有共同价值观。\n\n2，当然，普京也表明了心迹：我曾是苏共党员，我还是喜欢左翼价值观。\n\n普京就是普京！', 1, 0, 1, 0, NULL, '2020-11-09', 1, '2020-11-09');
INSERT INTO `tb_article` VALUES (45, 35, '美媒“官宣”拜登当选，媒体“错判”了咋办？', 'http://localhost:8888/cms/upload/124595fd-bad5-454e-bc49-1e5a6b377ee0.png', '当地时间11月7日，美联社、福克斯新闻、《纽约时报》、CNN、NBC等多家美媒宣布，民主党总统候选人拜登已获得超过270张选举人票，赢得了2020年总统选举。之后，媒体都称呼拜登为“当选总统”（President-elect），拜登也将自己的推特认证改为“当选总统”。', '科科程程', '', '\n当地时间11月7日，美联社、福克斯新闻、《纽约时报》、CNN、NBC等多家美媒宣布，民主党总统候选人拜登已获得超过270张选举人票，赢得了2020年总统选举。之后，媒体都称呼拜登为“当选总统”（President-elect），拜登也将自己的推特认证改为“当选总统”。\n\n此外，全球多国领导人发布声明，祝贺拜登和他的副总统搭档哈里斯赢得大选。拜登随后在特拉华州发表了全国讲话，称美国人民给了他“彻底的、令人信服的胜利”。\n\n▲民主党总统候选人乔·拜登与妻子在特拉华州威尔明顿的讲话舞台上拥抱。美联社截图\n\n然而，现任总统、共和党总统候选人特朗普却发表声明拒绝承认这一结果，称“总统是由合法选票决定，而不是新闻媒体”。\n\n事实上，截至北京时间11月8日，美国许多州仍在计票中，一些关键摇摆州的计票率仅为90%左右。为何媒体机构能够提前预判大选结果？媒体机构又是如何做出判定的？他们的宣告算不算是“官宣”？\n\n━━━━━\n\n**## 媒体如何判定结果？**\n\n实际上，美国大选是由各州自行计票统计数据的，并没有一个统一的机构汇总选举结果。正是因为考虑到民众对于大选信息的密切关注，所以大多数媒体机构都会实时收集各州计票数据，在各自网站上跟进直播计票情况，并根据数据预测结果，做出各州归属判定。\n\n当地时间11月7日，当主流媒体纷纷判定拜登当选总统时，各大媒体判定拜登获得的选举人票数却存在很大不同。福克斯新闻称，拜登获得290张选举人票；《纽约时报》、《华盛顿邮报》则称，拜登获得了279票。各家媒体的数据为何存在出入？各家媒体又是如何判断各州“变蓝”还是“变红”的呢？\n\n其实在每一年的大选中，各大媒体机构给出的统计票数均有所出入。这是因为美国各家媒体拥有不同的数据库，媒体先从各州投票站调查收集实时投票数、投票总数、投票后民调等数据，再采用不同的模型对尚未计算的选票进行预测。从预测中推断出落后的候选人可否通过尚未计算的选票赢得多数票。一旦判断出落后的候选人无力回天，即便该州计票仍未结束，媒体也会立刻预判该州归属。\n\n在2020年总统大选中，美国有线电视新闻网（CNN）、全国广播公司（NBC）、美国广播公司（ABC）、美国商业无线电视网（CBS）采用的是全国选举报道团（多家美媒组成的联盟，为美国选举提供投票后的民意调查信息）的数据，而福克斯新闻使用的是美联社的数据。美联社此前刊文表示，为保证公布数据的准确性，在2020年的总统选举中，它启动了一个由来自50个州的4000多名地方特约记者组成的信息收集网，逐县收集数据。\n\n各家媒体机构都表示是基于严谨的数据做出判断的。NBC新闻选举小组主任约翰·拉平斯基说，“NBC只有在至少99.5%确信的情况下，才会宣布某一候选人获胜，如果数据太过于接近，我们不会轻易下结论。”福克斯新闻则称，为了得到能够覆盖提前投票选民、选举日投票选民、邮寄选票选民的所有数据，他们在选举前几天在全国范围内进行了电话与网络投票。Politico表示，只有美联社或三大电视台（ABC、CBS、NBC）都宣布了获胜者，它才会宣布胜者。\n\n在众多媒体机构中，美联社的统计结果被认为更加权威、可信。美联社已有170余年的计票历史。在2016年的总统选举中，美联社对所有竞选结果发布的准确率为99.8%，对总统和国会的竞选结果发布准确率为100%。当年也是美联社第一个宣布，特朗普当选第45任美国总统。\n\n━━━━━\n\n## 媒体是否有过错判的案例？\n\n大多数媒体机构为了占得先机，都会在全部计票结果统计出来之前，提前判定结果。即便各家媒体都强调，他们在判定时慎之又慎，但还是无法避免“错判”的情形出现。\n\n据美国犹他州《德律撒新闻报》报道，1948年总统大选时，由共和党总统候选人托马斯·杜威对阵时任美国总统、民主党总统候选人杜鲁门。当时由于印刷工人罢工，报纸印刷的截止日期不得不提前，《芝加哥论坛报》主编马洛尼根据民意调查数据，在报纸上宣布了杜威获胜。结果杜鲁门在最后以不到1%的差距，在加利福尼亚州与伊利诺伊州成功“翻盘”，实现连任。', 1, 0, 1, 0, NULL, '2020-11-09', 1, '2020-11-09');
INSERT INTO `tb_article` VALUES (46, 17, '1', '', '11', '科科程程', '11', '', 1, 0, 0, 0, NULL, '2020-12-04', 1, '2020-12-04');
INSERT INTO `tb_article` VALUES (47, 17, '11', '', '', '科科程程', '', '``', 1, 0, 0, 0, NULL, '2020-12-04', 1, '2020-12-04');
INSERT INTO `tb_article` VALUES (48, 17, 'aaaa', '', 'aaa', NULL, '', 'sdfasdf', 1, 0, 0, 0, NULL, '2021-01-21', 2050, '2021-01-21');

-- ----------------------------
-- Table structure for tb_article_attachment
-- ----------------------------
DROP TABLE IF EXISTS `tb_article_attachment`;
CREATE TABLE `tb_article_attachment`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `article_id` int(11) NOT NULL,
  `url` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `description` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `suffix` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of tb_article_attachment
-- ----------------------------
INSERT INTO `tb_article_attachment` VALUES (1, 4, 'http://localhost:8888/cms/upload/03355670-681c-4933-9a35-c33c4f0fc72e.jpg', NULL, NULL);
INSERT INTO `tb_article_attachment` VALUES (2, 4, 'http://localhost:8888/cms/upload/d96ee37a-07e2-44c7-ad8d-a12f8ffd5bfd.jpg', NULL, NULL);

-- ----------------------------
-- Table structure for tb_article_tag
-- ----------------------------
DROP TABLE IF EXISTS `tb_article_tag`;
CREATE TABLE `tb_article_tag`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `article_id` int(11) NULL DEFAULT NULL,
  `tag_id` int(11) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 23 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of tb_article_tag
-- ----------------------------
INSERT INTO `tb_article_tag` VALUES (1, 4, 6);
INSERT INTO `tb_article_tag` VALUES (2, 4, 5);
INSERT INTO `tb_article_tag` VALUES (22, 6, 5);

-- ----------------------------
-- Table structure for tb_article_view
-- ----------------------------
DROP TABLE IF EXISTS `tb_article_view`;
CREATE TABLE `tb_article_view`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `article_id` int(11) NOT NULL,
  `view_date` date NULL DEFAULT NULL,
  `ip` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Table structure for tb_channel
-- ----------------------------
DROP TABLE IF EXISTS `tb_channel`;
CREATE TABLE `tb_channel`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `parent_id` int(11) NULL DEFAULT NULL,
  `channel_img` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `summary` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `single` char(1) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT 'Y单页|其他非单页',
  `url` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `seo_title` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `seo_keyword` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `seo_description` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `orderby` int(11) NULL DEFAULT NULL,
  `create_date` date NULL DEFAULT NULL,
  `create_user` int(11) NULL DEFAULT NULL,
  `deleted_flag` char(1) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT 'D删除',
  `pos` char(1) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT 'ABCDEFG',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 36 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of tb_channel
-- ----------------------------
INSERT INTO `tb_channel` VALUES (17, 'Spring技术栈', 0, 'http://localhost:8888/cms/upload/f6f9dacb-8d54-4e3e-9725-8e3a036dcad5.png', 'springframework 从最初的2.5版本发展至今，期间已经发生了非常多的修正及优化。许多新特性及模块的出现，使得整个框架体系显得越趋庞大，同时也带来了学习及理解上的困难。', 'N', '', '', '', '', '', NULL, '2020-11-04', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (18, 'Mybatis', 0, 'http://localhost:8888/cms/upload/1c978e62-05a7-4000-821b-973b0e02fb74.png', 'MyBatis 是一款优秀的持久层框架，它支持自定义 SQL、存储过程以及高级映射。MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。', 'N', '', '', '', '', '', NULL, '2020-11-04', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (19, 'Oracle', 0, 'http://localhost:8888/cms/upload/6f35639a-5194-41bc-8492-03f4917a79cd.png', 'ORACLE数据库系统是美国ORACLE公司（甲骨文）提供的以分布式数据库为核心的一组软件产品，是目前最流行的客户/服务器(CLIENT/SERVER)或B/S体系结构的数据库之一', 'N', '', '', '', '', '', NULL, '2020-11-04', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (21, 'java学习', 0, '', ' Java学习路线为： 1、打好Java基础，掌握Java核心技术 2、掌握Java Web技术栈，能够做一些项目 3、掌握Java方面的进阶技术，包括网络编程、并发编程、JVM4、掌握后端进阶技术，比如分布式、缓存、消息队列等技术 其实按照这路线图，若能掌握绝大部分内容加上一些实践，再通过后期的延伸基本可以胜任Java开发工程师的工作。', 'Y', '', '', '', '', 'Java学习路线:Java基础 --> 流程控制 --> 面向对象（包括Java语法） --> Java集合 --> Java IO流 --> 异常 --> 多线程 --> 网络编程 --> 反射,JavaWeb基础 --> HTML/CSS/JavaScript/jQuery --> Tomcat --> XML/注解 --> Servlet --> HTTP --> Filter过滤器和监听器 --> JSP --> AJAX/JSON --> 数据库（MySQL） --> JDBC和DbUtils项目管理和框架 --> Maven --> SpringBoot Linux基本命令。', NULL, '2020-11-04', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (22, '通知公告', 0, '', '同时提供免费的学习资料，学习技术内容包含有：Spring，Dubbo，MyBatis, RPC,源码分析，高并发、高性能、分布式,性能优化，微服务 高级架构开发等等。', 'Y', '', '', '', '', '', NULL, '2020-11-04', 1, NULL, 'C');
INSERT INTO `tb_channel` VALUES (23, '前端', 0, 'http://localhost:8888/cms/upload/0ccd0d36-5558-4616-9427-263261930803.png', '前端即网站前台部分，HTML5，CSS3，前端框架的应用，跨平台响应式网页设计能够适应各种屏幕分辨率，合适的动效设计，给用户带来极高的用户体验', 'N', '', '', '', '', '', NULL, '2020-11-05', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (24, 'HTML/H5', 23, '', '', 'Y', '', '', '', '', '', NULL, '2020-11-05', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (25, '分布式', 0, '', '', 'N', '', '', '', '', '', NULL, '2020-11-05', 1, NULL, 'B');
INSERT INTO `tb_channel` VALUES (26, '大数据', 0, '', '', 'N', '', '', '', '', '', NULL, '2020-11-05', 1, NULL, 'B');
INSERT INTO `tb_channel` VALUES (27, '人工智能', 0, '', '', 'N', '', '', '', '', '', NULL, '2020-11-05', 1, NULL, 'B');
INSERT INTO `tb_channel` VALUES (28, 'SpringBoot', 17, '', '技术社区 Spring Boot 的文章越来越多；Spring Boot 相关的图文、视频课程越来越多；使用 Spring Boot 的互联网公司越来越多；现在出去面试 Java 工程师， Spring Boot 已经成了必问的内容。', 'N', '', '', '', '', '', NULL, '2020-11-06', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (29, 'SpringCloud', 17, '', 'Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等', 'Y', '', '', '', '', '', NULL, '2020-11-06', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (30, 'CSS/CSS3', 23, '', '对CSS3已完全向后兼容，所以你就不必改变现有的设计。浏览器将永远支持CSS2。', 'N', '', '', '', '', '', NULL, '2020-11-06', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (31, 'Javascript', 23, '', 'JavaScript 是互联网上最流行的脚本语言，这门语言可用于 HTML 和 web，更可广泛用于服务器、PC、笔记本电脑、平板电脑和智能手机等设备。', 'N', '', '', '', '', '', NULL, '2020-11-06', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (32, 'jQuery', 23, '', 'jQuery 库可以通过一行简单的标记被添加到网页中。', 'N', '', '', '', '', '', NULL, '2020-11-06', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (33, 'VUE', 23, '', '是一套构建用户界面的渐进式框架，Vue 只关注视图层， 采用自底向上增量开发的设计。', 'Y', '', '', '', '', '', NULL, '2020-11-06', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (34, 'Spring', 17, '', '', 'N', '', '', '', '', '', NULL, '2020-11-07', 1, NULL, 'A');
INSERT INTO `tb_channel` VALUES (35, '轮播', 0, '', '', 'N', '', '', '', '', '', NULL, '2020-11-09', 1, NULL, 'D');

-- ----------------------------
-- Table structure for tb_comment
-- ----------------------------
DROP TABLE IF EXISTS `tb_comment`;
CREATE TABLE `tb_comment`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `author` int(11) NULL DEFAULT NULL,
  `email` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `ip` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `create_date` date NULL DEFAULT NULL,
  `content` text CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `status` int(1) NULL DEFAULT NULL COMMENT '0待批|1通过|2未通过',
  `article_id` int(11) NOT NULL,
  `parent_id` int(11) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 28 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of tb_comment
-- ----------------------------
INSERT INTO `tb_comment` VALUES (6, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '啊啊啊啊啊啊啊', 0, 21, NULL);
INSERT INTO `tb_comment` VALUES (7, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '啊啊啊啊啊啊啊', 0, 21, NULL);
INSERT INTO `tb_comment` VALUES (10, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '哎哎哎哎哎嗄阿斯蒂芬第三方', 0, 21, NULL);
INSERT INTO `tb_comment` VALUES (11, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '测试', 0, 42, NULL);
INSERT INTO `tb_comment` VALUES (12, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '啊啊啊', 0, 42, NULL);
INSERT INTO `tb_comment` VALUES (13, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '啊啊啊asdfasdf', 0, 42, NULL);
INSERT INTO `tb_comment` VALUES (14, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '啊啊啊asdfasdfasdfasdf', 0, 42, NULL);
INSERT INTO `tb_comment` VALUES (17, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', 'asdfasdf阿斯蒂芬', 0, 42, NULL);
INSERT INTO `tb_comment` VALUES (18, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', 'asdfasdf阿道夫', 0, 42, NULL);
INSERT INTO `tb_comment` VALUES (19, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '我的测试', 0, 17, NULL);
INSERT INTO `tb_comment` VALUES (22, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '测试一下', 0, 17, NULL);
INSERT INTO `tb_comment` VALUES (23, 2050, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '文章写的不错！赞一个！！', 0, 17, NULL);
INSERT INTO `tb_comment` VALUES (24, 1, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '测试一下！！！', 0, 35, NULL);
INSERT INTO `tb_comment` VALUES (25, 1, NULL, '0:0:0:0:0:0:0:1', '2021-01-20', '你好的，我想测试一下！！！', 0, 35, NULL);
INSERT INTO `tb_comment` VALUES (26, 2050, NULL, '192.168.0.130', '2021-01-21', '测试一下！！！', 0, 48, NULL);

-- ----------------------------
-- Table structure for tb_friend_link
-- ----------------------------
DROP TABLE IF EXISTS `tb_friend_link`;
CREATE TABLE `tb_friend_link`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `url` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `title` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `path` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `target` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of tb_friend_link
-- ----------------------------
INSERT INTO `tb_friend_link` VALUES (1, 'https://www.baidu.com', '百度', NULL, '_blank');

-- ----------------------------
-- Table structure for tb_tag
-- ----------------------------
DROP TABLE IF EXISTS `tb_tag`;
CREATE TABLE `tb_tag`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tag_name` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 7 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of tb_tag
-- ----------------------------
INSERT INTO `tb_tag` VALUES (5, '互利网');
INSERT INTO `tb_tag` VALUES (6, '二次元');

-- ----------------------------
-- Table structure for tb_user
-- ----------------------------
DROP TABLE IF EXISTS `tb_user`;
CREATE TABLE `tb_user`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_name` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '账号',
  `password` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '密码',
  `nick_name` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `avatar` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `email` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `create_date` date NULL DEFAULT NULL,
  `status` char(1) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT 'T正常|F禁用|D删除',
  `type` int(1) NULL DEFAULT 0 COMMENT '0系统用户|1注册用户',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 2052 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of tb_user
-- ----------------------------
INSERT INTO `tb_user` VALUES (1, 'admin', '123456', '科科程程', 'http://localhost:8888/cms/upload/43d16d12-ffb0-4532-abc3-5e8f0f6c2f74.jpg', '596183363@qq.com', NULL, 'T', 0);
INSERT INTO `tb_user` VALUES (2050, 'hua', '123456', NULL, 'http://localhost:8888/cms/upload/de8263b0-6927-420d-9bf1-6abb86381ae4.png', '123123', '2021-01-19', NULL, 1);
INSERT INTO `tb_user` VALUES (2051, 'yong', '123456', '123456', NULL, '', '2021-01-19', 'T', 0);

SET FOREIGN_KEY_CHECKS = 1;
